{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Les Fonctions MathÃ©matiques - Guide pour DÃ©butants\n",
    "\n",
    "Bienvenue dans ce cours sur les fonctions mathÃ©matiques ! Les fonctions sont partout en programmation et en Machine Learning. Ne t'inquiÃ¨te pas si c'est nouveau pour toi, nous allons tout expliquer pas Ã  pas avec des visualisations.\n",
    "\n",
    "## ðŸŽ¯ Objectifs de ce notebook:\n",
    "- Comprendre ce qu'est une fonction mathÃ©matique\n",
    "- Savoir lire et utiliser la notation mathÃ©matique\n",
    "- Visualiser des fonctions avec Python\n",
    "- MaÃ®triser le symbole Î£ (sigma) qui est ESSENTIEL en ML\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Importation des bibliothÃ¨ques nÃ©cessaires\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration pour de beaux graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"âœ… BibliothÃ¨ques importÃ©es avec succÃ¨s!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 1ï¸âƒ£ Qu'est-ce qu'une Fonction?\n\n### ðŸ¤” Analogie Simple\n\nImagine une **machine Ã  cafÃ©** â˜•:\n- Tu mets des **grains de cafÃ©** (INPUT)\n- La machine fait son travail (TRANSFORMATION)\n- Tu obtiens un **cafÃ©** (OUTPUT)\n\nUne fonction mathÃ©matique fonctionne exactement pareil!\n\n### ðŸ“ Notation MathÃ©matique\n\nOn Ã©crit: $f(x) = 2x + 1$\n\nCela se lit: **\"f de x Ã©gale 2x plus 1\"**\n\n- $f$ = le nom de la fonction (comme \"machine Ã  cafÃ©\")\n- $x$ = l'input (ce que tu donnes Ã  la fonction)\n- $2x + 1$ = la transformation (ce que la fonction fait)\n\n### ðŸ’¡ Exemple Concret\n\nSi $f(x) = 2x + 1$, alors:\n\n- $f(3) = 2(3) + 1 = 6 + 1 = 7$\n- $f(5) = 2(5) + 1 = 10 + 1 = 11$\n- $f(0) = 2(0) + 1 = 0 + 1 = 1$\n\nVoyons Ã§a en Python:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# DÃ©finir une fonction en Python\n",
    "def f(x):\n",
    "    \"\"\"Fonction mathÃ©matique: f(x) = 2x + 1\"\"\"\n",
    "    return 2 * x + 1\n",
    "\n",
    "# Tester notre fonction\n",
    "print(\"ðŸ”¢ Testons notre fonction f(x) = 2x + 1:\\n\")\n",
    "print(f\"f(3) = {f(3)}\")\n",
    "print(f\"f(5) = {f(5)}\")\n",
    "print(f\"f(0) = {f(0)}\")\n",
    "print(f\"f(-2) = {f(-2)}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Remarque: Une fonction accepte n'importe quel nombre (mÃªme nÃ©gatif!)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2ï¸âƒ£ ReprÃ©sentation Graphique\n\n### ðŸ“ Le Plan CartÃ©sien\n\nPour visualiser une fonction, on utilise un **plan cartÃ©sien** avec:\n- Un axe horizontal: **axe x** (les inputs)\n- Un axe vertical: **axe y** (les outputs)\n\nChaque point sur le graphique reprÃ©sente: $(x, f(x))$\n\n### ðŸŽ¨ Visualisons nos premiÃ¨res fonctions!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CrÃ©er des valeurs x de -10 Ã  10\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "# Fonction 1: f(x) = x (la fonction identitÃ©)\n",
    "y1 = x\n",
    "\n",
    "# Fonction 2: f(x) = xÂ² (fonction quadratique)\n",
    "y2 = x**2\n",
    "\n",
    "# Fonction 3: f(x) = 2x + 1\n",
    "y3 = 2*x + 1\n",
    "\n",
    "# CrÃ©er le graphique\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Graphique 1: f(x) = x\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(x, y1, 'b-', linewidth=2, label='f(x) = x')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Fonction IdentitÃ©')\n",
    "plt.legend()\n",
    "\n",
    "# Graphique 2: f(x) = xÂ²\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(x, y2, 'r-', linewidth=2, label='f(x) = xÂ²')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Fonction Quadratique')\n",
    "plt.legend()\n",
    "\n",
    "# Graphique 3: f(x) = 2x + 1\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(x, y3, 'g-', linewidth=2, label='f(x) = 2x + 1')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Fonction LinÃ©aire')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¨ Observations:\")\n",
    "print(\"â€¢ f(x) = x est une ligne droite Ã  45Â°\")\n",
    "print(\"â€¢ f(x) = xÂ² forme une parabole (forme en U)\")\n",
    "print(\"â€¢ f(x) = 2x + 1 est une ligne droite avec une pente\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### âœï¸ Pratique maintenant !\n\n**Exercices correspondants :** [Exercices 1.1 Ã  1.5 - Ã‰valuation de Fonctions](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ“Š-Section-1-:-Ã‰valuation-de-Fonctions)\n\n> ðŸ’¡ **Conseil** : Fais ces exercices maintenant avant de passer aux fonctions linÃ©aires !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 3ï¸âƒ£ Fonctions LinÃ©aires\n\n### ðŸ“ La Forme GÃ©nÃ©rale\n\nUne fonction linÃ©aire a toujours cette forme:\n\n$$f(x) = ax + b$$\n\nOÃ¹:\n- $a$ = la **pente** (slope en anglais) â†’ indique si la ligne monte ou descend\n- $b$ = **l'ordonnÃ©e Ã  l'origine** (y-intercept) â†’ oÃ¹ la ligne coupe l'axe y\n\n### ðŸ” Comprendre la Pente (a)\n\n- Si $a > 0$ â†’ la ligne **monte** ðŸ“ˆ\n- Si $a < 0$ â†’ la ligne **descend** ðŸ“‰\n- Si $a = 0$ â†’ la ligne est **horizontale** âž¡ï¸\n- Plus $a$ est grand, plus la ligne est **raide** (verticale)\n\n### ðŸ“ Comprendre l'OrdonnÃ©e Ã  l'Origine (b)\n\nC'est simplement la valeur de $f(x)$ quand $x = 0$:\n\n$$f(0) = a(0) + b = b$$\n\n### ðŸŽ¨ Visualisation Interactive"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CrÃ©er plusieurs fonctions linÃ©aires avec diffÃ©rentes pentes\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "# DiffÃ©rentes valeurs de a (pentes)\n",
    "pentes = [3, 1, 0.5, 0, -0.5, -1, -2]\n",
    "colors = ['red', 'orange', 'yellow', 'green', 'cyan', 'blue', 'purple']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for a, color in zip(pentes, colors):\n",
    "    y = a * x + 2  # b = 2 pour toutes\n",
    "    plt.plot(x, y, color=color, linewidth=2, label=f'f(x) = {a}x + 2')\n",
    "\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('f(x)', fontsize=14)\n",
    "plt.title('Effet de la Pente (a) sur la Fonction LinÃ©aire', fontsize=16)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(-15, 15)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Remarque:\")\n",
    "print(\"Toutes les lignes passent par le point (0, 2) car b = 2 pour toutes!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Maintenant, fixons la pente et changeons l'ordonnÃ©e Ã  l'origine\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "# DiffÃ©rentes valeurs de b (ordonnÃ©e Ã  l'origine)\n",
    "intercepts = [-3, -1, 0, 1, 3]\n",
    "colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for b, color in zip(intercepts, colors):\n",
    "    y = 2 * x + b  # a = 2 pour toutes\n",
    "    plt.plot(x, y, color=color, linewidth=2, label=f'f(x) = 2x + {b}')\n",
    "    # Marquer le point oÃ¹ la ligne coupe l'axe y\n",
    "    plt.plot(0, b, 'o', color=color, markersize=10)\n",
    "\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('f(x)', fontsize=14)\n",
    "plt.title('Effet de l\\'OrdonnÃ©e Ã  l\\'Origine (b) sur la Fonction LinÃ©aire', fontsize=16)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(-15, 15)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Remarque:\")\n",
    "print(\"Toutes les lignes sont parallÃ¨les (mÃªme pente a = 2)!\")\n",
    "print(\"Les points colorÃ©s montrent oÃ¹ chaque ligne coupe l'axe y (la valeur de b)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### âœï¸ Pratique maintenant !\n\n**Exercices correspondants :**\n- [Exercices 2.1 Ã  2.5 - Fonctions LinÃ©aires](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ“ˆ-Section-2-:-Fonctions-LinÃ©aires)\n- [Exercices 3.1 Ã  3.6 - Graphiques](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ“‰-Section-3-:-Graphiques-de-Fonctions)\n\n> ðŸ’¡ **Conseil** : Pratique la lecture des graphiques et le calcul des pentes avant de continuer !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4ï¸âƒ£ Fonctions Quadratiques (Paraboles)\n\n### ðŸŽ¢ La Forme GÃ©nÃ©rale\n\nUne fonction quadratique a cette forme:\n\n$$f(x) = ax^2 + bx + c$$\n\n### ðŸ“Š CaractÃ©ristiques\n\n- La courbe forme une **parabole** (forme en U ou en âˆ©)\n- Si $a > 0$ â†’ parabole **vers le haut** ðŸ™‚ (U)\n- Si $a < 0$ â†’ parabole **vers le bas** ðŸ™ƒ (âˆ©)\n- Le point le plus bas (ou haut) s'appelle le **sommet**\n\n### ðŸ¤– Pourquoi c'est important en Machine Learning?\n\nLes fonctions quadratiques sont PARTOUT en ML:\n- **Fonctions de coÃ»t** (erreur quadratique moyenne)\n- **Optimisation** (trouver le minimum d'une parabole)\n- **RÃ©gression polynomiale**\n\nExemple: En ML, on veut souvent **minimiser l'erreur**. Si l'erreur forme une parabole, on cherche son point le plus bas!\n\n### ðŸŽ¨ Visualisation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CrÃ©er diffÃ©rentes fonctions quadratiques\n",
    "x = np.linspace(-5, 5, 200)\n",
    "\n",
    "# Fonction 1: f(x) = xÂ² (parabole basique)\n",
    "y1 = x**2\n",
    "\n",
    "# Fonction 2: f(x) = -xÂ² (parabole inversÃ©e)\n",
    "y2 = -x**2\n",
    "\n",
    "# Fonction 3: f(x) = 0.5xÂ² (parabole plus large)\n",
    "y3 = 0.5 * x**2\n",
    "\n",
    "# Fonction 4: f(x) = 2xÂ² (parabole plus Ã©troite)\n",
    "y4 = 2 * x**2\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Graphique 1: Comparaison parabole normale vs inversÃ©e\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y1, 'b-', linewidth=2, label='f(x) = xÂ²')\n",
    "plt.plot(x, y2, 'r-', linewidth=2, label='f(x) = -xÂ²')\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('f(x)', fontsize=12)\n",
    "plt.title('Parabole Normale vs InversÃ©e', fontsize=14)\n",
    "plt.legend()\n",
    "plt.ylim(-25, 25)\n",
    "\n",
    "# Graphique 2: Effet du coefficient a\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, y3, 'g-', linewidth=2, label='f(x) = 0.5xÂ²')\n",
    "plt.plot(x, y1, 'b-', linewidth=2, label='f(x) = xÂ²')\n",
    "plt.plot(x, y4, 'r-', linewidth=2, label='f(x) = 2xÂ²')\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('f(x)', fontsize=12)\n",
    "plt.title('Effet du Coefficient a', fontsize=14)\n",
    "plt.legend()\n",
    "plt.ylim(0, 25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Observations:\")\n",
    "print(\"â€¢ Plus |a| est grand, plus la parabole est 'Ã©troite'\")\n",
    "print(\"â€¢ Si a > 0, la parabole sourit ðŸ™‚\")\n",
    "print(\"â€¢ Si a < 0, la parabole est triste ðŸ™ƒ\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemple d'application ML: Fonction de coÃ»t (erreur quadratique)\n",
    "# Imaginons qu'on essaie de prÃ©dire une valeur et qu'on mesure l'erreur\n",
    "\n",
    "# Valeur vraie\n",
    "valeur_vraie = 5\n",
    "\n",
    "# DiffÃ©rentes prÃ©dictions possibles\n",
    "predictions = np.linspace(0, 10, 100)\n",
    "\n",
    "# Erreur quadratique: (prÃ©diction - vraie_valeur)Â²\n",
    "erreur_quadratique = (predictions - valeur_vraie)**2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(predictions, erreur_quadratique, 'r-', linewidth=2)\n",
    "plt.axvline(x=valeur_vraie, color='g', linestyle='--', linewidth=2, label='Valeur optimale (erreur minimale)')\n",
    "plt.plot(valeur_vraie, 0, 'go', markersize=15, label='Minimum (erreur = 0)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('PrÃ©diction', fontsize=12)\n",
    "plt.ylabel('Erreur Quadratique', fontsize=12)\n",
    "plt.title('Fonction de CoÃ»t en Machine Learning\\n(Plus on est loin de la vraie valeur, plus l\\'erreur augmente!)', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ¤– Application ML:\")\n",
    "print(\"En Machine Learning, on cherche Ã  MINIMISER cette erreur!\")\n",
    "print(f\"L'erreur est minimale (= 0) quand la prÃ©diction = {valeur_vraie}\")\n",
    "print(\"\\nC'est pour Ã§a qu'on utilise des fonctions quadratiques:\")\n",
    "print(\"â€¢ Elles pÃ©nalisent les grosses erreurs plus que les petites\")\n",
    "print(\"â€¢ Elles ont un minimum clair (le fond de la parabole)\")\n",
    "print(\"â€¢ Elles sont faciles Ã  optimiser mathÃ©matiquement\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### âœï¸ Pratique maintenant !\n\n**Exercices correspondants :** [Exercices 4.1 Ã  4.4 - Fonctions Quadratiques](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ”²-Section-4-:-Fonctions-Quadratiques)\n\n> ðŸ’¡ **Conseil** : Comprendre les paraboles est essentiel pour l'optimisation en ML !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5ï¸âƒ£ La Notation Sigma (Î£) - CRUCIAL pour le ML!\n\n### ðŸ“š Qu'est-ce que Sigma?\n\nLe symbole **Î£** (sigma majuscule en grec) signifie **SOMME**.\n\nC'est un raccourci mathÃ©matique pour dire: \"**additionne tous ces nombres**\".\n\n### âœï¸ La Notation\n\n$$\\sum_{i=1}^{n} x_i = x_1 + x_2 + x_3 + ... + x_n$$\n\nSe lit: \"**Somme de i=1 Ã  n de x indice i**\"\n\nDÃ©composons:\n- $\\sum$ = symbole de somme\n- $i=1$ (en bas) = **dÃ©but** de la somme (i commence Ã  1)\n- $n$ (en haut) = **fin** de la somme (i va jusqu'Ã  n)\n- $x_i$ = ce qu'on additionne (x avec l'indice i)\n\n### ðŸ”¢ Exemples Concrets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"ðŸ“ Exemple 1: Somme des nombres de 1 Ã  5\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# En notation mathÃ©matique: Î£(i=1 Ã  5) i\n",
    "# Cela signifie: 1 + 2 + 3 + 4 + 5\n",
    "\n",
    "# MÃ©thode 1: Ã€ la main\n",
    "somme_manuelle = 1 + 2 + 3 + 4 + 5\n",
    "print(f\"Ã€ la main: 1 + 2 + 3 + 4 + 5 = {somme_manuelle}\")\n",
    "\n",
    "# MÃ©thode 2: Avec une boucle (la faÃ§on \"sigma\")\n",
    "somme_boucle = 0\n",
    "for i in range(1, 6):  # range(1, 6) donne [1, 2, 3, 4, 5]\n",
    "    somme_boucle += i\n",
    "print(f\"Avec boucle: Î£(i=1 Ã  5) i = {somme_boucle}\")\n",
    "\n",
    "# MÃ©thode 3: Avec sum() (le plus pythonique)\n",
    "somme_sum = sum(range(1, 6))\n",
    "print(f\"Avec sum(): {somme_sum}\")\n",
    "\n",
    "print(\"\\nâœ… Toutes les mÃ©thodes donnent le mÃªme rÃ©sultat!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"ðŸ“ Exemple 2: Somme des carrÃ©s\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# En notation mathÃ©matique: Î£(i=1 Ã  4) iÂ²\n",
    "# Cela signifie: 1Â² + 2Â² + 3Â² + 4Â²\n",
    "\n",
    "# Calculons pas Ã  pas\n",
    "print(\"\\nÃ‰tape par Ã©tape:\")\n",
    "total = 0\n",
    "for i in range(1, 5):\n",
    "    carre = i**2\n",
    "    total += carre\n",
    "    print(f\"i={i}: {i}Â² = {carre}, total = {total}\")\n",
    "\n",
    "print(f\"\\nRÃ©sultat final: Î£(i=1 Ã  4) iÂ² = {total}\")\n",
    "\n",
    "# VÃ©rifions\n",
    "print(f\"VÃ©rification: 1Â² + 2Â² + 3Â² + 4Â² = {1**2 + 2**2 + 3**2 + 4**2} âœ“\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ¤– Pourquoi Sigma est CRUCIAL en Machine Learning?\n\nEn ML, on utilise **constamment** des sommes! Voici quelques exemples:\n\n#### 1ï¸âƒ£ Calcul de la Moyenne\n\n$$\\text{moyenne} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$\n\n\"Additionne tous les nombres, puis divise par combien il y en a\"\n\n#### 2ï¸âƒ£ Erreur Quadratique Moyenne (MSE)\n\n$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n\nOÃ¹:\n- $y_i$ = valeur vraie\n- $\\hat{y}_i$ = prÃ©diction\n\n\"Calcule l'erreur pour chaque prÃ©diction, Ã©lÃ¨ve au carrÃ©, additionne tout, puis fais la moyenne\"\n\n#### 3ï¸âƒ£ Somme PondÃ©rÃ©e (Neurone)\n\n$$z = \\sum_{i=1}^{n} w_i x_i + b$$\n\n\"Multiplie chaque input par son poids, additionne tout, puis ajoute un biais\"\n\n### ðŸ’» ImplÃ©mentation Python"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemple 1: Calcul de la moyenne\n",
    "print(\"ðŸ“Š Exemple ML 1: Calcul de la Moyenne\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Des notes d'Ã©tudiants\n",
    "notes = [85, 92, 78, 90, 88, 95, 82]\n",
    "n = len(notes)\n",
    "\n",
    "print(f\"Notes: {notes}\")\n",
    "print(f\"Nombre d'Ã©tudiants (n): {n}\")\n",
    "\n",
    "# MÃ©thode avec boucle (comprendre Î£)\n",
    "somme = 0\n",
    "for note in notes:\n",
    "    somme += note\n",
    "moyenne_boucle = somme / n\n",
    "\n",
    "print(f\"\\nAvec Î£: Î£(notes) = {somme}\")\n",
    "print(f\"Moyenne = {somme}/{n} = {moyenne_boucle:.2f}\")\n",
    "\n",
    "# MÃ©thode Python\n",
    "moyenne_python = sum(notes) / len(notes)\n",
    "print(f\"\\nAvec Python: {moyenne_python:.2f}\")\n",
    "\n",
    "# MÃ©thode NumPy (le plus utilisÃ© en ML)\n",
    "moyenne_numpy = np.mean(notes)\n",
    "print(f\"Avec NumPy: {moyenne_numpy:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemple 2: Erreur Quadratique Moyenne (MSE)\n",
    "print(\"ðŸŽ¯ Exemple ML 2: Mean Squared Error (MSE)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Valeurs vraies et prÃ©dictions\n",
    "y_vrai = np.array([100, 150, 200, 250, 300])\n",
    "y_pred = np.array([110, 145, 190, 260, 295])\n",
    "\n",
    "print(\"Valeurs vraies:\", y_vrai)\n",
    "print(\"PrÃ©dictions:   \", y_pred)\n",
    "\n",
    "# Calcul du MSE avec une boucle (comprendre Î£)\n",
    "print(\"\\nðŸ“ Calcul Ã©tape par Ã©tape:\")\n",
    "n = len(y_vrai)\n",
    "somme_erreurs_carrees = 0\n",
    "\n",
    "for i in range(n):\n",
    "    erreur = y_vrai[i] - y_pred[i]\n",
    "    erreur_carree = erreur**2\n",
    "    somme_erreurs_carrees += erreur_carree\n",
    "    print(f\"i={i}: erreur={erreur}, erreurÂ²={erreur_carree}, somme={somme_erreurs_carrees}\")\n",
    "\n",
    "mse_boucle = somme_erreurs_carrees / n\n",
    "print(f\"\\nMSE = {somme_erreurs_carrees}/{n} = {mse_boucle:.2f}\")\n",
    "\n",
    "# MÃ©thode NumPy (le plus utilisÃ© en ML)\n",
    "mse_numpy = np.mean((y_vrai - y_pred)**2)\n",
    "print(f\"\\nAvec NumPy: MSE = {mse_numpy:.2f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ InterprÃ©tation:\")\n",
    "print(f\"En moyenne, nos prÃ©dictions sont Ã  {np.sqrt(mse_numpy):.2f} unitÃ©s de la vraie valeur\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemple 3: Somme PondÃ©rÃ©e (comme dans un neurone)\n",
    "print(\"ðŸ§  Exemple ML 3: Somme PondÃ©rÃ©e (Neurone Artificiel)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Inputs (caractÃ©ristiques)\n",
    "x = np.array([1.5, 2.0, 3.0])  # Par exemple: [taille, poids, Ã¢ge]\n",
    "\n",
    "# Poids (weights) appris par le modÃ¨le\n",
    "w = np.array([0.5, 0.3, 0.2])\n",
    "\n",
    "# Biais (bias)\n",
    "b = 1.0\n",
    "\n",
    "print(f\"Inputs (x): {x}\")\n",
    "print(f\"Poids (w): {w}\")\n",
    "print(f\"Biais (b): {b}\")\n",
    "\n",
    "# Calcul avec une boucle (comprendre Î£)\n",
    "print(\"\\nðŸ“ Calcul de z = Î£(w_i * x_i) + b:\")\n",
    "somme_ponderee = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    produit = w[i] * x[i]\n",
    "    somme_ponderee += produit\n",
    "    print(f\"i={i}: w[{i}] * x[{i}] = {w[i]} * {x[i]} = {produit:.2f}\")\n",
    "\n",
    "z_boucle = somme_ponderee + b\n",
    "print(f\"\\nSomme pondÃ©rÃ©e = {somme_ponderee:.2f}\")\n",
    "print(f\"z = {somme_ponderee:.2f} + {b} = {z_boucle:.2f}\")\n",
    "\n",
    "# MÃ©thode NumPy (le plus utilisÃ© en ML)\n",
    "z_numpy = np.dot(w, x) + b  # dot = produit scalaire\n",
    "print(f\"\\nAvec NumPy (np.dot): z = {z_numpy:.2f}\")\n",
    "\n",
    "print(\"\\nðŸ§  Dans un rÃ©seau de neurones:\")\n",
    "print(\"Cette valeur z serait ensuite passÃ©e Ã  une fonction d'activation!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¨ Visualisation de Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualisons comment une somme se construit\n",
    "n = 10\n",
    "valeurs = range(1, n+1)\n",
    "sommes_cumulatives = []\n",
    "\n",
    "somme_actuelle = 0\n",
    "for val in valeurs:\n",
    "    somme_actuelle += val\n",
    "    sommes_cumulatives.append(somme_actuelle)\n",
    "\n",
    "# CrÃ©er le graphique\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Graphique 1: Barres individuelles\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(valeurs, valeurs, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('i', fontsize=12)\n",
    "plt.ylabel('Valeur', fontsize=12)\n",
    "plt.title('Valeurs Individuelles', fontsize=14)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Graphique 2: Somme cumulative\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(valeurs, sommes_cumulatives, 'ro-', linewidth=2, markersize=8)\n",
    "plt.fill_between(valeurs, sommes_cumulatives, alpha=0.3, color='red')\n",
    "plt.xlabel('i', fontsize=12)\n",
    "plt.ylabel('Somme Cumulative', fontsize=12)\n",
    "plt.title(f'Î£(i=1 Ã  {n}) i = {sommes_cumulatives[-1]}', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ”¢ RÃ©sultat: Î£(i=1 Ã  {n}) i = {sommes_cumulatives[-1]}\")\n",
    "print(\"\\nðŸ’¡ Le graphique de droite montre comment la somme grandit Ã  chaque ajout!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### âœï¸ Pratique maintenant !\n\n**Exercices correspondants :**\n- [Exercices 5.1 Ã  5.8 - Notation Sigma (Î£)](../../envs/phase_1_math/exercices_02_fonctions.ipynb#âž•-Section-5-:-Notation-Sigma-(Î£))\n- [Exercices 6.1 Ã  6.8 - Applications ML](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ¤–-Section-6-:-Applications-ML)\n\n> ðŸ’¡ **Important** : La notation Sigma est FONDAMENTALE en Machine Learning. Prends le temps de bien maÃ®triser ces exercices !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ Formules Sigma Importantes en ML\n",
    "\n",
    "Voici un rÃ©sumÃ© des formules que tu verras TOUT LE TEMPS:\n",
    "\n",
    "| Formule | Notation Sigma | Utilisation |\n",
    "|---------|----------------|-------------|\n",
    "| Moyenne | $$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$ | Statistiques de base |\n",
    "| Variance | $$\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$$ | Mesure de dispersion |\n",
    "| MSE | $$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$ | Fonction de coÃ»t |\n",
    "| Somme pondÃ©rÃ©e | $$z = \\sum_{i=1}^{n} w_i x_i + b$$ | Neurones artificiels |\n",
    "| Produit scalaire | $$\\mathbf{w} \\cdot \\mathbf{x} = \\sum_{i=1}^{n} w_i x_i$$ | AlgÃ¨bre linÃ©aire |\n",
    "\n",
    "**âœ¨ Ne t'inquiÃ¨te pas si Ã§a semble beaucoup!** Avec la pratique, ces formules deviendront naturelles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## ðŸŽ“ RÃ©sumÃ© et Points ClÃ©s\n\n### âœ… Ce que tu as appris:\n\n1. **Les Fonctions**\n   - Une fonction transforme un input en output: $f(x)$\n   - Notation: $f(3) = 7$ signifie \"quand x=3, le rÃ©sultat est 7\"\n\n2. **Fonctions LinÃ©aires** $f(x) = ax + b$\n   - $a$ = pente (monte/descend)\n   - $b$ = ordonnÃ©e Ã  l'origine (coupe l'axe y)\n   - Forme une ligne droite\n\n3. **Fonctions Quadratiques** $f(x) = ax^2 + bx + c$\n   - Forme une parabole (U ou âˆ©)\n   - UtilisÃ©es partout en ML (fonctions de coÃ»t)\n\n4. **La Notation Sigma** $\\sum_{i=1}^{n} x_i$\n   - Signifie: \"additionne tous ces nombres\"\n   - ESSENTIEL en ML pour: moyennes, MSE, neurones, etc.\n\n---\n\n## ðŸ“š MÃ©thode de travail recommandÃ©e\n\n| Ã‰tape | Action |\n|-------|--------|\n| 1ï¸âƒ£ | Lis une section du cours |\n| 2ï¸âƒ£ | Fais les exercices correspondants |\n| 3ï¸âƒ£ | VÃ©rifie avec les solutions |\n| 4ï¸âƒ£ | Passe Ã  la section suivante |\n\n---\n\n## âœï¸ RÃ©capitulatif des exercices\n\n| Section du cours | Exercices |\n|------------------|-----------|\n| Fonctions de base | [Ex 1.1-1.5 Ã‰valuation](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ“Š-Section-1-:-Ã‰valuation-de-Fonctions) |\n| Fonctions linÃ©aires | [Ex 2.1-2.5 LinÃ©aires](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ“ˆ-Section-2-:-Fonctions-LinÃ©aires) |\n| Graphiques | [Ex 3.1-3.6 Graphiques](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ“‰-Section-3-:-Graphiques-de-Fonctions) |\n| Quadratiques | [Ex 4.1-4.4 Quadratiques](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ”²-Section-4-:-Fonctions-Quadratiques) |\n| Notation Sigma | [Ex 5.1-5.8 Sigma](../../envs/phase_1_math/exercices_02_fonctions.ipynb#âž•-Section-5-:-Notation-Sigma-(Î£)) |\n| Applications ML | [Ex 6.1-6.8 Applications](../../envs/phase_1_math/exercices_02_fonctions.ipynb#ðŸ¤–-Section-6-:-Applications-ML) |\n\n**Solutions :** [solutions_02_fonctions.ipynb](../../envs/phase_1_math/solutions_02_fonctions.ipynb)\n\n---\n\n**Conseils :**\n- Essaie **VRAIMENT** chaque exercice avant de regarder la solution\n- Les exercices sur Sigma (Î£) sont particuliÃ¨rement importants pour ML\n- Si tu bloques > 15 min, regarde un indice puis rÃ©essaie\n\n---\n\n### ðŸš€ Prochaines Ã‰tapes:\n\n- **Notebook suivant**: DÃ©rivÃ©es (comment les fonctions changent)\n- **Pourquoi c'est important**: Les dÃ©rivÃ©es sont au cÅ“ur de l'entraÃ®nement des rÃ©seaux de neurones!\n\n**N'oublie pas**: Les maths ne sont pas Ã  mÃ©moriser, mais Ã  **comprendre** et **visualiser**. Les graphiques sont tes amis! ðŸ“Š\n\n---\n\n#### ðŸ“š Ressources SupplÃ©mentaires:\n- [Khan Academy - Fonctions](https://fr.khanacademy.org/math/algebra/x2f8bb11595b61c86:functions)\n- [3Blue1Brown - Essence of Calculus](https://www.youtube.com/watch?v=WUvTyaaNkzM) (en anglais, excellentes visualisations)\n- Documentation Matplotlib pour crÃ©er tes propres graphiques"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}