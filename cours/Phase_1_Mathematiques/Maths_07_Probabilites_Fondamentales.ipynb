{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Chapitre 07 : Probabilit√©s Fondamentales\n",
    "\n",
    "## üéØ Objectifs du chapitre\n",
    "\n",
    "Les probabilit√©s sont **ABSOLUMENT ESSENTIELLES** pour le Machine Learning et la finance quantitative :\n",
    "\n",
    "- ü§ñ **Machine Learning** : Bayesian ML, Naive Bayes, √©chantillonnage, incertitude\n",
    "- üìà **Finance Quantitative** : Mod√©lisation des rendements, Value at Risk, options pricing\n",
    "- üß† **Deep Learning** : Dropout, variational inference, uncertainty quantification\n",
    "- üìä **Statistics** : Fondation de tous les tests statistiques et mod√®les\n",
    "\n",
    "### Ce que vous allez ma√Ætriser :\n",
    "\n",
    "1. ‚úÖ Espaces de probabilit√© et √©v√©nements\n",
    "2. ‚úÖ Probabilit√©s conditionnelles et ind√©pendance\n",
    "3. ‚úÖ **Th√©or√®me de Bayes** (crucial en ML !)\n",
    "4. ‚úÖ Variables al√©atoires discr√®tes et continues\n",
    "5. ‚úÖ Distributions de probabilit√© (Bernoulli, Binomiale, Poisson, Normale)\n",
    "6. ‚úÖ Esp√©rance, variance, moments\n",
    "7. ‚úÖ Covariance et corr√©lation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Imports n√©cessaires\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Seed pour reproductibilit√©\n",
    "np.random.seed(42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Espace de Probabilit√© et √âv√©nements\n",
    "\n",
    "### üìö Th√©orie\n",
    "\n",
    "Un **espace de probabilit√©** est un triplet $(\\Omega, \\mathcal{F}, P)$ o√π :\n",
    "\n",
    "- $\\Omega$ : **Espace √©chantillonnal** (ensemble de tous les r√©sultats possibles)\n",
    "- $\\mathcal{F}$ : **Tribu** ou œÉ-alg√®bre (ensemble des √©v√©nements mesurables)\n",
    "- $P$ : **Mesure de probabilit√©** qui satisfait :\n",
    "  - $P(\\Omega) = 1$\n",
    "  - $P(A) \\geq 0$ pour tout $A \\in \\mathcal{F}$\n",
    "  - Si $A_1, A_2, ...$ sont disjoints : $P(\\bigcup_{i=1}^{\\infty} A_i) = \\sum_{i=1}^{\\infty} P(A_i)$\n",
    "\n",
    "### üé≤ Op√©rations sur les √©v√©nements\n",
    "\n",
    "- **Union** : $A \\cup B$ (A ou B)\n",
    "- **Intersection** : $A \\cap B$ (A et B)\n",
    "- **Compl√©mentaire** : $A^c$ (non A)\n",
    "- **Diff√©rence** : $A \\setminus B$ = $A \\cap B^c$\n",
    "\n",
    "### üìê Axiomes de Kolmogorov\n",
    "\n",
    "$$P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$$\n",
    "$$P(A^c) = 1 - P(A)$$\n",
    "$$P(\\emptyset) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemple : Lancer de d√©\n",
    "class EspaceProbabilite:\n",
    "    \"\"\"Repr√©sentation d'un espace de probabilit√© discret\"\"\"\n",
    "    \n",
    "    def __init__(self, omega: List, probas: List[float]):\n",
    "        \"\"\"\n",
    "        omega: Liste des r√©sultats possibles\n",
    "        probas: Liste des probabilit√©s correspondantes\n",
    "        \"\"\"\n",
    "        assert len(omega) == len(probas), \"Dimensions incompatibles\"\n",
    "        assert abs(sum(probas) - 1.0) < 1e-10, \"Les probabilit√©s doivent sommer √† 1\"\n",
    "        \n",
    "        self.omega = omega\n",
    "        self.probas = np.array(probas)\n",
    "        self.proba_dict = dict(zip(omega, probas))\n",
    "    \n",
    "    def P(self, evenement: List) -> float:\n",
    "        \"\"\"Calcule P(√©v√©nement)\"\"\"\n",
    "        return sum(self.proba_dict.get(e, 0) for e in evenement)\n",
    "    \n",
    "    def union(self, A: List, B: List) -> List:\n",
    "        \"\"\"A ‚à™ B\"\"\"\n",
    "        return list(set(A) | set(B))\n",
    "    \n",
    "    def intersection(self, A: List, B: List) -> List:\n",
    "        \"\"\"A ‚à© B\"\"\"\n",
    "        return list(set(A) & set(B))\n",
    "    \n",
    "    def complementaire(self, A: List) -> List:\n",
    "        \"\"\"A^c\"\"\"\n",
    "        return [e for e in self.omega if e not in A]\n",
    "\n",
    "# Exemple : D√© √©quilibr√©\n",
    "de = EspaceProbabilite(\n",
    "    omega=[1, 2, 3, 4, 5, 6],\n",
    "    probas=[1/6] * 6\n",
    ")\n",
    "\n",
    "# √âv√©nements\n",
    "A = [2, 4, 6]  # Nombre pair\n",
    "B = [1, 2, 3]  # Nombre ‚â§ 3\n",
    "\n",
    "print(\"üé≤ Espace de probabilit√© : Lancer de d√©\\n\")\n",
    "print(f\"P(nombre pair) = P({A}) = {de.P(A):.4f}\")\n",
    "print(f\"P(nombre ‚â§ 3) = P({B}) = {de.P(B):.4f}\")\n",
    "print(f\"\\nP(A ‚à™ B) = {de.P(de.union(A, B)):.4f}\")\n",
    "print(f\"P(A ‚à© B) = {de.P(de.intersection(A, B)):.4f}\")\n",
    "print(f\"P(A^c) = {de.P(de.complementaire(A)):.4f}\")\n",
    "print(f\"\\nV√©rification : P(A) + P(A ‚à© B) - P(A ‚à© B) = {de.P(A) + de.P(B) - de.P(de.intersection(A, B)):.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Probabilit√©s Conditionnelles\n",
    "\n",
    "### üìö D√©finition\n",
    "\n",
    "La probabilit√© de $A$ **sachant** $B$ (not√©e $P(A|B)$) est :\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "si $P(B) > 0$.\n",
    "\n",
    "### üîó Formule de multiplication\n",
    "\n",
    "$$P(A \\cap B) = P(A|B) \\cdot P(B) = P(B|A) \\cdot P(A)$$\n",
    "\n",
    "### üéØ Ind√©pendance\n",
    "\n",
    "Deux √©v√©nements $A$ et $B$ sont **ind√©pendants** si :\n",
    "\n",
    "$$P(A \\cap B) = P(A) \\cdot P(B)$$\n",
    "\n",
    "√âquivalent √† : $P(A|B) = P(A)$ (l'information sur $B$ ne change pas $A$)\n",
    "\n",
    "### üå≥ Formule des probabilit√©s totales\n",
    "\n",
    "Si $(B_1, ..., B_n)$ forme une partition de $\\Omega$ :\n",
    "\n",
    "$$P(A) = \\sum_{i=1}^{n} P(A|B_i) \\cdot P(B_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemple : Test m√©dical\n",
    "def probabilite_conditionnelle(p_a_inter_b: float, p_b: float) -> float:\n",
    "    \"\"\"Calcule P(A|B) = P(A‚à©B) / P(B)\"\"\"\n",
    "    if p_b == 0:\n",
    "        raise ValueError(\"P(B) ne peut pas √™tre 0\")\n",
    "    return p_a_inter_b / p_b\n",
    "\n",
    "# Probl√®me : Test de d√©pistage\n",
    "# M = malade, T = test positif\n",
    "P_M = 0.01  # 1% de la population est malade\n",
    "P_T_sachant_M = 0.95  # Sensibilit√© : 95% de vrais positifs\n",
    "P_T_sachant_non_M = 0.05  # 5% de faux positifs\n",
    "\n",
    "# Calcul de P(T) par probabilit√©s totales\n",
    "P_T = P_T_sachant_M * P_M + P_T_sachant_non_M * (1 - P_M)\n",
    "\n",
    "print(\"üè• Exemple : Test m√©dical\\n\")\n",
    "print(f\"Pr√©valence de la maladie : {P_M*100:.1f}%\")\n",
    "print(f\"Sensibilit√© du test : {P_T_sachant_M*100:.1f}%\")\n",
    "print(f\"Taux de faux positifs : {P_T_sachant_non_M*100:.1f}%\")\n",
    "print(f\"\\nP(Test positif) = {P_T:.4f}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Diagramme en barres\n",
    "categories = ['Malades\\nTest√©s+', 'Sains\\nTest√©s+', 'Malades\\nTest√©s-', 'Sains\\nTest√©s-']\n",
    "probas = [\n",
    "    P_T_sachant_M * P_M,\n",
    "    P_T_sachant_non_M * (1 - P_M),\n",
    "    (1 - P_T_sachant_M) * P_M,\n",
    "    (1 - P_T_sachant_non_M) * (1 - P_M)\n",
    "]\n",
    "colors = ['green', 'orange', 'red', 'blue']\n",
    "\n",
    "ax1.bar(categories, probas, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Probabilit√©')\n",
    "ax1.set_title('Distribution des cas')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (cat, prob) in enumerate(zip(categories, probas)):\n",
    "    ax1.text(i, prob + 0.01, f'{prob:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# Diagramme de Venn\n",
    "from matplotlib.patches import Circle\n",
    "ax2.set_xlim(0, 4)\n",
    "ax2.set_ylim(0, 4)\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "circle_M = Circle((1.5, 2), 1, color='red', alpha=0.3, label='Malades')\n",
    "circle_T = Circle((2.5, 2), 1, color='blue', alpha=0.3, label='Test+')\n",
    "ax2.add_patch(circle_M)\n",
    "ax2.add_patch(circle_T)\n",
    "\n",
    "ax2.text(1.2, 2, f'M\\n{P_M:.3f}', ha='center', va='center', fontsize=10)\n",
    "ax2.text(2.8, 2, f'T\\n{P_T:.3f}', ha='center', va='center', fontsize=10)\n",
    "ax2.text(2, 2, f'M‚à©T\\n{P_T_sachant_M * P_M:.4f}', ha='center', va='center', fontsize=9)\n",
    "\n",
    "ax2.set_title('Diagramme de Venn')\n",
    "ax2.legend()\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Th√©or√®me de Bayes üåü\n",
    "\n",
    "### üéì LE th√©or√®me fondamental du ML !\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Ou, en version compl√®te avec probabilit√©s totales :\n",
    "\n",
    "$$P(A_i|B) = \\frac{P(B|A_i) \\cdot P(A_i)}{\\sum_{j=1}^{n} P(B|A_j) \\cdot P(A_j)}$$\n",
    "\n",
    "### üìñ Vocabulaire bay√©sien\n",
    "\n",
    "- $P(A)$ : **Prior** (probabilit√© a priori)\n",
    "- $P(B|A)$ : **Likelihood** (vraisemblance)\n",
    "- $P(A|B)$ : **Posterior** (probabilit√© a posteriori)\n",
    "- $P(B)$ : **Evidence** (normalisation)\n",
    "\n",
    "### ü§ñ ESSENTIEL EN ML !\n",
    "\n",
    "Le th√©or√®me de Bayes est la base de :\n",
    "- **Naive Bayes classifier**\n",
    "- **Bayesian inference**\n",
    "- **Bayesian optimization**\n",
    "- **Probabilistic graphical models**\n",
    "- **Posterior inference in neural networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def theoreme_bayes(prior: float, likelihood: float, evidence: float) -> float:\n",
    "    \"\"\"Calcule le posterior avec le th√©or√®me de Bayes\"\"\"\n",
    "    return (likelihood * prior) / evidence\n",
    "\n",
    "# Retour sur le test m√©dical avec Bayes\n",
    "print(\"üß¨ Th√©or√®me de Bayes : Test m√©dical\\n\")\n",
    "\n",
    "# P(Malade | Test+) = ?\n",
    "prior = P_M  # P(Malade)\n",
    "likelihood = P_T_sachant_M  # P(Test+ | Malade)\n",
    "evidence = P_T  # P(Test+)\n",
    "\n",
    "posterior = theoreme_bayes(prior, likelihood, evidence)\n",
    "\n",
    "print(f\"Prior P(Malade) = {prior:.4f}\")\n",
    "print(f\"Likelihood P(Test+|Malade) = {likelihood:.4f}\")\n",
    "print(f\"Evidence P(Test+) = {evidence:.4f}\")\n",
    "print(f\"\\nüéØ Posterior P(Malade|Test+) = {posterior:.4f}\")\n",
    "print(f\"\\nüí° Si test positif, seulement {posterior*100:.1f}% de chances d'√™tre malade!\")\n",
    "print(f\"   (Car la pr√©valence est faible et il y a des faux positifs)\")\n",
    "\n",
    "# Exemple 2 : Classification bay√©sienne\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìß Exemple : Filtre anti-spam bay√©sien\\n\")\n",
    "\n",
    "# Donn√©es\n",
    "P_spam = 0.3  # 30% des emails sont des spams\n",
    "P_mot_viagra_sachant_spam = 0.8  # 80% des spams contiennent \"viagra\"\n",
    "P_mot_viagra_sachant_ham = 0.05  # 5% des emails l√©gitimes contiennent \"viagra\"\n",
    "\n",
    "# P(\"viagra\") par probabilit√©s totales\n",
    "P_mot_viagra = (P_mot_viagra_sachant_spam * P_spam + \n",
    "                P_mot_viagra_sachant_ham * (1 - P_spam))\n",
    "\n",
    "# P(Spam | \"viagra\") par Bayes\n",
    "P_spam_sachant_viagra = theoreme_bayes(\n",
    "    prior=P_spam,\n",
    "    likelihood=P_mot_viagra_sachant_spam,\n",
    "    evidence=P_mot_viagra\n",
    ")\n",
    "\n",
    "print(f\"Prior P(Spam) = {P_spam:.2f}\")\n",
    "print(f\"P('viagra'|Spam) = {P_mot_viagra_sachant_spam:.2f}\")\n",
    "print(f\"P('viagra'|Ham) = {P_mot_viagra_sachant_ham:.2f}\")\n",
    "print(f\"\\nüéØ P(Spam|'viagra') = {P_spam_sachant_viagra:.4f}\")\n",
    "print(f\"\\nüí° Si email contient 'viagra', {P_spam_sachant_viagra*100:.1f}% de chances que ce soit un spam!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualisation de l'update bay√©sien\n",
    "def visualiser_update_bayesien(priors: np.ndarray, likelihoods: np.ndarray, \n",
    "                               labels: List[str], titre: str):\n",
    "    \"\"\"\n",
    "    Visualise comment le prior devient posterior apr√®s observation\n",
    "    \"\"\"\n",
    "    # Calcul des posteriors\n",
    "    evidence = np.sum(priors * likelihoods)\n",
    "    posteriors = (likelihoods * priors) / evidence\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Prior\n",
    "    axes[0].bar(labels, priors, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_title('Prior P(H)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Probabilit√©')\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Likelihood\n",
    "    axes[1].bar(labels, likelihoods, color='orange', alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_title('Likelihood P(D|H)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Probabilit√©')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Posterior\n",
    "    axes[2].bar(labels, posteriors, color='green', alpha=0.7, edgecolor='black')\n",
    "    axes[2].set_title('Posterior P(H|D)', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('Probabilit√©')\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Annotations\n",
    "    for ax, values in zip(axes, [priors, likelihoods, posteriors]):\n",
    "        for i, v in enumerate(values):\n",
    "            ax.text(i, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(titre, fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return posteriors\n",
    "\n",
    "# Exemple : Diagnostic m√©dical avec 3 maladies possibles\n",
    "labels = ['Grippe', 'Covid', 'Allergie']\n",
    "priors = np.array([0.5, 0.1, 0.4])  # Pr√©valences\n",
    "likelihoods = np.array([0.3, 0.9, 0.1])  # P(fi√®vre | maladie)\n",
    "\n",
    "posteriors = visualiser_update_bayesien(\n",
    "    priors, likelihoods, labels,\n",
    "    \"Update Bay√©sien : Diagnostic avec sympt√¥me 'fi√®vre'\"\n",
    ")\n",
    "\n",
    "print(\"\\nüîÑ Mise √† jour bay√©sienne :\")\n",
    "for label, prior, post in zip(labels, priors, posteriors):\n",
    "    print(f\"{label:10s} : {prior:.3f} ‚Üí {post:.3f} (√ó{post/prior:.2f})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Variables Al√©atoires\n",
    "\n",
    "### üìö D√©finition\n",
    "\n",
    "Une **variable al√©atoire** (VA) est une fonction $X: \\Omega \\to \\mathbb{R}$ qui associe un nombre r√©el √† chaque r√©sultat.\n",
    "\n",
    "### üé≤ Variables al√©atoires discr√®tes\n",
    "\n",
    "Une VA discr√®te prend un nombre fini ou d√©nombrable de valeurs.\n",
    "\n",
    "**Fonction de masse de probabilit√© (PMF)** :\n",
    "$$p_X(x) = P(X = x)$$\n",
    "\n",
    "**Propri√©t√©s** :\n",
    "- $p_X(x) \\geq 0$ pour tout $x$\n",
    "- $\\sum_{x} p_X(x) = 1$\n",
    "\n",
    "**Fonction de r√©partition (CDF)** :\n",
    "$$F_X(x) = P(X \\leq x) = \\sum_{t \\leq x} p_X(t)$$\n",
    "\n",
    "### üìä Variables al√©atoires continues\n",
    "\n",
    "Une VA continue peut prendre toute valeur dans un intervalle.\n",
    "\n",
    "**Fonction de densit√© de probabilit√© (PDF)** :\n",
    "$$P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx$$\n",
    "\n",
    "**Propri√©t√©s** :\n",
    "- $f_X(x) \\geq 0$ pour tout $x$\n",
    "- $\\int_{-\\infty}^{\\infty} f_X(x) dx = 1$\n",
    "- $P(X = x) = 0$ pour toute valeur $x$ (!)  \n",
    "\n",
    "**Fonction de r√©partition (CDF)** :\n",
    "$$F_X(x) = P(X \\leq x) = \\int_{-\\infty}^x f_X(t) dt$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemple de VA discr√®te : Lancer de d√©\n",
    "class VariableAleatoireDiscrete:\n",
    "    \"\"\"Repr√©sentation d'une variable al√©atoire discr√®te\"\"\"\n",
    "    \n",
    "    def __init__(self, valeurs: np.ndarray, probas: np.ndarray):\n",
    "        assert len(valeurs) == len(probas)\n",
    "        assert abs(np.sum(probas) - 1.0) < 1e-10\n",
    "        \n",
    "        self.valeurs = valeurs\n",
    "        self.probas = probas\n",
    "    \n",
    "    def pmf(self, x: float) -> float:\n",
    "        \"\"\"Fonction de masse P(X=x)\"\"\"\n",
    "        idx = np.where(self.valeurs == x)[0]\n",
    "        return self.probas[idx[0]] if len(idx) > 0 else 0.0\n",
    "    \n",
    "    def cdf(self, x: float) -> float:\n",
    "        \"\"\"Fonction de r√©partition P(X‚â§x)\"\"\"\n",
    "        return np.sum(self.probas[self.valeurs <= x])\n",
    "    \n",
    "    def esperance(self) -> float:\n",
    "        \"\"\"Esp√©rance E[X]\"\"\"\n",
    "        return np.sum(self.valeurs * self.probas)\n",
    "    \n",
    "    def variance(self) -> float:\n",
    "        \"\"\"Variance Var(X)\"\"\"\n",
    "        E_X = self.esperance()\n",
    "        return np.sum((self.valeurs - E_X)**2 * self.probas)\n",
    "    \n",
    "    def simuler(self, n: int) -> np.ndarray:\n",
    "        \"\"\"G√©n√®re n √©chantillons\"\"\"\n",
    "        return np.random.choice(self.valeurs, size=n, p=self.probas)\n",
    "\n",
    "# Exemple : D√© truqu√©\n",
    "de_truque = VariableAleatoireDiscrete(\n",
    "    valeurs=np.array([1, 2, 3, 4, 5, 6]),\n",
    "    probas=np.array([0.1, 0.1, 0.1, 0.2, 0.2, 0.3])  # Favorise 6\n",
    ")\n",
    "\n",
    "# Visualisation PMF et CDF\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# PMF\n",
    "ax1.bar(de_truque.valeurs, de_truque.probas, color='steelblue', \n",
    "        alpha=0.7, edgecolor='black', width=0.6)\n",
    "ax1.set_xlabel('Valeur x')\n",
    "ax1.set_ylabel('P(X = x)')\n",
    "ax1.set_title('PMF : Fonction de masse', fontweight='bold')\n",
    "ax1.set_xticks(de_truque.valeurs)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for x, p in zip(de_truque.valeurs, de_truque.probas):\n",
    "    ax1.text(x, p + 0.01, f'{p:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# CDF\n",
    "x_range = np.linspace(0, 7, 100)\n",
    "cdf_values = [de_truque.cdf(x) for x in x_range]\n",
    "\n",
    "ax2.plot(x_range, cdf_values, 'b-', linewidth=2)\n",
    "ax2.scatter(de_truque.valeurs, [de_truque.cdf(x) for x in de_truque.valeurs],\n",
    "           color='red', s=50, zorder=5)\n",
    "ax2.set_xlabel('Valeur x')\n",
    "ax2.set_ylabel('P(X ‚â§ x)')\n",
    "ax2.set_title('CDF : Fonction de r√©partition', fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_ylim(-0.05, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Caract√©ristiques du d√© truqu√© :\")\n",
    "print(f\"E[X] = {de_truque.esperance():.4f}\")\n",
    "print(f\"Var(X) = {de_truque.variance():.4f}\")\n",
    "print(f\"œÉ(X) = {np.sqrt(de_truque.variance()):.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Distributions de Probabilit√© Classiques\n",
    "\n",
    "### üé≤ Distributions Discr√®tes\n",
    "\n",
    "#### 1. Loi de Bernoulli : $X \\sim \\text{Ber}(p)$\n",
    "\n",
    "Mod√©lise une exp√©rience √† 2 r√©sultats (succ√®s/√©chec).\n",
    "\n",
    "- $X \\in \\{0, 1\\}$\n",
    "- $P(X = 1) = p$, $P(X = 0) = 1-p$\n",
    "- $E[X] = p$\n",
    "- $\\text{Var}(X) = p(1-p)$\n",
    "\n",
    "**Utilisation** : Classification binaire, dropout en neural networks\n",
    "\n",
    "#### 2. Loi Binomiale : $X \\sim \\mathcal{B}(n, p)$\n",
    "\n",
    "Nombre de succ√®s en $n$ essais ind√©pendants de Bernoulli.\n",
    "\n",
    "- $X \\in \\{0, 1, ..., n\\}$\n",
    "- $P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}$\n",
    "- $E[X] = np$\n",
    "- $\\text{Var}(X) = np(1-p)$\n",
    "\n",
    "**Utilisation** : Taux de conversion, A/B testing\n",
    "\n",
    "#### 3. Loi de Poisson : $X \\sim \\text{Poisson}(\\lambda)$\n",
    "\n",
    "Nombre d'√©v√©nements rares en un temps fix√©.\n",
    "\n",
    "- $X \\in \\{0, 1, 2, ...\\}$\n",
    "- $P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$\n",
    "- $E[X] = \\lambda$\n",
    "- $\\text{Var}(X) = \\lambda$\n",
    "\n",
    "**Utilisation** : Comptage d'√©v√©nements (clics, transactions, d√©faillances)\n",
    "\n",
    "### üìä Distributions Continues\n",
    "\n",
    "#### 4. Loi Normale (Gaussienne) : $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n",
    "\n",
    "**LA** distribution la plus importante en statistiques et ML !\n",
    "\n",
    "- $f_X(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$\n",
    "- $E[X] = \\mu$\n",
    "- $\\text{Var}(X) = \\sigma^2$\n",
    "\n",
    "**Propri√©t√©s remarquables** :\n",
    "- Sym√©trique autour de $\\mu$\n",
    "- 68% des valeurs dans $[\\mu - \\sigma, \\mu + \\sigma]$\n",
    "- 95% dans $[\\mu - 2\\sigma, \\mu + 2\\sigma]$\n",
    "- 99.7% dans $[\\mu - 3\\sigma, \\mu + 3\\sigma]$\n",
    "\n",
    "**Utilisation** : Mod√©lisation des erreurs, rendements financiers, processus gaussiens, initialisation des poids en DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualisation des distributions classiques\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# 1. Bernoulli\n",
    "p = 0.3\n",
    "x_bern = [0, 1]\n",
    "pmf_bern = [1-p, p]\n",
    "axes[0, 0].bar(x_bern, pmf_bern, color='steelblue', alpha=0.7, edgecolor='black', width=0.3)\n",
    "axes[0, 0].set_title(f'Bernoulli(p={p})', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('x')\n",
    "axes[0, 0].set_ylabel('P(X=x)')\n",
    "axes[0, 0].set_xticks([0, 1])\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Binomiale\n",
    "n, p = 20, 0.3\n",
    "x_binom = np.arange(0, n+1)\n",
    "pmf_binom = stats.binom.pmf(x_binom, n, p)\n",
    "axes[0, 1].bar(x_binom, pmf_binom, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title(f'Binomiale(n={n}, p={p})\\nE[X]={n*p:.1f}, œÉ={np.sqrt(n*p*(1-p)):.2f}', \n",
    "                     fontweight='bold')\n",
    "axes[0, 1].set_xlabel('x')\n",
    "axes[0, 1].set_ylabel('P(X=x)')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Poisson\n",
    "lambda_param = 5\n",
    "x_poisson = np.arange(0, 20)\n",
    "pmf_poisson = stats.poisson.pmf(x_poisson, lambda_param)\n",
    "axes[0, 2].bar(x_poisson, pmf_poisson, color='orange', alpha=0.7, edgecolor='black')\n",
    "axes[0, 2].set_title(f'Poisson(Œª={lambda_param})\\nE[X]=Var(X)={lambda_param}', \n",
    "                     fontweight='bold')\n",
    "axes[0, 2].set_xlabel('x')\n",
    "axes[0, 2].set_ylabel('P(X=x)')\n",
    "axes[0, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Normale standard\n",
    "x_norm = np.linspace(-4, 4, 200)\n",
    "pdf_norm = stats.norm.pdf(x_norm, 0, 1)\n",
    "axes[1, 0].plot(x_norm, pdf_norm, 'b-', linewidth=2, label='PDF')\n",
    "axes[1, 0].fill_between(x_norm, pdf_norm, alpha=0.3)\n",
    "\n",
    "# R√®gle 68-95-99.7\n",
    "axes[1, 0].axvline(-1, color='red', linestyle='--', alpha=0.5, label='Œº¬±œÉ (68%)')\n",
    "axes[1, 0].axvline(1, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].axvline(-2, color='orange', linestyle='--', alpha=0.5, label='Œº¬±2œÉ (95%)')\n",
    "axes[1, 0].axvline(2, color='orange', linestyle='--', alpha=0.5)\n",
    "\n",
    "axes[1, 0].set_title('Normale(Œº=0, œÉ¬≤=1)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('x')\n",
    "axes[1, 0].set_ylabel('f(x)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 5. Comparaison de normales\n",
    "params = [(0, 1), (0, 2), (2, 1)]\n",
    "colors = ['blue', 'red', 'green']\n",
    "for (mu, sigma), color in zip(params, colors):\n",
    "    pdf = stats.norm.pdf(x_norm, mu, sigma)\n",
    "    axes[1, 1].plot(x_norm, pdf, color=color, linewidth=2, \n",
    "                    label=f'Œº={mu}, œÉ={sigma}')\n",
    "\n",
    "axes[1, 1].set_title('Effet de Œº et œÉ', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('x')\n",
    "axes[1, 1].set_ylabel('f(x)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "# 6. Q-Q plot (Normal)\n",
    "sample = np.random.normal(0, 1, 1000)\n",
    "stats.probplot(sample, dist=\"norm\", plot=axes[1, 2])\n",
    "axes[1, 2].set_title('Q-Q Plot (test de normalit√©)', fontweight='bold')\n",
    "axes[1, 2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ü§ñ APPLICATION ML : √âchantillonnage et g√©n√©ration de donn√©es\n",
    "print(\"ü§ñ ESSENTIEL EN ML : G√©n√©ration de donn√©es synth√©tiques\\n\")\n",
    "\n",
    "# 1. Classification binaire avec donn√©es gaussiennes\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Classe 0 : N(Œº‚ÇÄ, Œ£‚ÇÄ)\n",
    "mean_0 = np.array([0, 0])\n",
    "cov_0 = np.array([[1, 0.5], [0.5, 1]])\n",
    "X_0 = np.random.multivariate_normal(mean_0, cov_0, n_samples)\n",
    "\n",
    "# Classe 1 : N(Œº‚ÇÅ, Œ£‚ÇÅ)\n",
    "mean_1 = np.array([3, 3])\n",
    "cov_1 = np.array([[1, -0.3], [-0.3, 1]])\n",
    "X_1 = np.random.multivariate_normal(mean_1, cov_1, n_samples)\n",
    "\n",
    "# Visualisation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.scatter(X_0[:, 0], X_0[:, 1], alpha=0.6, label='Classe 0', s=30)\n",
    "ax1.scatter(X_1[:, 0], X_1[:, 1], alpha=0.6, label='Classe 1', s=30)\n",
    "ax1.set_xlabel('Feature 1')\n",
    "ax1.set_ylabel('Feature 2')\n",
    "ax1.set_title('Dataset de classification g√©n√©r√©', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.axis('equal')\n",
    "\n",
    "# 2. Histogrammes marginaux\n",
    "ax2.hist(X_0[:, 0], bins=30, alpha=0.5, label='Classe 0 - Feature 1', density=True)\n",
    "ax2.hist(X_1[:, 0], bins=30, alpha=0.5, label='Classe 1 - Feature 1', density=True)\n",
    "\n",
    "# Overlay des densit√©s th√©oriques\n",
    "x_range = np.linspace(-3, 6, 200)\n",
    "ax2.plot(x_range, stats.norm.pdf(x_range, mean_0[0], np.sqrt(cov_0[0, 0])), \n",
    "         'b-', linewidth=2, label='Th√©orique Classe 0')\n",
    "ax2.plot(x_range, stats.norm.pdf(x_range, mean_1[0], np.sqrt(cov_1[0, 0])), \n",
    "         'r-', linewidth=2, label='Th√©orique Classe 1')\n",
    "\n",
    "ax2.set_xlabel('Feature 1')\n",
    "ax2.set_ylabel('Densit√©')\n",
    "ax2.set_title('Distributions marginales', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Applications en ML :\")\n",
    "print(\"  ‚Ä¢ G√©n√©ration de datasets synth√©tiques pour tests\")\n",
    "print(\"  ‚Ä¢ Augmentation de donn√©es (data augmentation)\")\n",
    "print(\"  ‚Ä¢ GANs (Generative Adversarial Networks)\")\n",
    "print(\"  ‚Ä¢ VAEs (Variational Autoencoders)\")\n",
    "print(\"  ‚Ä¢ Simulation de Monte Carlo\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Esp√©rance, Variance et Moments\n",
    "\n",
    "### üìê Esp√©rance math√©matique\n",
    "\n",
    "L'**esp√©rance** $E[X]$ est la \"moyenne pond√©r√©e\" des valeurs.\n",
    "\n",
    "**Cas discret** :\n",
    "$$E[X] = \\sum_{x} x \\cdot P(X = x)$$\n",
    "\n",
    "**Cas continu** :\n",
    "$$E[X] = \\int_{-\\infty}^{\\infty} x \\cdot f_X(x) dx$$\n",
    "\n",
    "**Propri√©t√©s** :\n",
    "- Lin√©arit√© : $E[aX + b] = aE[X] + b$\n",
    "- Additivit√© : $E[X + Y] = E[X] + E[Y]$ (toujours !)\n",
    "- Si $X, Y$ ind√©pendantes : $E[XY] = E[X]E[Y]$\n",
    "\n",
    "### üìä Variance\n",
    "\n",
    "La **variance** mesure la dispersion autour de la moyenne.\n",
    "\n",
    "$$\\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$\n",
    "\n",
    "**√âcart-type** :\n",
    "$$\\sigma_X = \\sqrt{\\text{Var}(X)}$$\n",
    "\n",
    "**Propri√©t√©s** :\n",
    "- $\\text{Var}(aX + b) = a^2 \\text{Var}(X)$\n",
    "- Si $X, Y$ ind√©pendantes : $\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)$\n",
    "\n",
    "### üìà Moments d'ordre sup√©rieur\n",
    "\n",
    "**Moment d'ordre $n$** :\n",
    "$$E[X^n]$$\n",
    "\n",
    "**Moment centr√© d'ordre $n$** :\n",
    "$$E[(X - E[X])^n]$$\n",
    "\n",
    "**Skewness (asym√©trie)** :\n",
    "$$\\gamma_1 = \\frac{E[(X - \\mu)^3]}{\\sigma^3}$$\n",
    "\n",
    "**Kurtosis (aplatissement)** :\n",
    "$$\\gamma_2 = \\frac{E[(X - \\mu)^4]}{\\sigma^4}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calcul et visualisation des moments\n",
    "def calculer_moments(data: np.ndarray) -> dict:\n",
    "    \"\"\"Calcule les moments statistiques d'un √©chantillon\"\"\"\n",
    "    return {\n",
    "        'mean': np.mean(data),\n",
    "        'variance': np.var(data, ddof=1),  # ddof=1 pour variance non biais√©e\n",
    "        'std': np.std(data, ddof=1),\n",
    "        'skewness': stats.skew(data),\n",
    "        'kurtosis': stats.kurtosis(data)\n",
    "    }\n",
    "\n",
    "# G√©n√©ration de diff√©rentes distributions\n",
    "np.random.seed(42)\n",
    "n = 10000\n",
    "\n",
    "distributions = {\n",
    "    'Normal(0,1)': np.random.normal(0, 1, n),\n",
    "    'Exponentielle(1)': np.random.exponential(1, n),\n",
    "    'Uniforme(-2,2)': np.random.uniform(-2, 2, n),\n",
    "    'Chi¬≤(5)': np.random.chisquare(5, n)\n",
    "}\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, data) in enumerate(distributions.items()):\n",
    "    moments = calculer_moments(data)\n",
    "    \n",
    "    # Histogramme\n",
    "    axes[i].hist(data, bins=50, density=True, alpha=0.7, \n",
    "                edgecolor='black', color='steelblue')\n",
    "    \n",
    "    # Ligne verticale pour la moyenne\n",
    "    axes[i].axvline(moments['mean'], color='red', linestyle='--', \n",
    "                   linewidth=2, label=f\"Œº = {moments['mean']:.2f}\")\n",
    "    \n",
    "    # Zone Œº ¬± œÉ\n",
    "    axes[i].axvspan(moments['mean'] - moments['std'], \n",
    "                   moments['mean'] + moments['std'], \n",
    "                   alpha=0.2, color='green', label=f\"Œº¬±œÉ ({moments['std']:.2f})\")\n",
    "    \n",
    "    # Annotations\n",
    "    textstr = f\"Skewness: {moments['skewness']:.2f}\\nKurtosis: {moments['kurtosis']:.2f}\"\n",
    "    axes[i].text(0.65, 0.95, textstr, transform=axes[i].transAxes,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    axes[i].set_title(name, fontweight='bold')\n",
    "    axes[i].set_xlabel('Valeur')\n",
    "    axes[i].set_ylabel('Densit√©')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tableau r√©capitulatif\n",
    "print(\"\\nüìä Tableau des moments :\\n\")\n",
    "df_moments = pd.DataFrame({\n",
    "    name: calculer_moments(data) \n",
    "    for name, data in distributions.items()\n",
    "}).T\n",
    "\n",
    "print(df_moments.round(3))\n",
    "\n",
    "print(\"\\nüí° Interpr√©tation :\")\n",
    "print(\"  ‚Ä¢ Skewness > 0 : Queue √† droite (asym√©trie positive)\")\n",
    "print(\"  ‚Ä¢ Skewness < 0 : Queue √† gauche (asym√©trie n√©gative)\")\n",
    "print(\"  ‚Ä¢ Kurtosis > 0 : Plus 'pointue' que normale (queues lourdes)\")\n",
    "print(\"  ‚Ä¢ Kurtosis < 0 : Plus 'plate' que normale (queues l√©g√®res)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Covariance et Corr√©lation\n",
    "\n",
    "### üîó Covariance\n",
    "\n",
    "La **covariance** mesure la relation lin√©aire entre deux variables.\n",
    "\n",
    "$$\\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]$$\n",
    "\n",
    "**Propri√©t√©s** :\n",
    "- $\\text{Cov}(X, X) = \\text{Var}(X)$\n",
    "- $\\text{Cov}(X, Y) = \\text{Cov}(Y, X)$ (sym√©trie)\n",
    "- $\\text{Cov}(aX + b, Y) = a\\text{Cov}(X, Y)$\n",
    "- Si $X, Y$ ind√©pendantes : $\\text{Cov}(X, Y) = 0$ (r√©ciproque fausse !)\n",
    "\n",
    "**Variance d'une somme** :\n",
    "$$\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X, Y)$$\n",
    "\n",
    "### üìê Corr√©lation (de Pearson)\n",
    "\n",
    "La **corr√©lation** est la covariance normalis√©e :\n",
    "\n",
    "$$\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}$$\n",
    "\n",
    "**Propri√©t√©s** :\n",
    "- $-1 \\leq \\rho \\leq 1$\n",
    "- $\\rho = 1$ : corr√©lation lin√©aire parfaite positive\n",
    "- $\\rho = -1$ : corr√©lation lin√©aire parfaite n√©gative\n",
    "- $\\rho = 0$ : pas de corr√©lation lin√©aire (‚ö†Ô∏è peut y avoir d√©pendance non-lin√©aire !)\n",
    "\n",
    "### üìä Matrice de covariance\n",
    "\n",
    "Pour un vecteur al√©atoire $\\mathbf{X} = (X_1, ..., X_n)$ :\n",
    "\n",
    "$$\\Sigma = \\begin{pmatrix}\n",
    "\\text{Var}(X_1) & \\text{Cov}(X_1, X_2) & \\cdots & \\text{Cov}(X_1, X_n) \\\\\n",
    "\\text{Cov}(X_2, X_1) & \\text{Var}(X_2) & \\cdots & \\text{Cov}(X_2, X_n) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}(X_n, X_1) & \\text{Cov}(X_n, X_2) & \\cdots & \\text{Var}(X_n)\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "**ESSENTIEL EN ML** : PCA, Gaussian Processes, portfolio optimization !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# G√©n√©ration de donn√©es corr√©l√©es\n",
    "def generer_donnees_correlees(n: int, rho: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    G√©n√®re deux variables corr√©l√©es avec coefficient œÅ\n",
    "    \"\"\"\n",
    "    # Matrice de covariance\n",
    "    cov = np.array([[1, rho], [rho, 1]])\n",
    "    \n",
    "    # G√©n√©ration\n",
    "    data = np.random.multivariate_normal([0, 0], cov, n)\n",
    "    return data[:, 0], data[:, 1]\n",
    "\n",
    "# Visualisation pour diff√©rentes corr√©lations\n",
    "correlations = [-0.9, -0.5, 0, 0.5, 0.9]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "axes = axes.ravel()\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "for i, rho in enumerate(correlations):\n",
    "    X, Y = generer_donnees_correlees(n, rho)\n",
    "    \n",
    "    # Calcul de la corr√©lation empirique\n",
    "    rho_empirique = np.corrcoef(X, Y)[0, 1]\n",
    "    cov_empirique = np.cov(X, Y, ddof=1)[0, 1]\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[i].scatter(X, Y, alpha=0.5, s=20)\n",
    "    \n",
    "    # R√©gression lin√©aire\n",
    "    z = np.polyfit(X, Y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(X.min(), X.max(), 100)\n",
    "    axes[i].plot(x_line, p(x_line), 'r-', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    axes[i].set_title(f'œÅ th√©orique = {rho:.1f}\\nœÅ empirique = {rho_empirique:.3f}',\n",
    "                     fontweight='bold')\n",
    "    axes[i].set_xlabel('X')\n",
    "    axes[i].set_ylabel('Y')\n",
    "    axes[i].grid(alpha=0.3)\n",
    "    axes[i].axis('equal')\n",
    "    \n",
    "    # Annotation de la covariance\n",
    "    axes[i].text(0.05, 0.95, f'Cov(X,Y) = {cov_empirique:.3f}',\n",
    "                transform=axes[i].transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Cas non-lin√©aire (derni√®re subplot)\n",
    "X = np.random.uniform(-3, 3, n)\n",
    "Y = X**2 + np.random.normal(0, 1, n)\n",
    "rho_nonlinear = np.corrcoef(X, Y)[0, 1]\n",
    "\n",
    "axes[5].scatter(X, Y, alpha=0.5, s=20, color='purple')\n",
    "axes[5].set_title(f'D√©pendance NON-lin√©aire\\nœÅ = {rho_nonlinear:.3f} ‚âà 0 !',\n",
    "                 fontweight='bold', color='red')\n",
    "axes[5].set_xlabel('X')\n",
    "axes[5].set_ylabel('Y = X¬≤ + bruit')\n",
    "axes[5].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è ATTENTION :\")\n",
    "print(\"  ‚Ä¢ Corr√©lation = 0 ‚â† Ind√©pendance !\")\n",
    "print(\"  ‚Ä¢ La corr√©lation mesure UNIQUEMENT les relations lin√©aires\")\n",
    "print(\"  ‚Ä¢ Pour d√©pendances non-lin√©aires : mutual information, rank correlation, etc.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# üìà APPLICATION FINANCE : Matrice de corr√©lation d'un portefeuille\n",
    "print(\"üìà APPLICATION FINANCE : Analyse de corr√©lation de portefeuille\\n\")\n",
    "\n",
    "# Simulation de rendements d'actifs\n",
    "np.random.seed(42)\n",
    "n_days = 252  # 1 an de trading\n",
    "n_assets = 5\n",
    "\n",
    "# Matrice de corr√©lation r√©aliste\n",
    "rho_matrix = np.array([\n",
    "    [1.0, 0.7, 0.5, 0.3, 0.1],   # Tech stock\n",
    "    [0.7, 1.0, 0.6, 0.4, 0.2],   # Tech stock 2\n",
    "    [0.5, 0.6, 1.0, 0.2, 0.0],   # Consumer goods\n",
    "    [0.3, 0.4, 0.2, 1.0, -0.3],  # Energy\n",
    "    [0.1, 0.2, 0.0, -0.3, 1.0]   # Gold (safe haven)\n",
    "])\n",
    "\n",
    "# Volatilit√©s annuelles\n",
    "volatilities = np.array([0.25, 0.30, 0.20, 0.35, 0.15])  # 15-35% par an\n",
    "\n",
    "# Matrice de covariance (annualis√©e)\n",
    "cov_matrix = np.outer(volatilities, volatilities) * rho_matrix\n",
    "\n",
    "# Simulation des rendements quotidiens\n",
    "mean_returns = np.array([0.10, 0.12, 0.08, 0.15, 0.05]) / 252  # Rendements annuels ‚Üí quotidiens\n",
    "cov_daily = cov_matrix / 252  # Variance annuelle ‚Üí quotidienne\n",
    "\n",
    "returns = np.random.multivariate_normal(mean_returns, cov_daily, n_days)\n",
    "\n",
    "asset_names = ['Tech A', 'Tech B', 'Consumer', 'Energy', 'Gold']\n",
    "\n",
    "# Visualisation de la matrice de corr√©lation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Heatmap de corr√©lation\n",
    "im = ax1.imshow(rho_matrix, cmap='RdYlGn', vmin=-1, vmax=1, aspect='auto')\n",
    "ax1.set_xticks(range(n_assets))\n",
    "ax1.set_yticks(range(n_assets))\n",
    "ax1.set_xticklabels(asset_names, rotation=45, ha='right')\n",
    "ax1.set_yticklabels(asset_names)\n",
    "ax1.set_title('Matrice de Corr√©lation', fontweight='bold')\n",
    "\n",
    "# Annotations\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_assets):\n",
    "        text = ax1.text(j, i, f'{rho_matrix[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=ax1, label='Corr√©lation')\n",
    "\n",
    "# √âvolution des rendements cumul√©s\n",
    "cumulative_returns = (1 + returns).cumprod(axis=0)\n",
    "for i, name in enumerate(asset_names):\n",
    "    ax2.plot(cumulative_returns[:, i], label=name, linewidth=2)\n",
    "\n",
    "ax2.set_xlabel('Jours de trading')\n",
    "ax2.set_ylabel('Valeur du portefeuille (base 1.0)')\n",
    "ax2.set_title('√âvolution des actifs', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcul du risque de portefeuille\n",
    "weights = np.array([0.3, 0.2, 0.2, 0.2, 0.1])  # R√©partition du portefeuille\n",
    "\n",
    "# Variance du portefeuille : w^T Œ£ w\n",
    "portfolio_variance = weights @ cov_matrix @ weights\n",
    "portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "\n",
    "# Rendement attendu du portefeuille\n",
    "annual_returns = np.array([0.10, 0.12, 0.08, 0.15, 0.05])\n",
    "portfolio_return = weights @ annual_returns\n",
    "\n",
    "print(f\"\\nüìä Analyse du portefeuille :\")\n",
    "print(f\"\\nR√©partition : {dict(zip(asset_names, weights))}\")\n",
    "print(f\"\\nRendement attendu : {portfolio_return*100:.2f}% par an\")\n",
    "print(f\"Volatilit√© (risque) : {portfolio_volatility*100:.2f}% par an\")\n",
    "print(f\"Ratio de Sharpe (simplifi√©) : {portfolio_return/portfolio_volatility:.2f}\")\n",
    "\n",
    "print(\"\\nüí° Effet de diversification :\")\n",
    "print(f\"  ‚Ä¢ Gold a corr√©lation n√©gative avec Energy (-0.3)\")\n",
    "print(f\"  ‚Ä¢ ‚áí R√©duit le risque global du portefeuille\")\n",
    "print(f\"  ‚Ä¢ Tech A et Tech B tr√®s corr√©l√©es (0.7) ‚áí Moins de diversification\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ R√©sum√© du Chapitre\n",
    "\n",
    "### ‚úÖ Concepts cl√©s ma√Ætris√©s\n",
    "\n",
    "1. **Espace de probabilit√©** : (Œ©, F, P)\n",
    "2. **Probabilit√©s conditionnelles** : P(A|B) = P(A‚à©B) / P(B)\n",
    "3. **Th√©or√®me de Bayes** : P(A|B) = P(B|A)P(A) / P(B)\n",
    "4. **Variables al√©atoires** : Discr√®tes (PMF) et continues (PDF)\n",
    "5. **Distributions classiques** :\n",
    "   - Bernoulli, Binomiale, Poisson\n",
    "   - **Normale** (la plus importante !)\n",
    "6. **Moments** : Esp√©rance, variance, skewness, kurtosis\n",
    "7. **Corr√©lation** : Mesure de d√©pendance lin√©aire\n",
    "\n",
    "### ü§ñ Applications en ML et Finance\n",
    "\n",
    "| Concept | ML Application | Finance Application |\n",
    "|---------|---------------|---------------------|\n",
    "| Bayes | Naive Bayes, Bayesian ML | Filtrage de signaux |\n",
    "| Normale | Initialisation poids, erreurs | Rendements, Black-Scholes |\n",
    "| Covariance | PCA, feature correlation | Diversification, risque |\n",
    "| √âchantillonnage | Data augmentation, GANs | Monte Carlo, simulation |\n",
    "| Moments | Feature engineering | Distribution analysis |\n",
    "\n",
    "### üìö Pour aller plus loin\n",
    "\n",
    "- ‚úÖ **Exercices** : [exercices_07_probabilites.ipynb](../envs/phase_1_math/exercices_07_probabilites.ipynb)\n",
    "- ‚úÖ **Projet** : [projet_07_monte_carlo.ipynb](../envs/phase_1_math/projet_07_monte_carlo.ipynb)\n",
    "- üìñ **Chapitre suivant** : Statistiques inf√©rentielles\n",
    "\n",
    "---\n",
    "\n",
    "### üéì Points essentiels √† retenir\n",
    "\n",
    "1. üåü **Th√©or√®me de Bayes = c≈ìur du ML bay√©sien**\n",
    "2. üìä **Loi normale = distribution fondamentale**\n",
    "3. üîó **Corr√©lation ‚â† Causalit√©** (et corr√©lation = 0 ‚â† ind√©pendance)\n",
    "4. üé≤ **√âchantillonnage = g√©n√©ration de donn√©es synth√©tiques**\n",
    "5. üìà **Matrice de covariance = cl√© de la diversification**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
