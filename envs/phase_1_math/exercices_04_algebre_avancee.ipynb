{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Exercices - Alg√®bre Lin√©aire Avanc√©e\n",
    "\n",
    "Bienvenue dans tes exercices d'alg√®bre lin√©aire avanc√©e ! üöÄ\n",
    "\n",
    "## üìù Instructions G√©n√©rales\n",
    "\n",
    "- **√âcris ton code Python** dans les cellules vides pr√©vues\n",
    "- **Utilise NumPy et scipy** pour tous les calculs\n",
    "- **Ex√©cute chaque cellule** avec `Shift + Enter` pour v√©rifier ta r√©ponse\n",
    "- **Les indices** sont dans les cellules comment√©es (`# INDICE :`)\n",
    "- **Visualise** quand c'est possible avec Matplotlib\n",
    "\n",
    "## üéØ Objectifs d'Apprentissage\n",
    "\n",
    "√Ä la fin de ces exercices, tu seras capable de :\n",
    "- ‚úÖ Identifier les sous-espaces vectoriels\n",
    "- ‚úÖ Tester l'ind√©pendance lin√©aire\n",
    "- ‚úÖ Calculer et interpr√©ter le rang d'une matrice\n",
    "- ‚úÖ Ma√Ætriser les valeurs propres et vecteurs propres\n",
    "- ‚úÖ Appliquer la d√©composition SVD\n",
    "- ‚úÖ Utiliser PCA pour r√©duire la dimension\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Conseil :** Ces concepts sont au c≈ìur du Machine Learning. Prends ton temps pour bien comprendre !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires pour tous les exercices\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import linalg\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"Imports r√©ussis ! ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Section 1 : Espaces Vectoriels et Sous-Espaces\n",
    "\n",
    "Dans cette section, tu vas explorer les espaces vectoriels et leurs sous-espaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1.1 : V√©rifier un Sous-Espace\n",
    "\n",
    "**Consigne :** Un sous-ensemble $W$ de $\\mathbb{R}^3$ est un sous-espace vectoriel s'il v√©rifie :\n",
    "1. Contient le vecteur nul $\\vec{0}$\n",
    "2. Ferm√© par addition : $\\vec{u}, \\vec{v} \\in W \\Rightarrow \\vec{u} + \\vec{v} \\in W$\n",
    "3. Ferm√© par multiplication scalaire : $\\vec{v} \\in W, \\alpha \\in \\mathbb{R} \\Rightarrow \\alpha\\vec{v} \\in W$\n",
    "\n",
    "V√©rifie si les ensembles suivants sont des sous-espaces de $\\mathbb{R}^3$ :\n",
    "\n",
    "1. $W_1 = \\{(x, y, 0) : x, y \\in \\mathbb{R}\\}$ (le plan xy)\n",
    "2. $W_2 = \\{(x, y, z) : x + y + z = 1\\}$ (un plan ne passant PAS par l'origine)\n",
    "3. $W_3 = \\{(x, 2x, 3x) : x \\in \\mathbb{R}\\}$ (une ligne passant par l'origine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1.1 : √âcris ton code ici\n",
    "\n",
    "# INDICE : Pour chaque ensemble, teste :\n",
    "# 1. (0, 0, 0) est dedans ?\n",
    "# 2. Prends deux vecteurs au hasard, leur somme est dedans ?\n",
    "# 3. Multiplie un vecteur par un scalaire, le r√©sultat est dedans ?\n",
    "\n",
    "def test_subspace_W1():\n",
    "    \"\"\"Teste si W1 = {(x, y, 0)} est un sous-espace.\"\"\"\n",
    "    # Ton code ici\n",
    "    pass\n",
    "\n",
    "def test_subspace_W2():\n",
    "    \"\"\"Teste si W2 = {(x, y, z) : x+y+z=1} est un sous-espace.\"\"\"\n",
    "    # Ton code ici\n",
    "    pass\n",
    "\n",
    "def test_subspace_W3():\n",
    "    \"\"\"Teste si W3 = {(x, 2x, 3x)} est un sous-espace.\"\"\"\n",
    "    # Ton code ici\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1.2 : Dimension d'un Sous-Espace\n",
    "\n",
    "**Consigne :** Pour chaque sous-espace, d√©termine sa dimension :\n",
    "\n",
    "1. $W_1 = \\text{span}\\{\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}\\}$\n",
    "2. $W_2 = \\text{span}\\{\\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}\\}$\n",
    "3. $W_3 = \\text{span}\\{\\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}, \\begin{bmatrix} 2 \\\\ 0 \\\\ 2 \\end{bmatrix}\\}$\n",
    "\n",
    "Utilise le rang de la matrice form√©e par les vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1.2 : √âcris ton code ici\n",
    "\n",
    "# INDICE : \n",
    "# - Forme une matrice avec les vecteurs en colonnes\n",
    "# - Calcule le rang avec np.linalg.matrix_rank()\n",
    "# - Rang = dimension du sous-espace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1.3 : Span de Vecteurs\n",
    "\n",
    "**Consigne :** Soit les vecteurs :\n",
    "$$\\vec{v_1} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix}, \\quad \\vec{v_2} = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3 \\end{bmatrix}, \\quad \\vec{v_3} = \\begin{bmatrix} 3 \\\\ 3 \\\\ 4 \\end{bmatrix}$$\n",
    "\n",
    "1. Le vecteur $\\vec{b} = \\begin{bmatrix} 5 \\\\ 5 \\\\ 7 \\end{bmatrix}$ est-il dans $\\text{span}\\{\\vec{v_1}, \\vec{v_2}, \\vec{v_3}\\}$ ?\n",
    "2. Si oui, trouve les coefficients $\\alpha, \\beta, \\gamma$ tels que $\\vec{b} = \\alpha\\vec{v_1} + \\beta\\vec{v_2} + \\gamma\\vec{v_3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1.3 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - R√©sous le syst√®me A*x = b o√π A = [v1 v2 v3]\n",
    "# - Utilise np.linalg.solve() ou np.linalg.lstsq()\n",
    "# - V√©rifie que A @ x donne bien b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1.4 : Intersection de Sous-Espaces\n",
    "\n",
    "**Consigne :** Trouve l'intersection de :\n",
    "- $W_1$ : le plan $x + y + z = 0$\n",
    "- $W_2$ : le plan $x - y = 0$\n",
    "\n",
    "Quelle est la dimension de l'intersection ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1.4 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - L'intersection = solutions du syst√®me :\n",
    "#   x + y + z = 0\n",
    "#   x - y = 0\n",
    "# - R√©sous et exprime les solutions en fonction d'un param√®tre libre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ Section 2 : Ind√©pendance Lin√©aire et Base\n",
    "\n",
    "Comprendre quand des vecteurs sont ind√©pendants et forment une base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2.1 : Test d'Ind√©pendance Lin√©aire\n",
    "\n",
    "**Consigne :** D√©termine si les vecteurs suivants sont lin√©airement ind√©pendants :\n",
    "\n",
    "1. $\\vec{v_1} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}, \\vec{v_2} = \\begin{bmatrix} 4 \\\\ 5 \\\\ 6 \\end{bmatrix}, \\vec{v_3} = \\begin{bmatrix} 7 \\\\ 8 \\\\ 9 \\end{bmatrix}$\n",
    "2. $\\vec{v_1} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\vec{v_2} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\vec{v_3} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$\n",
    "3. $\\vec{v_1} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\vec{v_2} = \\begin{bmatrix} 2 \\\\ 4 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2.1 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Forme une matrice A avec les vecteurs en colonnes\n",
    "# - Si rang(A) = nombre de vecteurs ‚Üí ind√©pendants\n",
    "# - Sinon ‚Üí d√©pendants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2.2 : Trouver une Base\n",
    "\n",
    "**Consigne :** Parmi les vecteurs suivants, trouve un sous-ensemble formant une base de $\\mathbb{R}^3$ :\n",
    "\n",
    "$$\\vec{v_1} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}, \\vec{v_2} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\vec{v_3} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 2 \\end{bmatrix}, \\vec{v_4} = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2.2 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Une base de R¬≥ a exactement 3 vecteurs ind√©pendants\n",
    "# - Teste diff√©rentes combinaisons de 3 vecteurs\n",
    "# - V√©rifie leur ind√©pendance avec le rang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2.3 : Compl√©ter une Base\n",
    "\n",
    "**Consigne :** Soit les vecteurs ind√©pendants :\n",
    "$$\\vec{v_1} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\vec{v_2} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}$$\n",
    "\n",
    "Trouve un vecteur $\\vec{v_3}$ tel que $\\{\\vec{v_1}, \\vec{v_2}, \\vec{v_3}\\}$ forme une base de $\\mathbb{R}^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2.3 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - v3 doit √™tre lin√©airement ind√©pendant de v1 et v2\n",
    "# - Teste avec (0, 0, 1) par exemple\n",
    "# - V√©rifie que le rang de [v1 v2 v3] = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2.4 : Coordonn√©es dans une Base\n",
    "\n",
    "**Consigne :** Soit la base $B = \\{\\vec{b_1}, \\vec{b_2}\\}$ de $\\mathbb{R}^2$ o√π :\n",
    "$$\\vec{b_1} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\quad \\vec{b_2} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$$\n",
    "\n",
    "Trouve les coordonn√©es du vecteur $\\vec{v} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}$ dans la base $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2.4 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - R√©sous v = Œ±*b1 + Œ≤*b2\n",
    "# - Forme le syst√®me matriciel [b1 b2] @ [Œ±, Œ≤]·µÄ = v\n",
    "# - R√©sous avec np.linalg.solve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2.5 : Dimension d'un Espace de Polyn√¥mes\n",
    "\n",
    "**Consigne :** L'espace des polyn√¥mes de degr√© ‚â§ 2 est un espace vectoriel.\n",
    "\n",
    "1. Donne une base de cet espace\n",
    "2. Quelle est sa dimension ?\n",
    "3. Exprime le polyn√¥me $p(x) = 3x^2 - 2x + 5$ dans cette base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2.5 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Base standard : {1, x, x¬≤}\n",
    "# - Dimension = 3\n",
    "# - Coordonn√©es = coefficients [5, -2, 3]\n",
    "# - Repr√©sente les polyn√¥mes comme vecteurs dans R¬≥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ Section 3 : Rang d'une Matrice\n",
    "\n",
    "Comprendre et calculer le rang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3.1 : Calcul du Rang\n",
    "\n",
    "**Consigne :** Calcule le rang des matrices suivantes :\n",
    "\n",
    "1. $A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{bmatrix}$\n",
    "2. $B = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$\n",
    "3. $C = \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\\\ 3 & 6 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3.1 : √âcris ton code ici\n",
    "\n",
    "# INDICE : np.linalg.matrix_rank(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3.2 : Rang et Inversibilit√©\n",
    "\n",
    "**Consigne :** Pour chaque matrice, d√©termine :\n",
    "1. Son rang\n",
    "2. Si elle est inversible\n",
    "3. Son d√©terminant\n",
    "\n",
    "Matrices :\n",
    "- $A = \\begin{bmatrix} 2 & 1 \\\\ 4 & 3 \\end{bmatrix}$\n",
    "- $B = \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\end{bmatrix}$\n",
    "\n",
    "V√©rifie la relation : inversible ‚ü∫ rang plein ‚ü∫ det ‚â† 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3.2 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - rang : np.linalg.matrix_rank()\n",
    "# - det : np.linalg.det()\n",
    "# - inversible si rang = n et det ‚â† 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3.3 : Rang et Syst√®mes Lin√©aires\n",
    "\n",
    "**Consigne :** Soit le syst√®me $A\\vec{x} = \\vec{b}$ avec :\n",
    "$$A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\\\ 1 & 1 & 1 \\end{bmatrix}, \\quad \\vec{b} = \\begin{bmatrix} 6 \\\\ 12 \\\\ 3 \\end{bmatrix}$$\n",
    "\n",
    "1. Calcule le rang de $A$\n",
    "2. Calcule le rang de $[A | \\vec{b}]$ (matrice augment√©e)\n",
    "3. Le syst√®me a-t-il une solution ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3.3 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Matrice augment√©e : np.column_stack([A, b])\n",
    "# - Si rang(A) = rang([A|b]) ‚Üí solution existe\n",
    "# - Si rang(A) < rang([A|b]) ‚Üí pas de solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3.4 : Rang d'un Produit Matriciel\n",
    "\n",
    "**Consigne :** V√©rifie la propri√©t√© : $\\text{rang}(AB) \\leq \\min(\\text{rang}(A), \\text{rang}(B))$\n",
    "\n",
    "Avec :\n",
    "$$A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3.4 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Calcule rang(A), rang(B), rang(A @ B)\n",
    "# - V√©rifie l'in√©galit√©\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3.5 : Approximation de Rang Faible\n",
    "\n",
    "**Consigne :** Cr√©e une matrice 5√ó5 al√©atoire et approxime-la par des matrices de rang 1, 2, 3.\n",
    "\n",
    "Utilise SVD et mesure l'erreur de Frobenius pour chaque approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3.5 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - U, s, Vt = np.linalg.svd(A)\n",
    "# - Pour rang k : garde seulement les k premi√®res valeurs singuli√®res\n",
    "# - Erreur : np.linalg.norm(A - A_k, 'fro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ Section 4 : Valeurs Propres et Vecteurs Propres\n",
    "\n",
    "Ma√Ætriser eigenvalues et eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4.1 : Calcul des Valeurs Propres\n",
    "\n",
    "**Consigne :** Calcule les valeurs propres et vecteurs propres de :\n",
    "\n",
    "1. $A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$\n",
    "2. $B = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}$ (matrice de rotation 90¬∞)\n",
    "3. $C = \\begin{bmatrix} 2 & 0 & 0 \\\\ 0 & 3 & 0 \\\\ 0 & 0 & 5 \\end{bmatrix}$\n",
    "\n",
    "V√©rifie que $A\\vec{v} = \\lambda \\vec{v}$ pour chaque paire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4.1 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "# - V√©rification : np.allclose(A @ v, Œª * v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4.2 : Propri√©t√©s des Valeurs Propres\n",
    "\n",
    "**Consigne :** Pour la matrice $A = \\begin{bmatrix} 4 & 2 \\\\ 1 & 3 \\end{bmatrix}$, v√©rifie :\n",
    "\n",
    "1. $\\sum \\lambda_i = \\text{tr}(A)$\n",
    "2. $\\prod \\lambda_i = \\det(A)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4.2 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - np.trace(A) pour la trace\n",
    "# - np.linalg.det(A) pour le d√©terminant\n",
    "# - np.sum(eigenvalues) et np.prod(eigenvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4.3 : Diagonalisation\n",
    "\n",
    "**Consigne :** Diagonalise la matrice $A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}$\n",
    "\n",
    "Trouve $P$ et $D$ tels que $A = PDP^{-1}$ et v√©rifie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4.3 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - P = matrice des vecteurs propres (colonnes)\n",
    "# - D = matrice diagonale des valeurs propres\n",
    "# - V√©rifie : A = P @ D @ np.linalg.inv(P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4.4 : Puissance Matricielle\n",
    "\n",
    "**Consigne :** Calcule $A^{50}$ pour $A = \\begin{bmatrix} 0.8 & 0.2 \\\\ 0.3 & 0.7 \\end{bmatrix}$ \n",
    "\n",
    "Utilise la diagonalisation pour acc√©l√©rer le calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4.4 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Si A = P @ D @ P‚Åª¬π\n",
    "# - Alors A‚Åø = P @ D‚Åø @ P‚Åª¬π\n",
    "# - Et D‚Åø = diag(Œª‚ÇÅ‚Åø, Œª‚ÇÇ‚Åø, ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4.5 : Matrices Sym√©triques\n",
    "\n",
    "**Consigne :** Pour la matrice sym√©trique $A = \\begin{bmatrix} 5 & 2 & 0 \\\\ 2 & 6 & 2 \\\\ 0 & 2 & 7 \\end{bmatrix}$ :\n",
    "\n",
    "1. Calcule ses valeurs propres\n",
    "2. V√©rifie qu'elles sont toutes r√©elles\n",
    "3. V√©rifie que les vecteurs propres sont orthogonaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4.5 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Valeurs propres r√©elles : np.all(np.isreal(eigenvalues))\n",
    "# - Orthogonalit√© : v1 @ v2 ‚âà 0 pour i ‚â† j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4.6 : Application - Stabilit√© d'un Syst√®me\n",
    "\n",
    "**Consigne :** Un syst√®me dynamique $\\vec{x}_{t+1} = A\\vec{x}_t$ est stable si toutes les valeurs propres de $A$ ont un module < 1.\n",
    "\n",
    "D√©termine si le syst√®me avec $A = \\begin{bmatrix} 0.5 & 0.2 \\\\ 0.1 & 0.6 \\end{bmatrix}$ est stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4.6 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Calcule les valeurs propres\n",
    "# - Module : np.abs(Œª)\n",
    "# - Stable si np.all(np.abs(eigenvalues) < 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Section 5 : D√©composition SVD\n",
    "\n",
    "Ma√Ætriser la SVD et ses applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5.1 : SVD Basique\n",
    "\n",
    "**Consigne :** Calcule la SVD de $A = \\begin{bmatrix} 3 & 1 & 1 \\\\ 1 & 3 & 1 \\end{bmatrix}$\n",
    "\n",
    "1. Trouve $U$, $\\Sigma$, $V^T$\n",
    "2. V√©rifie que $A = U \\Sigma V^T$\n",
    "3. Affiche les valeurs singuli√®res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5.1 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - U, s, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "# - Reconstruire Œ£ : np.diag(s)\n",
    "# - V√©rifier : np.allclose(A, U @ Sigma @ Vt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5.2 : Approximation de Rang k\n",
    "\n",
    "**Consigne :** Cr√©e une matrice 10√ó10 al√©atoire.\n",
    "\n",
    "1. Calcule sa SVD\n",
    "2. Cr√©e des approximations de rang 1, 2, 3, 5\n",
    "3. Pour chaque approximation, calcule l'erreur relative : $\\frac{\\|A - A_k\\|_F}{\\|A\\|_F}$\n",
    "4. Trace un graphique de l'erreur en fonction du rang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5.2 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Pour rang k : garde seulement s[:k]\n",
    "# - Norme de Frobenius : np.linalg.norm(A, 'fro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5.3 : SVD et Rang\n",
    "\n",
    "**Consigne :** V√©rifie que le rang d'une matrice = nombre de valeurs singuli√®res non nulles.\n",
    "\n",
    "Teste avec :\n",
    "$$A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\\\ 1 & 2 & 3 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5.3 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - rang = np.linalg.matrix_rank(A)\n",
    "# - nombre de œÉ > seuil : np.sum(s > 1e-10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5.4 : Pseudo-Inverse avec SVD\n",
    "\n",
    "**Consigne :** La pseudo-inverse de Moore-Penrose se calcule via SVD :\n",
    "$$A^+ = V \\Sigma^+ U^T$$\n",
    "\n",
    "o√π $\\Sigma^+$ a les inverses des valeurs singuli√®res non nulles.\n",
    "\n",
    "1. Impl√©mente cette formule\n",
    "2. Compare avec `np.linalg.pinv()`\n",
    "\n",
    "Teste avec $A = \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\end{bmatrix}$ (non inversible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5.4 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Pour Œ£‚Å∫ : inverse les œÉ > seuil, garde 0 pour les autres\n",
    "# - A‚Å∫ = Vt.T @ Sigma_plus @ U.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5.5 : Compression d'Image Simple\n",
    "\n",
    "**Consigne :** Cr√©e une \"image\" 20√ó20 avec un motif (par exemple un gradient).\n",
    "\n",
    "1. Applique SVD\n",
    "2. Reconstruit avec diff√©rents rangs (1, 3, 5, 10, 20)\n",
    "3. Visualise les reconstructions\n",
    "4. Calcule le taux de compression et l'erreur pour chaque rang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5.5 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Cr√©er un gradient : np.outer(np.linspace(0, 1, 20), np.linspace(0, 1, 20))\n",
    "# - Taux de compression : (k*(m+n+1)) / (m*n)\n",
    "# - Visualiser avec plt.imshow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Section 6 : PCA (Principal Component Analysis)\n",
    "\n",
    "R√©duction de dimension en pratique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6.1 : PCA √† la Main\n",
    "\n",
    "**Consigne :** Impl√©mente PCA from scratch sur ces donn√©es :\n",
    "$$X = \\begin{bmatrix} 2 & 3 \\\\ 3 & 4 \\\\ 4 & 5 \\\\ 5 & 6 \\\\ 6 & 7 \\end{bmatrix}$$\n",
    "\n",
    "√âtapes :\n",
    "1. Centre les donn√©es\n",
    "2. Calcule la matrice de covariance\n",
    "3. Trouve les valeurs propres et vecteurs propres\n",
    "4. Projette sur la 1√®re composante principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 6.1 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Centrer : X - np.mean(X, axis=0)\n",
    "# - Covariance : np.cov(X_centered.T)\n",
    "# - Eigen : np.linalg.eig(cov)\n",
    "# - Projection : X_centered @ eigenvector[:, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6.2 : Variance Expliqu√©e\n",
    "\n",
    "**Consigne :** G√©n√®re 100 points 3D avec corr√©lations :\n",
    "- Feature 1 : al√©atoire\n",
    "- Feature 2 : Feature1 + bruit\n",
    "- Feature 3 : petit bruit seulement\n",
    "\n",
    "1. Applique PCA\n",
    "2. Calcule la variance expliqu√©e par chaque composante\n",
    "3. Trace le scree plot\n",
    "4. Combien de composantes pour capturer 95% de variance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 6.2 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Variance expliqu√©e : Œª·µ¢ / Œ£Œª‚±º\n",
    "# - Cumulative : np.cumsum(variance_ratios)\n",
    "# - Scree plot : barplot des variances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6.3 : PCA pour Visualisation\n",
    "\n",
    "**Consigne :** G√©n√®re 3 clusters en 5D avec `sklearn.datasets.make_blobs`.\n",
    "\n",
    "1. Applique PCA pour r√©duire √† 2D\n",
    "2. Visualise les clusters dans l'espace r√©duit\n",
    "3. Les clusters sont-ils bien s√©par√©s apr√®s PCA ?\n",
    "4. Quelle proportion de variance est conserv√©e ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 6.3 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - from sklearn.datasets import make_blobs\n",
    "# - X, y = make_blobs(n_samples=300, n_features=5, centers=3)\n",
    "# - Applique PCA puis scatter plot avec couleurs par cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6.4 : PCA vs SVD\n",
    "\n",
    "**Consigne :** Montre que PCA peut se calculer via SVD.\n",
    "\n",
    "Sur des donn√©es centr√©es :\n",
    "1. M√©thode 1 : PCA classique (covariance ‚Üí eigen)\n",
    "2. M√©thode 2 : SVD de $X_{centered}$\n",
    "3. Compare les composantes principales obtenues\n",
    "4. Compare les variances expliqu√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 6.4 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - SVD : U, s, Vt = np.linalg.svd(X_centered)\n",
    "# - Composantes principales = V (colonnes de Vt.T)\n",
    "# - Variances = s¬≤ / (n-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6.5 : Reconstruction avec PCA\n",
    "\n",
    "**Consigne :** Utilise le dataset Digits de sklearn (64 dimensions).\n",
    "\n",
    "1. Applique PCA avec diff√©rents nombres de composantes : 2, 5, 10, 20\n",
    "2. Reconstruit les images originales\n",
    "3. Visualise l'original et les reconstructions\n",
    "4. Calcule l'erreur de reconstruction pour chaque cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 6.5 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - from sklearn.datasets import load_digits\n",
    "# - Reconstruction : X_reconstructed = X_pca @ components.T + mean\n",
    "# - Erreur : np.mean((X - X_reconstructed)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6.6 : PCA sur Donn√©es Financi√®res\n",
    "\n",
    "**Consigne :** Simule les rendements de 10 actions corr√©l√©es.\n",
    "\n",
    "1. G√©n√®re une matrice de corr√©lation r√©aliste\n",
    "2. Simule les rendements avec cette corr√©lation\n",
    "3. Applique PCA\n",
    "4. Interpr√®te : combien de \"facteurs de march√©\" expliquent 80% du risque ?\n",
    "5. Visualise les loadings de la 1√®re composante (beta de chaque action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 6.6 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Corr√©lation : cr√©er une matrice semi-d√©finie positive\n",
    "# - Simulation : np.random.multivariate_normal()\n",
    "# - Loadings = eigenvectors = poids de chaque action dans chaque composante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£ Section 7 : Applications Int√©gr√©es\n",
    "\n",
    "Projets mini qui combinent plusieurs concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7.1 : Syst√®mes de Recommandation Simplifi√©\n",
    "\n",
    "**Consigne :** Cr√©e une matrice utilisateurs√ófilms (5√ó8) avec des notes (1-5, certaines manquantes = 0).\n",
    "\n",
    "1. Applique SVD avec rang 2\n",
    "2. Reconstruit la matrice\n",
    "3. Utilise les valeurs reconstruites pour pr√©dire les notes manquantes\n",
    "4. Compare avec les vraies notes si tu en avais cach√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 7.1 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Matrice incompl√®te : remplace certaines valeurs par 0\n",
    "# - SVD puis reconstruction de rang k\n",
    "# - Pr√©dictions = valeurs reconstruites aux positions manquantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7.2 : Analyse d'Images Avec Eigenfaces\n",
    "\n",
    "**Consigne :** Simule 20 \"visages\" comme matrices 10√ó10 al√©atoires mais corr√©l√©es.\n",
    "\n",
    "1. Applique PCA sur les visages (chaque visage = 1 ligne de 100 features)\n",
    "2. Visualise les 5 premi√®res \"eigenfaces\" (composantes principales)\n",
    "3. Reconstruit un visage avec diff√©rents nombres de composantes\n",
    "4. Montre la progression de la qualit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 7.2 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Chaque visage : vecteur de 100 dimensions (flatten de 10√ó10)\n",
    "# - Eigenfaces = vecteurs propres reshap√©s en 10√ó10\n",
    "# - Reconstruction : projection puis retour dans l'espace original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7.3 : D√©tection d'Anomalies avec PCA\n",
    "\n",
    "**Consigne :** G√©n√®re 100 points 3D normaux + 10 points anomalies (outliers).\n",
    "\n",
    "1. Applique PCA avec 2 composantes\n",
    "2. Calcule l'erreur de reconstruction pour chaque point\n",
    "3. Les anomalies ont une erreur plus √©lev√©e ?\n",
    "4. Visualise en 2D avec couleur selon l'erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 7.3 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Points normaux : np.random.randn()\n",
    "# - Anomalies : points tr√®s √©loign√©s\n",
    "# - Erreur de reconstruction : ||x - x_reconstructed||¬≤\n",
    "# - Seuil : points avec erreur √©lev√©e = anomalies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7.4 : Portfolio Optimization Simple\n",
    "\n",
    "**Consigne :** Simule les rendements de 5 actions.\n",
    "\n",
    "1. Calcule la matrice de covariance $\\Sigma$\n",
    "2. Pour un portefeuille √©quipond√©r√© $w = [0.2, 0.2, 0.2, 0.2, 0.2]$ :\n",
    "   - Calcule le risque : $\\sigma_p = \\sqrt{w^T \\Sigma w}$\n",
    "3. Utilise les vecteurs propres de $\\Sigma$ pour identifier les directions de risque max/min\n",
    "4. Trace un graphique rendement/risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 7.4 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Covariance : np.cov(returns.T)\n",
    "# - Risque portefeuille : np.sqrt(w @ Sigma @ w)\n",
    "# - Direction de risque max = vecteur propre avec Œª max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7.5 : Compression de Texte avec SVD\n",
    "\n",
    "**Consigne :** Cr√©e une matrice \"terme-document\" 20√ó10 (20 mots, 10 documents).\n",
    "\n",
    "1. Remplis avec des fr√©quences de mots simul√©es\n",
    "2. Applique SVD\n",
    "3. R√©duis √† rang 3 (3 \"topics\")\n",
    "4. Interpr√®te les composantes comme des sujets th√©matiques\n",
    "5. Projette les documents dans l'espace r√©duit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 7.5 : √âcris ton code ici\n",
    "\n",
    "# INDICE :\n",
    "# - Matrice : terme-document[i,j] = fr√©quence du mot i dans doc j\n",
    "# - Topics = composantes de V (colonnes)\n",
    "# - Document embeddings = U @ Œ£\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ F√©licitations !\n",
    "\n",
    "Tu as termin√© tous les exercices d'alg√®bre lin√©aire avanc√©e ! üéä\n",
    "\n",
    "### üìä Ce que tu as accompli :\n",
    "\n",
    "‚úÖ **Section 1** : Espaces vectoriels et sous-espaces ma√Ætris√©s\n",
    "‚úÖ **Section 2** : Ind√©pendance lin√©aire et bases comprises\n",
    "‚úÖ **Section 3** : Rang et ses implications domin√©s\n",
    "‚úÖ **Section 4** : Valeurs propres et diagonalisation acquises\n",
    "‚úÖ **Section 5** : SVD et approximation de rang faible ma√Ætris√©es\n",
    "‚úÖ **Section 6** : PCA pour r√©duction de dimension appliqu√©e\n",
    "‚úÖ **Section 7** : Applications concr√®tes r√©alis√©es\n",
    "\n",
    "### üöÄ Prochaines √âtapes :\n",
    "\n",
    "1. **V√©rifie tes r√©ponses** avec `solutions_04_algebre_avancee.ipynb`\n",
    "2. **Projet final** : `projet_04_compression_svd.ipynb` - Compression d'images r√©elles\n",
    "3. **Revois les concepts** o√π tu as eu des difficult√©s\n",
    "4. **Applique √† tes projets** : ces outils sont partout en ML/Finance !\n",
    "\n",
    "### üí° Points Cl√©s √† Retenir :\n",
    "\n",
    "- **Sous-espaces** : Structures lin√©aires qui simplifient les probl√®mes\n",
    "- **Ind√©pendance** : Crit√®re fondamental pour √©viter la redondance\n",
    "- **Rang** : Mesure de l'information ind√©pendante dans une matrice\n",
    "- **Eigenvalues** : R√©v√®lent les directions importantes d'une transformation\n",
    "- **SVD** : L'outil universel pour comprendre les matrices\n",
    "- **PCA** : R√©duction de dimension intelligente bas√©e sur la variance\n",
    "\n",
    "---\n",
    "\n",
    "**Tu es maintenant arm√© pour comprendre le Deep Learning et la Finance Quantitative en profondeur ! üí™üî•**\n",
    "\n",
    "**Continue avec le projet de compression SVD pour voir la magie op√©rer sur de vraies images ! üé®**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
