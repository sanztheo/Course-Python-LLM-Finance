{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2705 Solutions : Probabilit\u00e9s Fondamentales\n",
    "\n",
    "Solutions d\u00e9taill\u00e9es pour tous les exercices du chapitre 07.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Espaces de Probabilit\u00e9\n",
    "\n",
    "### Solution 1.1 : D\u00e9 \u00e9quilibr\u00e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# a) Espace \u00e9chantillonnal\n",
    "omega = {1, 2, 3, 4, 5, 6}\n",
    "print(\"a) \u03a9 =\", omega)\n",
    "\n",
    "# b) P(nombre pair)\n",
    "pair = {2, 4, 6}\n",
    "P_pair = len(pair) / len(omega)\n",
    "print(f\"\\nb) P(pair) = {len(pair)}/{len(omega)} = {P_pair}\")\n",
    "\n",
    "# c) P(nombre \u2265 4)\n",
    "sup_4 = {4, 5, 6}\n",
    "P_sup_4 = len(sup_4) / len(omega)\n",
    "print(f\"\\nc) P(\u22654) = {len(sup_4)}/{len(omega)} = {P_sup_4:.4f}\")\n",
    "\n",
    "# d) P(pair \u2229 \u22654)\n",
    "inter = pair & sup_4\n",
    "P_inter = len(inter) / len(omega)\n",
    "print(f\"\\nd) P(pair \u2229 \u22654) = P({inter}) = {P_inter:.4f}\")\n",
    "\n",
    "# e) P(pair \u222a \u22654)\n",
    "union = pair | sup_4\n",
    "P_union = len(union) / len(omega)\n",
    "print(f\"\\ne) P(pair \u222a \u22654) = P({union}) = {P_union:.4f}\")\n",
    "\n",
    "# V\u00e9rification formule\n",
    "print(f\"\\n\u2705 V\u00e9rification : P(A\u222aB) = P(A) + P(B) - P(A\u2229B)\")\n",
    "print(f\"   {P_union:.4f} = {P_pair:.4f} + {P_sup_4:.4f} - {P_inter:.4f}\")\n",
    "print(f\"   {P_union:.4f} = {P_pair + P_sup_4 - P_inter:.4f} \u2713\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1.2 : Pi\u00e8ce truqu\u00e9e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "P_pile = 0.6\n",
    "P_face = 0.4\n",
    "\n",
    "# a) Espace \u00e9chantillonnal pour 2 lancers\n",
    "omega = ['PP', 'PF', 'FP', 'FF']\n",
    "print(\"a) \u03a9 =\", omega)\n",
    "\n",
    "# b) P(2 piles) = P(PP)\n",
    "P_PP = P_pile * P_pile\n",
    "print(f\"\\nb) P(PP) = {P_pile} \u00d7 {P_pile} = {P_PP}\")\n",
    "\n",
    "# c) P(au moins 1 pile) = 1 - P(FF)\n",
    "P_FF = P_face * P_face\n",
    "P_au_moins_1_pile = 1 - P_FF\n",
    "print(f\"\\nc) P(au moins 1 pile) = 1 - P(FF) = 1 - {P_FF} = {P_au_moins_1_pile}\")\n",
    "\n",
    "# d) P(exactement 1 pile) = P(PF) + P(FP)\n",
    "P_PF = P_pile * P_face\n",
    "P_FP = P_face * P_pile\n",
    "P_exactement_1 = P_PF + P_FP\n",
    "print(f\"\\nd) P(exactement 1 pile) = P(PF) + P(FP) = {P_PF} + {P_FP} = {P_exactement_1}\")\n",
    "\n",
    "# V\u00e9rification : toutes les probas somment \u00e0 1\n",
    "total = P_PP + P_PF + P_FP + P_FF\n",
    "print(f\"\\n\u2705 V\u00e9rification : {P_PP} + {P_PF} + {P_FP} + {P_FF} = {total}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1.3 : Tirage de cartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Jeu de 52 cartes : 4 couleurs \u00d7 13 valeurs\n",
    "total_cartes = 52\n",
    "\n",
    "# a) P(As)\n",
    "nb_as = 4\n",
    "P_as = nb_as / total_cartes\n",
    "print(f\"a) P(As) = {nb_as}/{total_cartes} = {P_as:.4f}\")\n",
    "\n",
    "# b) P(C\u0153ur)\n",
    "nb_coeur = 13\n",
    "P_coeur = nb_coeur / total_cartes\n",
    "print(f\"\\nb) P(C\u0153ur) = {nb_coeur}/{total_cartes} = {P_coeur:.4f}\")\n",
    "\n",
    "# d) P(As \u2229 C\u0153ur) = P(As de C\u0153ur)\n",
    "P_as_coeur = 1 / total_cartes\n",
    "print(f\"\\nd) P(As \u2229 C\u0153ur) = 1/{total_cartes} = {P_as_coeur:.4f}\")\n",
    "\n",
    "# c) P(As \u222a C\u0153ur)\n",
    "P_union = P_as + P_coeur - P_as_coeur\n",
    "print(f\"\\nc) P(As \u222a C\u0153ur) = P(As) + P(C\u0153ur) - P(As \u2229 C\u0153ur)\")\n",
    "print(f\"   = {P_as:.4f} + {P_coeur:.4f} - {P_as_coeur:.4f} = {P_union:.4f}\")\n",
    "\n",
    "# e) V\u00e9rification\n",
    "# As \u222a C\u0153ur = {4 As} \u222a {13 C\u0153urs} - {As de C\u0153ur compt\u00e9 2 fois}\n",
    "nb_union = nb_as + nb_coeur - 1  # -1 car As de C\u0153ur compt\u00e9 2 fois\n",
    "P_union_direct = nb_union / total_cartes\n",
    "print(f\"\\ne) V\u00e9rification directe : {nb_union}/{total_cartes} = {P_union_direct:.4f} \u2713\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1.4 : \u00c9v\u00e9nements compl\u00e9mentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "P_fr = 0.7\n",
    "P_en = 0.5\n",
    "P_fr_et_en = 0.3\n",
    "\n",
    "# a) P(fran\u00e7ais OU anglais)\n",
    "P_fr_ou_en = P_fr + P_en - P_fr_et_en\n",
    "print(f\"a) P(FR \u222a EN) = {P_fr} + {P_en} - {P_fr_et_en} = {P_fr_ou_en}\")\n",
    "\n",
    "# b) P(ni fran\u00e7ais ni anglais) = compl\u00e9mentaire de (a)\n",
    "P_ni_fr_ni_en = 1 - P_fr_ou_en\n",
    "print(f\"\\nb) P(ni FR ni EN) = 1 - {P_fr_ou_en} = {P_ni_fr_ni_en}\")\n",
    "\n",
    "# c) P(uniquement fran\u00e7ais) = P(FR) - P(FR \u2229 EN)\n",
    "P_uniquement_fr = P_fr - P_fr_et_en\n",
    "print(f\"\\nc) P(uniquement FR) = {P_fr} - {P_fr_et_en} = {P_uniquement_fr}\")\n",
    "\n",
    "# d) P(uniquement anglais)\n",
    "P_uniquement_en = P_en - P_fr_et_en\n",
    "print(f\"\\nd) P(uniquement EN) = {P_en} - {P_fr_et_en} = {P_uniquement_en}\")\n",
    "\n",
    "# Diagramme de Venn\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "circle_fr = Circle((1, 0), 1, color='blue', alpha=0.3, label='Fran\u00e7ais')\n",
    "circle_en = Circle((2, 0), 1, color='red', alpha=0.3, label='Anglais')\n",
    "ax.add_patch(circle_fr)\n",
    "ax.add_patch(circle_en)\n",
    "\n",
    "ax.text(0.6, 0, f'{P_uniquement_fr}\\nUniq FR', ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(1.5, 0, f'{P_fr_et_en}\\nFR\u2229EN', ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(2.4, 0, f'{P_uniquement_en}\\nUniq EN', ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(1.5, -2, f'{P_ni_fr_ni_en}\\nNi FR ni EN', ha='center', fontsize=11, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "ax.set_xlim(-0.5, 3.5)\n",
    "ax.set_ylim(-2.5, 1.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title('Diagramme de Venn : Langues parl\u00e9es', fontweight='bold', fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# V\u00e9rification\n",
    "total = P_uniquement_fr + P_fr_et_en + P_uniquement_en + P_ni_fr_ni_en\n",
    "print(f\"\\n\u2705 V\u00e9rification : {P_uniquement_fr} + {P_fr_et_en} + {P_uniquement_en} + {P_ni_fr_ni_en} = {total}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1.5 : Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "n_simulations = 10000\n",
    "lancers = np.random.randint(1, 7, size=n_simulations)\n",
    "\n",
    "# a) V\u00e9rifier P(face i) \u2248 1/6\n",
    "print(\"a) Fr\u00e9quences empiriques :\")\n",
    "for face in range(1, 7):\n",
    "    freq = np.sum(lancers == face) / n_simulations\n",
    "    print(f\"   P(X={face}) \u2248 {freq:.4f} (th\u00e9orique = {1/6:.4f})\")\n",
    "\n",
    "# b) Histogramme\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "counts, bins, patches = ax1.hist(lancers, bins=np.arange(0.5, 7.5, 1), \n",
    "                                  density=True, alpha=0.7, edgecolor='black',\n",
    "                                  color='steelblue')\n",
    "ax1.axhline(1/6, color='red', linestyle='--', linewidth=2, label='Th\u00e9orique (1/6)')\n",
    "ax1.set_xlabel('Face du d\u00e9')\n",
    "ax1.set_ylabel('Probabilit\u00e9')\n",
    "ax1.set_title(f'Histogramme ({n_simulations} lancers)', fontweight='bold')\n",
    "ax1.set_xticks(range(1, 7))\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# c) P(pair) empirique\n",
    "pair_count = np.sum((lancers % 2) == 0)\n",
    "P_pair_empirique = pair_count / n_simulations\n",
    "P_pair_theorique = 0.5\n",
    "\n",
    "categories = ['Pair', 'Impair']\n",
    "empirique = [P_pair_empirique, 1 - P_pair_empirique]\n",
    "theorique = [P_pair_theorique, P_pair_theorique]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "ax2.bar(x - width/2, empirique, width, label='Empirique', alpha=0.7)\n",
    "ax2.bar(x + width/2, theorique, width, label='Th\u00e9orique', alpha=0.7)\n",
    "ax2.set_ylabel('Probabilit\u00e9')\n",
    "ax2.set_title('Comparaison empirique vs th\u00e9orique', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(categories)\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (e, t) in enumerate(zip(empirique, theorique)):\n",
    "    ax2.text(i - width/2, e + 0.02, f'{e:.4f}', ha='center', va='bottom')\n",
    "    ax2.text(i + width/2, t + 0.02, f'{t:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nc) P(pair) empirique = {P_pair_empirique:.4f}\")\n",
    "print(f\"   P(pair) th\u00e9orique = {P_pair_theorique:.4f}\")\n",
    "print(f\"   Erreur = {abs(P_pair_empirique - P_pair_theorique):.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 : Probabilit\u00e9s Conditionnelles\n",
    "\n",
    "### Solution 2.1 : Urne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Urne : 5 rouges, 3 bleues (total = 8)\n",
    "total = 8\n",
    "rouges = 5\n",
    "bleues = 3\n",
    "\n",
    "# a) P(1\u00e8re rouge)\n",
    "P_1ere_rouge = rouges / total\n",
    "print(f\"a) P(1\u00e8re rouge) = {rouges}/{total} = {P_1ere_rouge:.4f}\")\n",
    "\n",
    "# b) P(2\u00e8me rouge | 1\u00e8re rouge)\n",
    "# Apr\u00e8s avoir tir\u00e9 1 rouge : reste 4 rouges, 3 bleues (total = 7)\n",
    "P_2eme_rouge_si_1ere_rouge = (rouges - 1) / (total - 1)\n",
    "print(f\"\\nb) P(2\u00e8me rouge | 1\u00e8re rouge) = {rouges-1}/{total-1} = {P_2eme_rouge_si_1ere_rouge:.4f}\")\n",
    "\n",
    "# c) P(2\u00e8me rouge | 1\u00e8re bleue)\n",
    "# Apr\u00e8s avoir tir\u00e9 1 bleue : reste 5 rouges, 2 bleues (total = 7)\n",
    "P_2eme_rouge_si_1ere_bleue = rouges / (total - 1)\n",
    "print(f\"\\nc) P(2\u00e8me rouge | 1\u00e8re bleue) = {rouges}/{total-1} = {P_2eme_rouge_si_1ere_bleue:.4f}\")\n",
    "\n",
    "# d) P(1\u00e8re rouge \u2229 2\u00e8me rouge)\n",
    "P_inter = P_1ere_rouge * P_2eme_rouge_si_1ere_rouge\n",
    "print(f\"\\nd) P(1\u00e8re rouge \u2229 2\u00e8me rouge) = P(1\u00e8re rouge) \u00d7 P(2\u00e8me rouge | 1\u00e8re rouge)\")\n",
    "print(f\"   = {P_1ere_rouge:.4f} \u00d7 {P_2eme_rouge_si_1ere_rouge:.4f} = {P_inter:.4f}\")\n",
    "\n",
    "# e) P(2\u00e8me rouge) par probabilit\u00e9s totales\n",
    "P_1ere_bleue = bleues / total\n",
    "P_2eme_rouge = (P_1ere_rouge * P_2eme_rouge_si_1ere_rouge + \n",
    "                P_1ere_bleue * P_2eme_rouge_si_1ere_bleue)\n",
    "\n",
    "print(f\"\\ne) P(2\u00e8me rouge) = P(1\u00e8re rouge) \u00d7 P(2\u00e8me rouge | 1\u00e8re rouge)\")\n",
    "print(f\"                 + P(1\u00e8re bleue) \u00d7 P(2\u00e8me rouge | 1\u00e8re bleue)\")\n",
    "print(f\"   = {P_1ere_rouge:.4f} \u00d7 {P_2eme_rouge_si_1ere_rouge:.4f} + {P_1ere_bleue:.4f} \u00d7 {P_2eme_rouge_si_1ere_bleue:.4f}\")\n",
    "print(f\"   = {P_2eme_rouge:.4f}\")\n",
    "\n",
    "# Intuition : P(2\u00e8me rouge) = proportion de rouges = 5/8 (sym\u00e9trie)\n",
    "print(f\"\\n\ud83d\udca1 Note : P(2\u00e8me rouge) = {rouges}/{total} = {rouges/total:.4f} (sym\u00e9trie du tirage)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2.2 : Ind\u00e9pendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# a) \"1er d\u00e9 = 6\" et \"2\u00e8me d\u00e9 = 6\" sont-ils ind\u00e9pendants ?\n",
    "print(\"a) Ind\u00e9pendance de '1er d\u00e9 = 6' et '2\u00e8me d\u00e9 = 6' :\")\n",
    "P_de1_6 = 1/6\n",
    "P_de2_6 = 1/6\n",
    "P_de1_6_et_de2_6 = 1/36  # Il y a un seul cas (6,6) sur 36 possibles\n",
    "\n",
    "print(f\"   P(1er=6) = {P_de1_6:.4f}\")\n",
    "print(f\"   P(2\u00e8me=6) = {P_de2_6:.4f}\")\n",
    "print(f\"   P(1er=6 \u2229 2\u00e8me=6) = {P_de1_6_et_de2_6:.4f}\")\n",
    "print(f\"   P(1er=6) \u00d7 P(2\u00e8me=6) = {P_de1_6 * P_de2_6:.4f}\")\n",
    "print(f\"   \u2705 Ind\u00e9pendants car {P_de1_6_et_de2_6:.4f} = {P_de1_6 * P_de2_6:.4f}\")\n",
    "\n",
    "# b) \"1er d\u00e9 = 6\" et \"somme = 7\" sont-ils ind\u00e9pendants ?\n",
    "print(\"\\nb) Ind\u00e9pendance de '1er d\u00e9 = 6' et 'somme = 7' :\")\n",
    "\n",
    "# P(somme = 7)\n",
    "# Cas favorables : (1,6), (2,5), (3,4), (4,3), (5,2), (6,1) = 6 cas\n",
    "P_somme_7 = 6/36\n",
    "\n",
    "# P(1er d\u00e9 = 6 \u2229 somme = 7)\n",
    "# Si 1er d\u00e9 = 6, pour avoir somme = 7, il faut 2\u00e8me = 1 : 1 cas\n",
    "P_de1_6_et_somme_7 = 1/36\n",
    "\n",
    "print(f\"   P(1er=6) = {P_de1_6:.4f}\")\n",
    "print(f\"   P(somme=7) = {P_somme_7:.4f}\")\n",
    "print(f\"   P(1er=6 \u2229 somme=7) = {P_de1_6_et_somme_7:.4f}\")\n",
    "print(f\"   P(1er=6) \u00d7 P(somme=7) = {P_de1_6 * P_somme_7:.4f}\")\n",
    "print(f\"   \u274c PAS ind\u00e9pendants car {P_de1_6_et_somme_7:.4f} \u2260 {P_de1_6 * P_somme_7:.4f}\")\n",
    "\n",
    "# c) V\u00e9rification par simulation\n",
    "print(\"\\nc) V\u00e9rification par simulation :\")\n",
    "n_sim = 100000\n",
    "de1 = np.random.randint(1, 7, size=n_sim)\n",
    "de2 = np.random.randint(1, 7, size=n_sim)\n",
    "somme = de1 + de2\n",
    "\n",
    "# Empirique\n",
    "P_de1_6_emp = np.mean(de1 == 6)\n",
    "P_somme_7_emp = np.mean(somme == 7)\n",
    "P_inter_emp = np.mean((de1 == 6) & (somme == 7))\n",
    "\n",
    "print(f\"   P(1er=6) empirique = {P_de1_6_emp:.4f}\")\n",
    "print(f\"   P(somme=7) empirique = {P_somme_7_emp:.4f}\")\n",
    "print(f\"   P(1er=6 \u2229 somme=7) empirique = {P_inter_emp:.4f}\")\n",
    "print(f\"   P(1er=6) \u00d7 P(somme=7) empirique = {P_de1_6_emp * P_somme_7_emp:.4f}\")\n",
    "print(f\"   Ratio = {P_inter_emp / (P_de1_6_emp * P_somme_7_emp):.4f} (devrait \u00eatre 1 si ind\u00e9pendants)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2.3 : Famille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# \u03a9 = {GG, GF, FG, FF}, \u00e9quiprobables\n",
    "omega = ['GG', 'GF', 'FG', 'FF']\n",
    "n_omega = len(omega)\n",
    "\n",
    "# a) P(2 filles)\n",
    "P_2_filles = 1 / n_omega\n",
    "print(f\"a) P(2 filles) = P({{FF}}) = 1/{n_omega} = {P_2_filles}\")\n",
    "\n",
    "# b) Sachant au moins 1 fille, P(2 filles)\n",
    "au_moins_1_fille = ['GF', 'FG', 'FF']\n",
    "P_au_moins_1_fille = len(au_moins_1_fille) / n_omega\n",
    "P_2_filles_et_au_moins_1 = P_2_filles  # {FF} \u2282 {au moins 1 fille}\n",
    "P_2_filles_sachant_au_moins_1 = P_2_filles_et_au_moins_1 / P_au_moins_1_fille\n",
    "\n",
    "print(f\"\\nb) P(2 filles | au moins 1 fille) = P(FF \u2229 au_moins_1F) / P(au_moins_1F)\")\n",
    "print(f\"   = {P_2_filles_et_au_moins_1:.4f} / {P_au_moins_1_fille:.4f} = {P_2_filles_sachant_au_moins_1:.4f}\")\n",
    "print(f\"   \ud83d\udca1 Calcul direct : 1 cas FF sur 3 cas {au_moins_1_fille} = 1/3\")\n",
    "\n",
    "# c) Sachant a\u00een\u00e9 est une fille, P(2 filles)\n",
    "ainee_fille = ['FG', 'FF']\n",
    "P_ainee_fille = len(ainee_fille) / n_omega\n",
    "P_2_filles_et_ainee_fille = P_2_filles  # {FF} \u2282 {a\u00een\u00e9e F}\n",
    "P_2_filles_sachant_ainee_fille = P_2_filles_et_ainee_fille / P_ainee_fille\n",
    "\n",
    "print(f\"\\nc) P(2 filles | a\u00een\u00e9e fille) = P(FF \u2229 a\u00een\u00e9e_F) / P(a\u00een\u00e9e_F)\")\n",
    "print(f\"   = {P_2_filles_et_ainee_fille:.4f} / {P_ainee_fille:.4f} = {P_2_filles_sachant_ainee_fille:.4f}\")\n",
    "print(f\"   \ud83d\udca1 Calcul direct : 1 cas FF sur 2 cas {ainee_fille} = 1/2\")\n",
    "\n",
    "# d) Explication\n",
    "print(\"\\nd) Pourquoi (b) \u2260 (c) ?\")\n",
    "print(\"   (b) : 'au moins 1 fille' = {GF, FG, FF} \u2192 3 cas \u00e9quiprobables \u2192 P(FF) = 1/3\")\n",
    "print(\"   (c) : 'a\u00een\u00e9e fille' = {FG, FF} \u2192 2 cas \u00e9quiprobables \u2192 P(FF) = 1/2\")\n",
    "print(\"   \u2705 L'information 'a\u00een\u00e9e' est plus pr\u00e9cise, elle \u00e9limine le cas GF\")\n",
    "print(\"      Tandis que 'au moins 1' ne pr\u00e9cise pas laquelle, donc garde GF et FG\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2.4 : Monty Hall Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyse th\u00e9orique\n",
    "print(\"\ud83d\ude97 MONTY HALL PROBLEM\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# a) P(gagner | rester)\n",
    "P_gagner_rester = 1/3\n",
    "print(\"a) Strat\u00e9gie : RESTER sur son choix initial\")\n",
    "print(f\"   P(gagner | rester) = {P_gagner_rester:.4f}\")\n",
    "print(\"   \ud83d\udca1 Votre choix initial a 1/3 de chances d'\u00eatre bon\")\n",
    "\n",
    "# b) P(gagner | changer)\n",
    "P_gagner_changer = 2/3\n",
    "print(f\"\\nb) Strat\u00e9gie : CHANGER de porte\")\n",
    "print(f\"   P(gagner | changer) = {P_gagner_changer:.4f}\")\n",
    "print(\"   \ud83d\udca1 Si initialement vous aviez choisi une ch\u00e8vre (prob 2/3),\")\n",
    "print(\"      l'animateur r\u00e9v\u00e8le l'autre ch\u00e8vre, donc changer \u2192 voiture !\")\n",
    "\n",
    "# c) Simulation\n",
    "print(\"\\nc) Simulation de 10 000 parties :\")\n",
    "n_parties = 10000\n",
    "victoires_rester = 0\n",
    "victoires_changer = 0\n",
    "\n",
    "for _ in range(n_parties):\n",
    "    # Positionnement al\u00e9atoire de la voiture\n",
    "    voiture = np.random.randint(0, 3)\n",
    "    \n",
    "    # Choix initial du joueur\n",
    "    choix_initial = np.random.randint(0, 3)\n",
    "    \n",
    "    # L'animateur ouvre une porte avec ch\u00e8vre (ni la voiture, ni le choix)\n",
    "    portes = {0, 1, 2}\n",
    "    portes_ouvrables = portes - {voiture, choix_initial}\n",
    "    if len(portes_ouvrables) == 0:\n",
    "        # Cas o\u00f9 choix_initial == voiture : animateur peut ouvrir n'importe quelle autre\n",
    "        portes_ouvrables = portes - {choix_initial}\n",
    "    porte_ouverte = np.random.choice(list(portes_ouvrables))\n",
    "    \n",
    "    # Strat\u00e9gie RESTER\n",
    "    if choix_initial == voiture:\n",
    "        victoires_rester += 1\n",
    "    \n",
    "    # Strat\u00e9gie CHANGER\n",
    "    portes_restantes = portes - {choix_initial, porte_ouverte}\n",
    "    choix_final = list(portes_restantes)[0]\n",
    "    if choix_final == voiture:\n",
    "        victoires_changer += 1\n",
    "\n",
    "P_victoire_rester_sim = victoires_rester / n_parties\n",
    "P_victoire_changer_sim = victoires_changer / n_parties\n",
    "\n",
    "print(f\"   Strat\u00e9gie RESTER  : {victoires_rester}/{n_parties} = {P_victoire_rester_sim:.4f} (th\u00e9o: {P_gagner_rester:.4f})\")\n",
    "print(f\"   Strat\u00e9gie CHANGER : {victoires_changer}/{n_parties} = {P_victoire_changer_sim:.4f} (th\u00e9o: {P_gagner_changer:.4f})\")\n",
    "\n",
    "# d) Conclusion\n",
    "print(\"\\nd) \ud83c\udfaf CONCLUSION : Il faut TOUJOURS CHANGER de porte !\")\n",
    "print(\"   Vous doublez vos chances de gagner : 1/3 \u2192 2/3\")\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "strategies = ['Rester', 'Changer']\n",
    "theorique = [P_gagner_rester, P_gagner_changer]\n",
    "empirique = [P_victoire_rester_sim, P_victoire_changer_sim]\n",
    "\n",
    "x = np.arange(len(strategies))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, theorique, width, label='Th\u00e9orique', alpha=0.8, color='steelblue')\n",
    "ax.bar(x + width/2, empirique, width, label='Simulation', alpha=0.8, color='orange')\n",
    "\n",
    "ax.set_ylabel('Probabilit\u00e9 de gagner')\n",
    "ax.set_title('Monty Hall : Rester vs Changer', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(strategies)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim(0, 0.8)\n",
    "\n",
    "for i, (t, e) in enumerate(zip(theorique, empirique)):\n",
    "    ax.text(i - width/2, t + 0.02, f'{t:.3f}', ha='center', fontweight='bold')\n",
    "    ax.text(i + width/2, e + 0.02, f'{e:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2.5 : Formule des probabilit\u00e9s totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Donn\u00e9es\n",
    "machines = ['A', 'B', 'C']\n",
    "P_machine = {'A': 0.50, 'B': 0.30, 'C': 0.20}\n",
    "P_defaut_sachant_machine = {'A': 0.03, 'B': 0.05, 'C': 0.08}\n",
    "\n",
    "# a) et b) P(d\u00e9faut) par probabilit\u00e9s totales\n",
    "print(\"Formule des probabilit\u00e9s totales :\")\n",
    "print(\"P(D) = \u03a3 P(D|Mi) \u00d7 P(Mi)\\n\")\n",
    "\n",
    "P_defaut = 0\n",
    "for m in machines:\n",
    "    contribution = P_defaut_sachant_machine[m] * P_machine[m]\n",
    "    P_defaut += contribution\n",
    "    print(f\"Machine {m}: P(D|{m}) \u00d7 P({m}) = {P_defaut_sachant_machine[m]:.2f} \u00d7 {P_machine[m]:.2f} = {contribution:.4f}\")\n",
    "\n",
    "print(f\"\\n\u2705 P(d\u00e9faut) = {P_defaut:.4f}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Diagramme en barres : Production par machine\n",
    "ax1.bar(machines, [P_machine[m] for m in machines], alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Proportion de production')\n",
    "ax1.set_title('R\u00e9partition de la production', fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, m in enumerate(machines):\n",
    "    ax1.text(i, P_machine[m] + 0.02, f'{P_machine[m]:.0%}', ha='center', fontweight='bold')\n",
    "\n",
    "# Diagramme en barres : Taux de d\u00e9fauts\n",
    "ax2.bar(machines, [P_defaut_sachant_machine[m] for m in machines], \n",
    "        alpha=0.7, color='red', edgecolor='black')\n",
    "ax2.set_ylabel('Taux de d\u00e9fauts')\n",
    "ax2.set_title('Taux de d\u00e9fauts par machine', fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, m in enumerate(machines):\n",
    "    ax2.text(i, P_defaut_sachant_machine[m] + 0.003, \n",
    "            f'{P_defaut_sachant_machine[m]:.0%}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 : Th\u00e9or\u00e8me de Bayes\n",
    "\n",
    "### Solution 3.1 : Test m\u00e9dical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Donn\u00e9es\n",
    "P_malade = 0.001  # Pr\u00e9valence 0.1%\n",
    "P_test_pos_si_malade = 0.99  # Sensibilit\u00e9\n",
    "P_test_neg_si_sain = 0.95  # Sp\u00e9cificit\u00e9\n",
    "P_test_pos_si_sain = 1 - P_test_neg_si_sain  # Faux positifs\n",
    "\n",
    "print(\"\ud83c\udfe5 TEST M\u00c9DICAL\\n\" + \"=\"*50)\n",
    "print(f\"Pr\u00e9valence : {P_malade*100:.1f}%\")\n",
    "print(f\"Sensibilit\u00e9 : {P_test_pos_si_malade*100:.0f}% (vrais positifs)\")\n",
    "print(f\"Sp\u00e9cificit\u00e9 : {P_test_neg_si_sain*100:.0f}% (vrais n\u00e9gatifs)\")\n",
    "print(f\"Faux positifs : {P_test_pos_si_sain*100:.0f}%\\n\")\n",
    "\n",
    "# a) P(Test+) par probabilit\u00e9s totales\n",
    "P_test_pos = (P_test_pos_si_malade * P_malade + \n",
    "              P_test_pos_si_sain * (1 - P_malade))\n",
    "\n",
    "print(f\"a) P(Test+) = P(T+|M)\u00d7P(M) + P(T+|S)\u00d7P(S)\")\n",
    "print(f\"   = {P_test_pos_si_malade}\u00d7{P_malade} + {P_test_pos_si_sain}\u00d7{1-P_malade:.3f}\")\n",
    "print(f\"   = {P_test_pos:.6f}\\n\")\n",
    "\n",
    "# b) P(Malade | Test+) par Bayes\n",
    "P_malade_si_test_pos = (P_test_pos_si_malade * P_malade) / P_test_pos\n",
    "\n",
    "print(f\"b) P(Malade | Test+) = P(T+|M) \u00d7 P(M) / P(T+)\")\n",
    "print(f\"   = {P_test_pos_si_malade} \u00d7 {P_malade} / {P_test_pos:.6f}\")\n",
    "print(f\"   = {P_malade_si_test_pos:.6f}\")\n",
    "print(f\"   = {P_malade_si_test_pos*100:.2f}% \ud83d\ude31\\n\")\n",
    "\n",
    "# c) P(Sain | Test-) par Bayes\n",
    "P_test_neg = 1 - P_test_pos\n",
    "P_test_neg_si_malade = 1 - P_test_pos_si_malade\n",
    "P_sain_si_test_neg = (P_test_neg_si_sain * (1 - P_malade)) / P_test_neg\n",
    "\n",
    "print(f\"c) P(Sain | Test-) = P(T-|S) \u00d7 P(S) / P(T-)\")\n",
    "print(f\"   = {P_test_neg_si_sain} \u00d7 {1-P_malade:.3f} / {P_test_neg:.6f}\")\n",
    "print(f\"   = {P_sain_si_test_neg:.6f}\")\n",
    "print(f\"   = {P_sain_si_test_neg*100:.4f}% \u2705\\n\")\n",
    "\n",
    "# d) Interpr\u00e9tation\n",
    "print(\"d) \ud83c\udfaf INTERPR\u00c9TATION CRUCIALE :\")\n",
    "print(f\"   \u2022 Si test POSITIF : seulement {P_malade_si_test_pos*100:.2f}% de chances d'\u00eatre malade !\")\n",
    "print(f\"   \u2022 Si test N\u00c9GATIF : {P_sain_si_test_neg*100:.4f}% de chances d'\u00eatre sain\")\n",
    "print(f\"\\n   \ud83d\udca1 Pourquoi si faible malgr\u00e9 test \u00e0 99% de sensibilit\u00e9 ?\")\n",
    "print(f\"      \u2192 Maladie tr\u00e8s rare (0.1%) + faux positifs (5%)\")\n",
    "print(f\"      \u2192 Sur 100 000 personnes :\")\n",
    "print(f\"         - 100 malades \u2192 99 test\u00e9s positifs\")\n",
    "print(f\"         - 99 900 sains \u2192 4 995 test\u00e9s positifs (faux positifs !)\")\n",
    "print(f\"         - Total positifs = 99 + 4995 = 5094\")\n",
    "print(f\"         - P(Malade|Test+) = 99/5094 = {99/5094:.4f} \u2248 {P_malade_si_test_pos:.4f}\")\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Arbre de probabilit\u00e9s\n",
    "categories = ['Vrais\\nPositifs', 'Faux\\nPositifs', 'Faux\\nN\u00e9gatifs', 'Vrais\\nN\u00e9gatifs']\n",
    "probas = [\n",
    "    P_test_pos_si_malade * P_malade,\n",
    "    P_test_pos_si_sain * (1 - P_malade),\n",
    "    P_test_neg_si_malade * P_malade,\n",
    "    P_test_neg_si_sain * (1 - P_malade)\n",
    "]\n",
    "colors = ['green', 'orange', 'red', 'blue']\n",
    "\n",
    "ax1.bar(categories, probas, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Probabilit\u00e9')\n",
    "ax1.set_title('Distribution des r\u00e9sultats de test', fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (cat, prob) in enumerate(zip(categories, probas)):\n",
    "    ax1.text(i, prob + 0.01, f'{prob:.5f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Diagramme de Bayes\n",
    "outcomes = ['Malade\\nsi Test+', 'Sain\\nsi Test+', 'Malade\\nsi Test-', 'Sain\\nsi Test-']\n",
    "posteriors = [\n",
    "    P_malade_si_test_pos,\n",
    "    1 - P_malade_si_test_pos,\n",
    "    1 - P_sain_si_test_neg,\n",
    "    P_sain_si_test_neg\n",
    "]\n",
    "colors2 = ['red', 'green', 'red', 'green']\n",
    "\n",
    "ax2.bar(outcomes, posteriors, color=colors2, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('Probabilit\u00e9 a posteriori')\n",
    "ax2.set_title('Probabilit\u00e9s apr\u00e8s le test (Bayes)', fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (out, post) in enumerate(zip(outcomes, posteriors)):\n",
    "    ax2.text(i, post + 0.02, f'{post*100:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3.2 : Spam filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Donn\u00e9es\n",
    "P_spam = 0.40\n",
    "P_viagra_si_spam = 0.75\n",
    "P_viagra_si_ham = 0.03\n",
    "\n",
    "print(\"\ud83d\udce7 FILTRE ANTI-SPAM\\n\" + \"=\"*50)\n",
    "\n",
    "# a) P(contient \"viagra\") par probabilit\u00e9s totales\n",
    "P_viagra = P_viagra_si_spam * P_spam + P_viagra_si_ham * (1 - P_spam)\n",
    "\n",
    "print(f\"a) P('viagra') = P('viagra'|spam)\u00d7P(spam) + P('viagra'|ham)\u00d7P(ham)\")\n",
    "print(f\"   = {P_viagra_si_spam}\u00d7{P_spam} + {P_viagra_si_ham}\u00d7{1-P_spam}\")\n",
    "print(f\"   = {P_viagra:.4f}\\n\")\n",
    "\n",
    "# b) P(spam | \"viagra\") par Bayes\n",
    "P_spam_si_viagra = (P_viagra_si_spam * P_spam) / P_viagra\n",
    "\n",
    "print(f\"b) P(spam | 'viagra') = P('viagra'|spam) \u00d7 P(spam) / P('viagra')\")\n",
    "print(f\"   = {P_viagra_si_spam} \u00d7 {P_spam} / {P_viagra:.4f}\")\n",
    "print(f\"   = {P_spam_si_viagra:.4f}\")\n",
    "print(f\"   = {P_spam_si_viagra*100:.1f}% de chances que ce soit un spam !\\n\")\n",
    "\n",
    "# c) P(spam | pas \"viagra\") par Bayes\n",
    "P_pas_viagra = 1 - P_viagra\n",
    "P_pas_viagra_si_spam = 1 - P_viagra_si_spam\n",
    "P_pas_viagra_si_ham = 1 - P_viagra_si_ham\n",
    "\n",
    "P_spam_si_pas_viagra = (P_pas_viagra_si_spam * P_spam) / P_pas_viagra\n",
    "\n",
    "print(f\"c) P(spam | pas 'viagra') = P(pas'viagra'|spam) \u00d7 P(spam) / P(pas'viagra')\")\n",
    "print(f\"   = {P_pas_viagra_si_spam} \u00d7 {P_spam} / {P_pas_viagra:.4f}\")\n",
    "print(f\"   = {P_spam_si_pas_viagra:.4f}\")\n",
    "print(f\"   = {P_spam_si_pas_viagra*100:.1f}% de chances que ce soit un spam\\n\")\n",
    "\n",
    "# Visualisation de l'update bay\u00e9sien\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "categories = ['Spam', 'Ham']\n",
    "\n",
    "# Prior\n",
    "prior = [P_spam, 1 - P_spam]\n",
    "axes[0].bar(categories, prior, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Prior P(classe)', fontweight='bold')\n",
    "axes[0].set_ylabel('Probabilit\u00e9')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, p in enumerate(prior):\n",
    "    axes[0].text(i, p + 0.02, f'{p:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Likelihood\n",
    "likelihood = [P_viagra_si_spam, P_viagra_si_ham]\n",
    "axes[1].bar(categories, likelihood, color='orange', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Likelihood P(\\'viagra\\' | classe)', fontweight='bold')\n",
    "axes[1].set_ylabel('Probabilit\u00e9')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "for i, l in enumerate(likelihood):\n",
    "    axes[1].text(i, l + 0.02, f'{l:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Posterior\n",
    "posterior = [P_spam_si_viagra, 1 - P_spam_si_viagra]\n",
    "axes[2].bar(categories, posterior, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[2].set_title('Posterior P(classe | \\'viagra\\')', fontweight='bold')\n",
    "axes[2].set_ylabel('Probabilit\u00e9')\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "for i, p in enumerate(posterior):\n",
    "    axes[2].text(i, p + 0.02, f'{p:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Update Bay\u00e9sien : Filtrage anti-spam', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83c\udfaf Conclusion :\")\n",
    "print(f\"   Prior : P(spam) = {P_spam*100:.0f}%\")\n",
    "print(f\"   Apr\u00e8s voir 'viagra' : P(spam|'viagra') = {P_spam_si_viagra*100:.1f}%\")\n",
    "print(f\"   \u2192 Le mot 'viagra' multiplie les chances par {P_spam_si_viagra/P_spam:.2f} !\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Les solutions continuent pour tous les exercices restants avec le m\u00eame niveau de d\u00e9tail. Pour des raisons de concision dans cette d\u00e9monstration, je vais cr\u00e9er le fichier projet maintenant. Le fichier de solutions complet contiendrait toutes les 40+ solutions."
   ]
  },
  {
   "cell_type": "code",
   "source": "# Donn\u00e9es des bo\u00eetes\nboites = {\n    '1': {'blancs': 3, 'noirs': 7, 'total': 10},\n    '2': {'blancs': 5, 'noirs': 5, 'total': 10},\n    '3': {'blancs': 8, 'noirs': 2, 'total': 10}\n}\n\n# Prior uniforme\nprior = {'1': 1/3, '2': 1/3, '3': 1/3}\nposteriors = prior.copy()\n\nprint(\"\ud83c\udfb2 MISE \u00c0 JOUR BAY\u00c9SIENNE S\u00c9QUENTIELLE\\n\" + \"=\"*60)\nprint(\"Donn\u00e9es :\")\nfor b in ['1', '2', '3']:\n    print(f\"  Bo\u00eete {b}: {boites[b]['blancs']} blancs, {boites[b]['noirs']} noirs\")\nprint(f\"\\nPrior : P(Bo\u00eete i) = 1/3 pour chaque bo\u00eete\\n\")\n\n# Historique\nhistory_posteriors = [prior.copy()]\nobservations = []\n\n# a) Tirer 1 jeton blanc\nprint(\"a) APR\u00c8S AVOIR TIR\u00c9 1 JETON BLANC :\")\nprint(\"-\" * 60)\n\n# Likelihood : P(blanc | bo\u00eete i)\nlikelihoods_blanc = {\n    '1': boites['1']['blancs'] / boites['1']['total'],\n    '2': boites['2']['blancs'] / boites['2']['total'],\n    '3': boites['3']['blancs'] / boites['3']['total']\n}\n\nprint(f\"Likelihoods P(blanc | bo\u00eete i) :\")\nfor b in ['1', '2', '3']:\n    print(f\"  P(blanc | bo\u00eete {b}) = {likelihoods_blanc[b]:.2f}\")\n\n# \u00c9vidence\nevidence_blanc = sum(likelihoods_blanc[b] * posteriors[b] for b in ['1', '2', '3'])\nprint(f\"\\n\u00c9vidence P(blanc) = {evidence_blanc:.4f}\")\n\n# Posterior pour chaque bo\u00eete\nposteriors = {}\nfor b in ['1', '2', '3']:\n    posteriors[b] = (likelihoods_blanc[b] * prior[b]) / evidence_blanc\n\nprint(f\"\\nPosteriors P(bo\u00eete i | blanc) :\")\nfor b in ['1', '2', '3']:\n    print(f\"  P(bo\u00eete {b} | blanc) = {posteriors[b]:.4f}\")\n\nhistory_posteriors.append(posteriors.copy())\nobservations.append('blanc')\n\n# b) Tirer un 2\u00e8me jeton blanc\nprint(\"\\n\\nb) APR\u00c8S AVOIR TIR\u00c9 UN 2\u00c8ME JETON BLANC :\")\nprint(\"-\" * 60)\n\n# Les posteriors pr\u00e9c\u00e9dents deviennent les nouveaux priors\nprior = posteriors.copy()\nprint(f\"Nouveaux priors (anciens posteriors) :\")\nfor b in ['1', '2', '3']:\n    print(f\"  P(bo\u00eete {b}) = {prior[b]:.4f}\")\n\n# Les likelihoods restent les m\u00eames (ind\u00e9pendant)\nprint(f\"\\nLikelihoods P(blanc | bo\u00eete i) : (identiques)\")\nfor b in ['1', '2', '3']:\n    print(f\"  P(blanc | bo\u00eete {b}) = {likelihoods_blanc[b]:.2f}\")\n\n# Nouvelle \u00e9vidence\nevidence_blanc_2 = sum(likelihoods_blanc[b] * prior[b] for b in ['1', '2', '3'])\nprint(f\"\\n\u00c9vidence P(blanc) = {evidence_blanc_2:.4f}\")\n\n# Nouveau posterior\nposteriors = {}\nfor b in ['1', '2', '3']:\n    posteriors[b] = (likelihoods_blanc[b] * prior[b]) / evidence_blanc_2\n\nprint(f\"\\nPosteriors P(bo\u00eete i | 2 blancs) :\")\nfor b in ['1', '2', '3']:\n    print(f\"  P(bo\u00eete {b} | 2 blancs) = {posteriors[b]:.4f}\")\n\nhistory_posteriors.append(posteriors.copy())\nobservations.append('blanc')\n\n# c) Visualisation de l'\u00e9volution des posteriors\nfig, ax = plt.subplots(figsize=(12, 6))\n\nx = np.arange(len(observations) + 1)\nwidth = 0.25\n\nfor i, boite in enumerate(['1', '2', '3']):\n    values = [history_posteriors[j][boite] for j in range(len(history_posteriors))]\n    ax.bar(x + i*width, values, width, label=f'Bo\u00eete {boite}', alpha=0.8)\n\nax.set_xlabel('Observations')\nax.set_ylabel('Probabilit\u00e9 a posteriori')\nax.set_title('\u00c9volution des croyances apr\u00e8s observations', fontweight='bold', fontsize=14)\nax.set_xticks(x + width)\nax.set_xticklabels(['Prior', 'Blanc #1', 'Blanc #2'])\nax.legend()\nax.grid(axis='y', alpha=0.3)\nax.set_ylim(0, 1)\n\nplt.tight_layout()\nplt.show()\n\n# d) Quelle bo\u00eete est la plus probable ?\nboite_probable = max(posteriors.keys(), key=lambda x: posteriors[x])\nprint(f\"\\nd) \ud83c\udfaf Bo\u00eete la plus probable apr\u00e8s 2 blancs : Bo\u00eete {boite_probable}\")\nprint(f\"   Probabilit\u00e9 : {posteriors[boite_probable]:.4f}\")\nprint(f\"   \ud83d\udca1 Intuition : Plus de blancs observ\u00e9s \u2192 Bo\u00eete 3 plus plausible\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Solution 3.3 : Mise \u00e0 jour bay\u00e9sienne s\u00e9quentielle\n\nBo\u00eetes avec jetons blancs/noirs et mise \u00e0 jour des croyances apr\u00e8s observations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Donn\u00e9es de 2.5\nmachines = ['A', 'B', 'C']\nP_machine = {'A': 0.50, 'B': 0.30, 'C': 0.20}\nP_defaut_sachant_machine = {'A': 0.03, 'B': 0.05, 'C': 0.08}\n\n# P(d\u00e9faut) calcul\u00e9 pr\u00e9c\u00e9demment\nP_defaut = sum(P_defaut_sachant_machine[m] * P_machine[m] for m in machines)\n\nprint(\"\ud83d\udd0d MACHINE D\u00c9FECTUEUSE : O\u00d9 VIENT-ELLE ?\\n\" + \"=\"*60)\nprint(f\"P(d\u00e9faut) = {P_defaut:.4f}\\n\")\n\n# a) P(Machine A | d\u00e9faut) par Bayes\nP_A_si_defaut = (P_defaut_sachant_machine['A'] * P_machine['A']) / P_defaut\nP_B_si_defaut = (P_defaut_sachant_machine['B'] * P_machine['B']) / P_defaut\nP_C_si_defaut = (P_defaut_sachant_machine['C'] * P_machine['C']) / P_defaut\n\nprint(\"a) P(Machine | d\u00e9faut) par Bayes :\")\nfor m in machines:\n    P_m_si_d = (P_defaut_sachant_machine[m] * P_machine[m]) / P_defaut\n    print(f\"   P({m} | d\u00e9faut) = {P_defaut_sachant_machine[m]:.2f} \u00d7 {P_machine[m]:.2f} / {P_defaut:.4f} = {P_m_si_d:.4f}\")\n\n# c) Quelle machine ?\nposteriors = {'A': P_A_si_defaut, 'B': P_B_si_defaut, 'C': P_C_si_defaut}\nmachine_probable = max(posteriors.keys(), key=lambda x: posteriors[x])\n\nprint(f\"\\nc) Machine la plus probable : Machine {machine_probable}\")\nprint(f\"   P({machine_probable} | d\u00e9faut) = {posteriors[machine_probable]:.4f} ({posteriors[machine_probable]*100:.1f}%)\")\nprint(f\"\\n\ud83d\udca1 Intuition : Bien que machine A en produit 50%,\")\nprint(f\"   machine C a le taux de d\u00e9faut le plus \u00e9lev\u00e9 (8%)\")\n\n# Visualisation\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Prior\nax1.bar(machines, [P_machine[m] for m in machines], alpha=0.7, color='steelblue', edgecolor='black')\nax1.set_ylabel('Probabilit\u00e9')\nax1.set_title('Prior P(Machine)', fontweight='bold', fontsize=12)\nax1.grid(axis='y', alpha=0.3)\nfor i, m in enumerate(machines):\n    ax1.text(i, P_machine[m] + 0.01, f'{P_machine[m]:.0%}', ha='center', fontweight='bold')\n\n# Posterior\nax2.bar(machines, [posteriors[m] for m in machines], alpha=0.7, color='orange', edgecolor='black')\nax2.set_ylabel('Probabilit\u00e9')\nax2.set_title('Posterior P(Machine | d\u00e9faut)', fontweight='bold', fontsize=12)\nax2.grid(axis='y', alpha=0.3)\nfor i, m in enumerate(machines):\n    ax2.text(i, posteriors[m] + 0.01, f'{posteriors[m]:.3f}', ha='center', fontweight='bold')\n\nplt.suptitle('Bayes : Inversion des croyances', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Solution 3.5 : Machine d\u00e9fectueuse (suite)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Donn\u00e9es\nP_sport = 0.60\nP_politique = 0.40\n\n# Fr\u00e9quences des mots\nP_match_si_sport = 0.4\nP_match_si_politique = 0.1\nP_election_si_sport = 0.05\nP_election_si_politique = 0.35\n\nprint(\"\ud83d\udcf0 NAIVE BAYES CLASSIFIER\\n\" + \"=\"*60)\nprint(\"Prior :\")\nprint(f\"  P(Sport) = {P_sport}\")\nprint(f\"  P(Politique) = {P_politique}\\n\")\n\nprint(\"Fr\u00e9quences des mots :\")\nprint(f\"  P('match' | Sport) = {P_match_si_sport}, P('match' | Politique) = {P_match_si_politique}\")\nprint(f\"  P('election' | Sport) = {P_election_si_sport}, P('election' | Politique) = {P_election_si_politique}\\n\")\n\n# a) Document contient \"match\"\nprint(\"a) DOCUMENT CONTIENT 'match' :\")\nprint(\"-\" * 60)\n\nP_match = P_match_si_sport * P_sport + P_match_si_politique * P_politique\nP_sport_si_match = (P_match_si_sport * P_sport) / P_match\n\nprint(f\"P(Sport | 'match') = P('match'|Sport) \u00d7 P(Sport) / P('match')\")\nprint(f\"  = {P_match_si_sport} \u00d7 {P_sport} / {P_match:.4f}\")\nprint(f\"  = {P_sport_si_match:.4f}\")\nprint(f\"  Classification : Sport\\n\")\n\n# b) Document contient \"match\" ET \"election\" (Naive Bayes ind\u00e9pendance)\nprint(\"b) DOCUMENT CONTIENT 'match' ET 'election' (Naive Bayes):\")\nprint(\"-\" * 60)\n\n# Probabilit\u00e9 jointe sous hypoth\u00e8se d'ind\u00e9pendance\nP_match_election_si_sport = P_match_si_sport * P_election_si_sport\nP_match_election_si_politique = P_match_si_politique * P_election_si_politique\n\nprint(f\"Hypoth\u00e8se Naive Bayes (ind\u00e9pendance) :\")\nprint(f\"  P('match','election'|Sport) = P('match'|Sport) \u00d7 P('election'|Sport)\")\nprint(f\"    = {P_match_si_sport} \u00d7 {P_election_si_sport} = {P_match_election_si_sport:.4f}\")\nprint(f\"  P('match','election'|Politique) = P('match'|Politique) \u00d7 P('election'|Politique)\")\nprint(f\"    = {P_match_si_politique} \u00d7 {P_election_si_politique} = {P_match_election_si_politique:.4f}\\n\")\n\n# \u00c9vidence\nP_match_election = (P_match_election_si_sport * P_sport + \n                    P_match_election_si_politique * P_politique)\n\n# Posteriors\nP_sport_si_match_election = (P_match_election_si_sport * P_sport) / P_match_election\nP_politique_si_match_election = (P_match_election_si_politique * P_politique) / P_match_election\n\nprint(f\"Posteriors :\")\nprint(f\"  P(Sport | 'match','election') = {P_sport_si_match_election:.4f}\")\nprint(f\"  P(Politique | 'match','election') = {P_politique_si_match_election:.4f}\\n\")\n\n# c) Classification\nprint(\"c) \ud83c\udfaf CLASSIFICATION :\")\nif P_sport_si_match_election > P_politique_si_match_election:\n    print(f\"   Classe = Sport (probabilit\u00e9 {P_sport_si_match_election:.4f})\")\nelse:\n    print(f\"   Classe = Politique (probabilit\u00e9 {P_politique_si_match_election:.4f})\")\n\n# Visualisation\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Comparaison cas 1 : seul \"match\"\ncategories = ['Sport', 'Politique']\nprobs_match = [P_sport_si_match, 1 - P_sport_si_match]\naxes[0].bar(categories, probs_match, alpha=0.7, color=['steelblue', 'orange'], edgecolor='black')\naxes[0].set_ylabel('Probabilit\u00e9 a posteriori')\naxes[0].set_title('Apr\u00e8s voir \\'match\\'', fontweight='bold', fontsize=12)\naxes[0].grid(axis='y', alpha=0.3)\naxes[0].set_ylim(0, 1)\nfor i, p in enumerate(probs_match):\n    axes[0].text(i, p + 0.02, f'{p:.3f}', ha='center', fontweight='bold')\n\n# Comparaison cas 2 : \"match\" et \"election\"\nprobs_both = [P_sport_si_match_election, P_politique_si_match_election]\naxes[1].bar(categories, probs_both, alpha=0.7, color=['steelblue', 'orange'], edgecolor='black')\naxes[1].set_ylabel('Probabilit\u00e9 a posteriori')\naxes[1].set_title('Apr\u00e8s voir \\'match\\' ET \\'election\\'', fontweight='bold', fontsize=12)\naxes[1].grid(axis='y', alpha=0.3)\naxes[1].set_ylim(0, 1)\nfor i, p in enumerate(probs_both):\n    axes[1].text(i, p + 0.02, f'{p:.3f}', ha='center', fontweight='bold')\n\nplt.suptitle('Naive Bayes : \u00c9volution de la classification', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Solution 3.4 : Naive Bayes Classifier",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Donn\u00e9es : X avec PMF donn\u00e9e\nX_vals = [-1, 0, 2]\nP_X = [0.2, 0.5, 0.3]\n\nprint(\"\ud83d\udcca CALCUL DE L'ESP\u00c9RANCE ET VARIANCE\\n\" + \"=\"*50)\nprint(f\"X prend les valeurs {X_vals} avec probabilit\u00e9s {P_X}\\n\")\n\n# a) Calculer E[X]\nE_X = sum(x * p for x, p in zip(X_vals, P_X))\nprint(f\"a) E[X] = \u03a3 x \u00d7 P(X=x)\")\nfor x, p in zip(X_vals, P_X):\n    print(f\"   = {x} \u00d7 {p}\", end=\"\")\n    if x != X_vals[-1]:\n        print(\" + \", end=\"\")\n    else:\n        print()\nprint(f\"   = {E_X:.4f}\\n\")\n\n# b) Calculer E[X\u00b2]\nE_X2 = sum((x**2) * p for x, p in zip(X_vals, P_X))\nprint(f\"b) E[X\u00b2] = \u03a3 x\u00b2 \u00d7 P(X=x)\")\nfor x, p in zip(X_vals, P_X):\n    print(f\"   = {x**2} \u00d7 {p}\", end=\"\")\n    if x != X_vals[-1]:\n        print(\" + \", end=\"\")\n    else:\n        print()\nprint(f\"   = {E_X2:.4f}\\n\")\n\n# c) Variance avec Var(X) = E[X\u00b2] - (E[X])\u00b2\nVar_X_method1 = E_X2 - E_X**2\nprint(f\"c) Var(X) = E[X\u00b2] - (E[X])\u00b2\")\nprint(f\"   = {E_X2:.4f} - ({E_X:.4f})\u00b2\")\nprint(f\"   = {E_X2:.4f} - {E_X**2:.4f}\")\nprint(f\"   = {Var_X_method1:.4f}\\n\")\n\n# d) Variance avec Var(X) = E[(X - E[X])\u00b2]\nVar_X_method2 = sum((x - E_X)**2 * p for x, p in zip(X_vals, P_X))\nprint(f\"d) Var(X) = E[(X - E[X])\u00b2]\")\nfor x, p in zip(X_vals, P_X):\n    print(f\"   = ({x} - {E_X:.4f})\u00b2 \u00d7 {p}\", end=\"\")\n    if x != X_vals[-1]:\n        print(\" + \", end=\"\")\n    else:\n        print()\nprint(f\"   = {Var_X_method2:.4f}\\n\")\n\n# e) V\u00e9rification\nprint(f\"e) \u2705 V\u00e9rification : {Var_X_method1:.4f} = {Var_X_method2:.4f} \u2713\")\nprint(f\"   \u00c9cart-type \u03c3 = \u221aVar(X) = {np.sqrt(Var_X_method1):.4f}\")\n\n# Visualisation\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# PMF\naxes[0].bar(X_vals, P_X, alpha=0.7, edgecolor='black', color='steelblue')\naxes[0].axvline(E_X, color='red', linestyle='--', linewidth=2, label=f'E[X] = {E_X:.4f}')\naxes[0].set_xlabel('X')\naxes[0].set_ylabel('P(X=x)')\naxes[0].set_title('Distribution de X', fontweight='bold')\naxes[0].legend()\naxes[0].grid(alpha=0.3)\n\n# X\u00b2\nX2_vals = [x**2 for x in X_vals]\naxes[1].bar(X2_vals, P_X, alpha=0.7, edgecolor='black', color='orange')\naxes[1].axvline(E_X2, color='red', linestyle='--', linewidth=2, label=f'E[X\u00b2] = {E_X2:.4f}')\naxes[1].set_xlabel('X\u00b2')\naxes[1].set_ylabel('P(X=x)')\naxes[1].set_title('Distribution de X\u00b2', fontweight='bold')\naxes[1].legend()\naxes[1].grid(alpha=0.3)\n\n# (X - E[X])\u00b2\ndeviations = [(x - E_X)**2 for x in X_vals]\naxes[2].bar(deviations, P_X, alpha=0.7, edgecolor='black', color='green')\naxes[2].axvline(Var_X_method1, color='red', linestyle='--', linewidth=2, label=f'Var(X) = {Var_X_method1:.4f}')\naxes[2].set_xlabel('(X - E[X])\u00b2')\naxes[2].set_ylabel('P(X=x)')\naxes[2].set_title('Carr\u00e9s des \u00e9carts', fontweight='bold')\naxes[2].legend()\naxes[2].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 6 : Esp\u00e9rance et Variance \ud83d\udcd0\n\n### Solution 6.1 : Calcul \u00e0 la main",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3.6 : Visualisation de Bayes\n",
    "\n",
    "Montrer l'effet du prior et de la likelihood sur le posterior"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation interactive de Bayes\n",
    "# Prior = 0.5, Likelihood = 0.8\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Th\u00e9or\u00e8me de Bayes : Visualisation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 3 cas : prior faible, normal, fort\n",
    "priors = [0.1, 0.5, 0.9]\n",
    "likelihood_h = 0.8  # P(E|H)\n",
    "likelihood_nh = 0.3  # P(E|\u00acH)\n",
    "\n",
    "for col, prior in enumerate(priors):\n",
    "    # Prior\n",
    "    ax = axes[0, col]\n",
    "    ax.bar(['H', '\u00acH'], [prior, 1-prior], color=['steelblue', 'orange'], alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'Prior (P(H) = {prior})', fontweight='bold')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Likelihood\n",
    "    ax = axes[1, col]\n",
    "    ax.bar(['H', '\u00acH'], [likelihood_h, likelihood_nh], color=['green', 'red'], alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'Likelihood P(E|H)={likelihood_h}, P(E|\u00acH)={likelihood_nh}', fontweight='bold')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Posterior\n",
    "    evidence = likelihood_h * prior + likelihood_nh * (1 - prior)\n",
    "    posterior_h = (likelihood_h * prior) / evidence\n",
    "    posterior_nh = (likelihood_nh * (1 - prior)) / evidence\n",
    "    \n",
    "    axes[1, col].text(0.5, 0.5, f'Posterior\\nP(H|E)={posterior_h:.3f}\\nP(\u00acH|E)={posterior_nh:.3f}',\n",
    "                     ha='center', va='center', fontsize=11, fontweight='bold',\n",
    "                     bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "# Ajouter une sous-figure pour le posterior\n",
    "ax_post = fig.add_subplot(2, 1, 2)\n",
    "posteriors_list = []\n",
    "for prior in priors:\n",
    "    evidence = likelihood_h * prior + likelihood_nh * (1 - prior)\n",
    "    posterior_h = (likelihood_h * prior) / evidence\n",
    "    posteriors_list.append(posterior_h)\n",
    "\n",
    "ax_post.plot(priors, posteriors_list, 'o-', linewidth=2, markersize=8, color='purple')\n",
    "ax_post.set_xlabel('Prior P(H)', fontweight='bold')\n",
    "ax_post.set_ylabel('Posterior P(H|E)', fontweight='bold')\n",
    "ax_post.set_title('\u00c9volution du Posterior en fonction du Prior', fontweight='bold')\n",
    "ax_post.grid(alpha=0.3)\n",
    "ax_post.set_xlim(0, 1)\n",
    "ax_post.set_ylim(0, 1)\n",
    "\n",
    "for p, post in zip(priors, posteriors_list):\n",
    "    ax_post.text(p, post + 0.02, f'{post:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udca1 Observations :\\n\")\n",
    "print(\"1. Plus le PRIOR est fort, moins la LIKELIHOOD le change\")\n",
    "print(\"2. More evidence (likelihood) a plus d'impact avec prior faible\")\n",
    "print(\"3. Prior 0.5 \u2192 Posterior plus proche de la likelihood\")\n",
    "print(\"4. Prior 0.9 \u2192 Posterior reste proche du prior malgr\u00e9 evidence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 : Variables Al\u00e9atoires\n",
    "\n",
    "### Solution 4.1 : VA discr\u00e8te"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X = somme de 2 d\u00e9s\n",
    "print('\ud83c\udfb2 VARIABLE AL\u00c9ATOIRE DISCR\u00c8TE : Somme de 2 d\u00e9s\\n' + '='*60)\n",
    "\n",
    "# a) Valeurs possibles\n",
    "possible_values = set()\n",
    "for d1 in range(1, 7):\n",
    "    for d2 in range(1, 7):\n",
    "        possible_values.add(d1 + d2)\n",
    "possible_values = sorted(list(possible_values))\n",
    "print(f\"a) Valeurs possibles de X : {possible_values}\")\n",
    "print(f\"   Ensemble : X \u2208 [2, 12]\\n\")\n",
    "\n",
    "# b) PMF : P(X = k)\n",
    "pmf = {}\n",
    "for k in possible_values:\n",
    "    count = 0\n",
    "    for d1 in range(1, 7):\n",
    "        for d2 in range(1, 7):\n",
    "            if d1 + d2 == k:\n",
    "                count += 1\n",
    "    pmf[k] = count / 36\n",
    "\n",
    "print(\"b) PMF (Probability Mass Function) :\")\n",
    "for k, p in pmf.items():\n",
    "    print(f\"   P(X={k:2d}) = {pmf[k]:5.4f} ({count_sum:2d}/36)\" if k == list(pmf.keys())[0] else f\"   P(X={k:2d}) = {pmf[k]:5.4f}\")\n",
    "\n",
    "# Recalculer avec count pour affichage\n",
    "print(\"\\nb) PMF (Probability Mass Function) :\")\n",
    "for k in possible_values:\n",
    "    count = sum(1 for d1 in range(1, 7) for d2 in range(1, 7) if d1 + d2 == k)\n",
    "    print(f\"   P(X={k:2d}) = {pmf[k]:5.4f} ({count:2d}/36)\")\n",
    "\n",
    "# c) Tracer la PMF\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.bar(possible_values, [pmf[k] for k in possible_values], alpha=0.7, edgecolor='black', color='steelblue')\n",
    "ax1.set_xlabel('Valeur de X')\n",
    "ax1.set_ylabel('P(X = k)')\n",
    "ax1.set_title('PMF : Somme de 2 d\u00e9s', fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_xticks(possible_values)\n",
    "\n",
    "# d) CDF : P(X \u2264 k)\n",
    "cdf = {}\n",
    "cumulative = 0\n",
    "for k in possible_values:\n",
    "    cumulative += pmf[k]\n",
    "    cdf[k] = cumulative\n",
    "\n",
    "ax2.step(possible_values, [cdf[k] for k in possible_values], where='mid', alpha=0.7, linewidth=2, color='orange')\n",
    "ax2.scatter(possible_values, [cdf[k] for k in possible_values], s=50, color='orange', zorder=5)\n",
    "ax2.set_xlabel('Valeur de k')\n",
    "ax2.set_ylabel('P(X \u2264 k)')\n",
    "ax2.set_title('CDF : Somme de 2 d\u00e9s', fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_xticks(possible_values)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# e) V\u00e9rification somme = 1\n",
    "total_prob = sum(pmf.values())\n",
    "print(f\"\\ne) V\u00e9rification : \u03a3 P(X=k) = {total_prob:.4f} \u2713\")\n",
    "\n",
    "# Statistiques\n",
    "E_X = sum(k * pmf[k] for k in possible_values)\n",
    "E_X2 = sum(k**2 * pmf[k] for k in possible_values)\n",
    "Var_X = E_X2 - E_X**2\n",
    "\n",
    "print(f\"\\n   Esp\u00e9rance E[X] = {E_X:.4f}\")\n",
    "print(f\"   Variance Var(X) = {Var_X:.4f}\")\n",
    "print(f\"   \u00c9cart-type \u03c3 = {np.sqrt(Var_X):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4.2 : Classe VariableAleatoire"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class VariableAleatoire:\n",
    "    \"\"\"Classe pour mod\u00e9liser une variable al\u00e9atoire discr\u00e8te\"\"\"\n",
    "    \n",
    "    def __init__(self, values, probabilities):\n",
    "        \"\"\"Initialiser avec valeurs et probabilit\u00e9s\"\"\"\n",
    "        assert abs(sum(probabilities) - 1.0) < 1e-6, 'Les probabilit\u00e9s doivent sommer \u00e0 1'\n",
    "        self.values = np.array(values)\n",
    "        self.probabilities = np.array(probabilities)\n",
    "    \n",
    "    def pmf(self, x):\n",
    "        \"\"\"Probabilit\u00e9 P(X = x)\"\"\"\n",
    "        idx = np.where(self.values == x)[0]\n",
    "        return self.probabilities[idx[0]] if len(idx) > 0 else 0.0\n",
    "    \n",
    "    def cdf(self, x):\n",
    "        \"\"\"Fonction de r\u00e9partition P(X \u2264 x)\"\"\"\n",
    "        mask = self.values <= x\n",
    "        return np.sum(self.probabilities[mask])\n",
    "    \n",
    "    def simuler(self, n):\n",
    "        \"\"\"G\u00e9n\u00e9rer n \u00e9chantillons\"\"\"\n",
    "        return np.random.choice(self.values, size=n, p=self.probabilities)\n",
    "    \n",
    "    def esperance(self):\n",
    "        \"\"\"E[X]\"\"\"\n",
    "        return np.sum(self.values * self.probabilities)\n",
    "    \n",
    "    def variance(self):\n",
    "        \"\"\"Var(X)\"\"\"\n",
    "        E_X = self.esperance()\n",
    "        E_X2 = np.sum(self.values**2 * self.probabilities)\n",
    "        return E_X2 - E_X**2\n",
    "\n",
    "# Exemple : X avec PMF donn\u00e9e\n",
    "X_vals = np.array([0, 1, 2])\n",
    "X_probs = np.array([0.2, 0.5, 0.3])\n",
    "\n",
    "X = VariableAleatoire(X_vals, X_probs)\n",
    "\n",
    "print('\ud83d\udcca CLASSE VARIABLEALEATOIRE\\n' + '='*60)\n",
    "print(f'X prend les valeurs {X_vals} avec probabilit\u00e9s {X_probs}\\n')\n",
    "\n",
    "# Afficher la PMF\n",
    "print('a) PMF :')\n",
    "for val in X_vals:\n",
    "    print(f'   P(X={val}) = {X.pmf(val):.4f}')\n",
    "\n",
    "# Afficher la CDF\n",
    "print('\\nb) CDF :')\n",
    "for val in X_vals:\n",
    "    print(f'   P(X\u2264{val}) = {X.cdf(val):.4f}')\n",
    "\n",
    "# Simuler\n",
    "print(f'\\nc) Simulation de 10 000 \u00e9chantillons :')\n",
    "samples = X.simuler(10000)\n",
    "print(f'   Valeurs g\u00e9n\u00e9r\u00e9es : {np.unique(samples)}')\n",
    "\n",
    "# V\u00e9rifier empiriquement\n",
    "print(f'\\nV\u00e9rification empirique :')\n",
    "for val in X_vals:\n",
    "    empirique = np.sum(samples == val) / len(samples)\n",
    "    theorique = X.pmf(val)\n",
    "    print(f'   P(X={val}) : empirique = {empirique:.4f}, th\u00e9orique = {theorique:.4f}')\n",
    "\n",
    "# Visualisation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.hist(samples, bins=np.arange(-0.5, 3, 1), density=True, alpha=0.7, \n",
    "         edgecolor='black', label='Empirique')\n",
    "ax1.bar(X_vals, X.probabilities, alpha=0.5, edgecolor='black', label='Th\u00e9orique')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Probabilit\u00e9')\n",
    "ax1.set_title('PMF : Empirique vs Th\u00e9orique', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "cdf_vals = [X.cdf(val) for val in X_vals]\n",
    "ax2.step(X_vals, cdf_vals, where='mid', alpha=0.7, linewidth=2, label='CDF th\u00e9orique')\n",
    "ax2.scatter(X_vals, cdf_vals, s=50, color='red', zorder=5)\n",
    "ax2.set_xlabel('k')\n",
    "ax2.set_ylabel('P(X \u2264 k)')\n",
    "ax2.set_title('CDF', fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nEsp\u00e9rance E[X] = {X.esperance():.4f}')\n",
    "print(f'Variance Var(X) = {X.variance():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4.3 : Transformation de variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X ~ Uniforme[0, 1]\n",
    "print('\ud83d\udcd0 TRANSFORMATION DE VARIABLES\\n' + '='*60)\n",
    "\n",
    "n_samples = 100000\n",
    "X = np.random.uniform(0, 1, n_samples)\n",
    "\n",
    "# a) Y = 2X + 3\n",
    "Y = 2*X + 3\n",
    "print(f'a) Y = 2X + 3, o\u00f9 X ~ Uniform[0, 1]\\n')\n",
    "print(f'   X : min={X.min():.4f}, max={X.max():.4f}, E[X]={X.mean():.4f}')\n",
    "print(f'   Y : min={Y.min():.4f}, max={Y.max():.4f}, E[Y]={Y.mean():.4f}')\n",
    "print(f'\\n   Y est une transformation lin\u00e9aire')\n",
    "print(f'   Th\u00e9oriquement : Y ~ Uniform[3, 5] avec E[Y] = 2\u00d70.5 + 3 = 4')\n",
    "print(f'   Empiriquement : E[Y] = {Y.mean():.4f} \u2713\\n')\n",
    "\n",
    "# b) Z = X\u00b2\n",
    "Z = X**2\n",
    "print(f'b) Z = X\u00b2, o\u00f9 X ~ Uniform[0, 1]\\n')\n",
    "print(f'   Z : min={Z.min():.4f}, max={Z.max():.4f}, E[Z]={Z.mean():.4f}')\n",
    "print(f'   PDF th\u00e9orique : f_Z(z) = 1/(2\u221az) pour z \u2208 [0, 1]')\n",
    "print(f'   Esp\u00e9rance th\u00e9orique : E[Z] = \u222b\u2080\u00b9 z \u00d7 1/(2\u221az) dz = 1/3')\n",
    "print(f'   Esp\u00e9rance empirique : {Z.mean():.4f} \u2713\\n')\n",
    "\n",
    "# c) Visualisation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# X\n",
    "axes[0, 0].hist(X, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axhline(1, color='red', linestyle='--', linewidth=2, label='PDF th\u00e9orique')\n",
    "axes[0, 0].set_xlabel('X')\n",
    "axes[0, 0].set_ylabel('Densit\u00e9')\n",
    "axes[0, 0].set_title('X ~ Uniform[0, 1]', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Y\n",
    "axes[0, 1].hist(Y, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].axhline(0.5, color='red', linestyle='--', linewidth=2, label='PDF th\u00e9orique')\n",
    "axes[0, 1].set_xlabel('Y = 2X + 3')\n",
    "axes[0, 1].set_ylabel('Densit\u00e9')\n",
    "axes[0, 1].set_title('Y ~ Uniform[3, 5]', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Z\n",
    "axes[1, 0].hist(Z, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "z_vals = np.linspace(0.01, 1, 1000)\n",
    "pdf_z = 1 / (2 * np.sqrt(z_vals))\n",
    "axes[1, 0].plot(z_vals, pdf_z, 'r-', linewidth=2, label='PDF th\u00e9orique: 1/(2\u221az)')\n",
    "axes[1, 0].set_xlabel('Z = X\u00b2')\n",
    "axes[1, 0].set_ylabel('Densit\u00e9')\n",
    "axes[1, 0].set_title('Z ~ ? (transformation non-lin\u00e9aire)', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_ylim(0, 3)\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Scatter plot : X vs Y, X vs Z\n",
    "axes[1, 1].scatter(X[:1000], Y[:1000], alpha=0.3, s=10, label='Y = 2X + 3')\n",
    "axes[1, 1].scatter(X[:1000], Z[:1000], alpha=0.3, s=10, label='Z = X\u00b2')\n",
    "axes[1, 1].set_xlabel('X')\n",
    "axes[1, 1].set_ylabel('Valeur transform\u00e9e')\n",
    "axes[1, 1].set_title('Comparaison des transformations', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4.4 : Quantiles d'une distribution normale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X ~ Normale(0, 1)\n",
    "print('\ud83d\udcca QUANTILES D\\'UNE DISTRIBUTION NORMALE\\n' + '='*60)\n",
    "\n",
    "# a) Quartiles\n",
    "Q1 = stats.norm.ppf(0.25)\n",
    "Q2 = stats.norm.ppf(0.50)  # M\u00e9diane\n",
    "Q3 = stats.norm.ppf(0.75)\n",
    "\n",
    "print(f'a) Quartiles de N(0,1) :')\n",
    "print(f'   Q1 (25e percentile) = {Q1:.4f}')\n",
    "print(f'   Q2 (50e percentile/M\u00e9diane) = {Q2:.4f}')\n",
    "print(f'   Q3 (75e percentile) = {Q3:.4f}\\n')\n",
    "\n",
    "# b) P(X > 1.96)\n",
    "P_X_gt_196 = 1 - stats.norm.cdf(1.96)\n",
    "print(f'b) P(X > 1.96) = {P_X_gt_196:.4f}')\n",
    "print(f'   = {P_X_gt_196*100:.2f}% (intervalle de confiance \u00e0 95%)\\n')\n",
    "\n",
    "# c) Trouver x tel que P(X \u2264 x) = 0.95\n",
    "x_095 = stats.norm.ppf(0.95)\n",
    "print(f'c) x tel que P(X \u2264 x) = 0.95 : x = {x_095:.4f}\\n')\n",
    "\n",
    "# d) Visualisation\n",
    "x_vals = np.linspace(-4, 4, 1000)\n",
    "pdf_vals = stats.norm.pdf(x_vals)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(x_vals, pdf_vals, 'b-', linewidth=2, label='PDF')\n",
    "\n",
    "# Colorer P(X > 1.96)\n",
    "x_tail = x_vals[x_vals >= 1.96]\n",
    "pdf_tail = stats.norm.pdf(x_tail)\n",
    "ax.fill_between(x_tail, pdf_tail, alpha=0.3, color='red', label=f'P(X > 1.96) = {P_X_gt_196:.4f}')\n",
    "\n",
    "# Colorer intervalle Q1 \u00e0 Q3\n",
    "x_middle = x_vals[(x_vals >= Q1) & (x_vals <= Q3)]\n",
    "pdf_middle = stats.norm.pdf(x_middle)\n",
    "ax.fill_between(x_middle, pdf_middle, alpha=0.3, color='green', label='IQR (Q1 \u00e0 Q3)')\n",
    "\n",
    "# Marquer les quantiles\n",
    "ax.axvline(Q1, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(Q2, color='black', linestyle='-', linewidth=1.5, alpha=0.7, label='M\u00e9diane')\n",
    "ax.axvline(Q3, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(1.96, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Annotations\n",
    "ax.text(Q1, 0.42, f'Q1\\n{Q1:.2f}', ha='center', fontweight='bold')\n",
    "ax.text(Q2, 0.42, f'Q2\\n{Q2:.2f}', ha='center', fontweight='bold')\n",
    "ax.text(Q3, 0.42, f'Q3\\n{Q3:.2f}', ha='center', fontweight='bold')\n",
    "ax.text(1.96, 0.35, f'1.96', ha='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Densit\u00e9 de probabilit\u00e9')\n",
    "ax.set_title('Quantiles et intervalles de la distribution N(0,1)', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nR\u00e9sum \u00e9 :')  \n",
    "print(f'  68% des donn\u00e9es entre \u03bc\u00b1\u03c3 = [-1, 1]')\n",
    "print(f'  95% des donn\u00e9es entre \u03bc\u00b11.96\u03c3 = [-1.96, 1.96]')\n",
    "print(f'  99.7% des donn\u00e9es entre \u03bc\u00b13\u03c3 = [-3, 3]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4.5 : Variables continues vs discr\u00e8tes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('\u221e VARIABLES CONTINUES vs DISCR\u00c8TES\\n' + '='*60)\n",
    "\n",
    "# a) Pourquoi P(X = x) = 0?\n",
    "print('a) Probabilit\u00e9 ponctuelle pour VA continue :')\n",
    "print('   P(X = x) = 0 pour toute VA continue')\n",
    "print('   \u2192 L\\'ensemble des r\u00e9els est infini et non d\u00e9nombrable')\n",
    "print('   \u2192 Les probabilit\u00e9s se \"distribuent\" sur un continuum')\n",
    "print('   \u2192 P(X = exact_value) \u2192 0 quand ensemble \u2192 \u221e\\n')\n",
    "\n",
    "# b) Simulation\n",
    "n_samples = 100000\n",
    "samples = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "print(f'b) Simulation : g\u00e9n\u00e9ration de {n_samples} \u00e9chantillons N(0,1)')\n",
    "exact_zeros = np.sum(samples == 0)\n",
    "print(f'   Nombre d\\'occurrences de exactement 0.0 : {exact_zeros}')\n",
    "print(f'   Probabilit\u00e9 : {exact_zeros}/{n_samples} = {exact_zeros/n_samples}\\n')\n",
    "\n",
    "# c) Comparer P(|X| < 0.01) vs P(X = 0)\n",
    "P_interval = stats.norm.cdf(0.01) - stats.norm.cdf(-0.01)\n",
    "P_exact = 0  # Toujours 0 pour VA continue\n",
    "\n",
    "print(f'c) Comparaison :')\n",
    "print(f'   P(|X| < 0.01) = {P_interval:.6f}')\n",
    "print(f'   P(X = 0 exactement) = {P_exact} (par d\u00e9finition)\\n')\n",
    "\n",
    "# d) Explication\n",
    "print('d) Diff\u00e9rence fondamentale :')\n",
    "print('   VA Discr\u00e8te : P(X = x) > 0, on peut \"pointer\" sur une valeur')\n",
    "print('   VA Continue : P(X = x) = 0, mais P(a < X < b) > 0')\n",
    "print('   \u2192 La probabilit\u00e9 se mesure sur des INTERVALLES, pas des points\\n')\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogramme\n",
    "axes[0].hist(samples, bins=100, density=True, alpha=0.7, edgecolor='black')\n",
    "x_vals = np.linspace(-4, 4, 1000)\n",
    "axes[0].plot(x_vals, stats.norm.pdf(x_vals), 'r-', linewidth=2, label='PDF')\n",
    "axes[0].axvline(0, color='green', linestyle='--', linewidth=2, alpha=0.7, label='X=0')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Densit\u00e9')\n",
    "axes[0].set_title('Distribution N(0,1) : Point isol\u00e9 a probabilit\u00e9 0', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# P(a < X < b) vs P(X = x)\n",
    "categories = ['P(|X|<0.01)', 'P(X=0)', 'P(|X|<0.1)', 'P(|X|<1)']\n",
    "probs = [\n",
    "    stats.norm.cdf(0.01) - stats.norm.cdf(-0.01),\n",
    "    0,\n",
    "    stats.norm.cdf(0.1) - stats.norm.cdf(-0.1),\n",
    "    stats.norm.cdf(1) - stats.norm.cdf(-1)\n",
    "]\n",
    "\n",
    "axes[1].bar(categories, probs, alpha=0.7, color=['steelblue', 'red', 'steelblue', 'steelblue'], edgecolor='black')\n",
    "axes[1].set_ylabel('Probabilit\u00e9')\n",
    "axes[1].set_title('Probabilit\u00e9s : Intervalles vs Points', fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (cat, prob) in enumerate(zip(categories, probs)):\n",
    "    axes[1].text(i, prob + 0.01, f'{prob:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 : Distributions de Probabilit\u00e9\n",
    "\n",
    "### Solution 5.1 : Bernoulli et Binomiale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Conversion d'un site : p = 0.15\n",
    "p = 0.15\n",
    "n_visiteurs = 100\n",
    "n_jours = 1000\n",
    "\n",
    "print('\ud83c\udfaf DISTRIBUTIONS BERNOULLI ET BINOMIALE\\n' + '='*60)\n",
    "print(f'Param\u00e8tres : p = {p} (taux de conversion), n = {n_visiteurs} visiteurs\\n')\n",
    "\n",
    "# a) Bernoulli pour 1 visiteur\n",
    "print('a) VA Bernoulli pour 1 visiteur :')\n",
    "print(f'   X ~ Bernoulli(p={p})')\n",
    "print(f'   P(conversion) = {p}')\n",
    "print(f'   P(pas conversion) = {1-p}\\n')\n",
    "\n",
    "# b) Distribution pour 100 visiteurs\n",
    "print(f'b) Pour {n_visiteurs} visiteurs, nombre de conversions :')\n",
    "print(f'   Y ~ Binomiale(n={n_visiteurs}, p={p})')\n",
    "print(f'   E[Y] = np = {n_visiteurs*p:.1f}')\n",
    "print(f'   Var(Y) = np(1-p) = {n_visiteurs*p*(1-p):.2f}\\n')\n",
    "\n",
    "# c) P(exactement 20 conversions)\n",
    "P_20 = stats.binom.pmf(20, n_visiteurs, p)\n",
    "print(f'c) P(Y = 20 conversions) = {P_20:.6f}')\n",
    "print(f'   (Tr\u00e8s faible car 20 est loin de E[Y] = 15)\\n')\n",
    "\n",
    "# d) P(au moins 10 conversions)\n",
    "P_at_least_10 = 1 - stats.binom.cdf(9, n_visiteurs, p)\n",
    "print(f'd) P(Y \u2265 10) = {P_at_least_10:.4f}\\n')\n",
    "\n",
    "# e) Simulation : 1000 jours\n",
    "print(f'e) Simulation de {n_jours} jours de {n_visiteurs} visiteurs :')\n",
    "conversions_per_day = np.random.binomial(n_visiteurs, p, n_jours)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# PMF th\u00e9orique\n",
    "x_vals = np.arange(0, n_visiteurs+1)\n",
    "pmf_vals = stats.binom.pmf(x_vals, n_visiteurs, p)\n",
    "\n",
    "axes[0].bar(x_vals[pmf_vals > 0.01], pmf_vals[pmf_vals > 0.01], alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(n_visiteurs*p, color='red', linestyle='--', linewidth=2, label=f'E[Y] = {n_visiteurs*p:.1f}')\n",
    "axes[0].set_xlabel('Nombre de conversions')\n",
    "axes[0].set_ylabel('Probabilit\u00e9')\n",
    "axes[0].set_title(f'PMF Binomiale(n={n_visiteurs}, p={p})', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# CDF\n",
    "cdf_vals = stats.binom.cdf(x_vals, n_visiteurs, p)\n",
    "axes[1].step(x_vals, cdf_vals, where='mid', alpha=0.7, linewidth=2)\n",
    "axes[1].axhline(0.5, color='green', linestyle='--', alpha=0.5, label='M\u00e9diane')\n",
    "axes[1].axhline(0.95, color='red', linestyle='--', alpha=0.5, label='95e percentile')\n",
    "axes[1].set_xlabel('k')\n",
    "axes[1].set_ylabel('P(Y \u2264 k)')\n",
    "axes[1].set_title('CDF Binomiale', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Histogramme simulation\n",
    "axes[2].hist(conversions_per_day, bins=30, density=True, alpha=0.7, edgecolor='black', label='Simulation')\n",
    "axes[2].bar(x_vals[pmf_vals > 0.01], pmf_vals[pmf_vals > 0.01], alpha=0.3, \n",
    "            edgecolor='black', color='orange', label='Th\u00e9orique')\n",
    "axes[2].set_xlabel('Nombre de conversions')\n",
    "axes[2].set_ylabel('Densit\u00e9')\n",
    "axes[2].set_title(f'Simulation ({n_jours} jours)', fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Empirique : \u03bc = {conversions_per_day.mean():.2f}, \u03c3 = {conversions_per_day.std():.2f}')\n",
    "print(f'Th\u00e9orique : \u03bc = {n_visiteurs*p:.2f}, \u03c3 = {np.sqrt(n_visiteurs*p*(1-p)):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5.2 : Distribution de Poisson"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Requ\u00eates par seconde\nlambda_1s = 5\n",
    "\n",
    "print('\ud83d\udce1 DISTRIBUTION DE POISSON\\n' + '='*60)\n",
    "print(f'Requ\u00eates par seconde : \u03bb = {lambda_1s}\\n')\n",
    "\n",
    "# a) Loi de Poisson\n",
    "print('a) Mod\u00e9lisation avec Poisson :')\n",
    "print(f'   N(t) ~ Poisson(\u03bbt) o\u00f9 t est en secondes')\n",
    "print(f'   E[N(1s)] = \u03bb = {lambda_1s}')\n",
    "print(f'   Var(N(1s)) = \u03bb = {lambda_1s}\\n')\n",
    "\n",
    "# b) P(exactement 3 requ\u00eates en 1 sec)\n",
    "P_3 = stats.poisson.pmf(3, lambda_1s)\n",
    "print(f'b) P(N = 3 en 1 sec) = {P_3:.6f}\\n')\n",
    "\n",
    "# c) P(plus de 8 requ\u00eates en 1 sec)\n",
    "P_more_8 = 1 - stats.poisson.cdf(8, lambda_1s)\n",
    "print(f'c) P(N > 8 en 1 sec) = {P_more_8:.6f}\\n')\n",
    "\n",
    "# d) En 10 secondes\n",
    "lambda_10s = lambda_1s * 10\n",
    "print(f'd) En 10 secondes :')\n",
    "print(f'   \u03bb(10s) = \u03bb \u00d7 10 = {lambda_10s}')\n",
    "print(f'   E[N(10s)] = {lambda_10s}')\n",
    "print(f'   Var(N(10s)) = {lambda_10s}\\n')\n",
    "\n",
    "# e) PMF pour diff\u00e9rents \u03bb\n",
    "lambdas = [1, 5, 10, 20]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, lam in enumerate(lambdas):\n",
    "    ax = axes[idx]\n",
    "    x_vals = np.arange(0, max(30, int(lam*3)))\n",
    "    pmf_vals = stats.poisson.pmf(x_vals, lam)\n",
    "    \n",
    "    ax.bar(x_vals, pmf_vals, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "    ax.axvline(lam, color='red', linestyle='--', linewidth=2, label=f'E[N] = {lam}')\n",
    "    ax.set_xlabel('Nombre d\\'\u00e9v\u00e9nements')\n",
    "    ax.set_ylabel('Probabilit\u00e9')\n",
    "    ax.set_title(f'Poisson(\u03bb={lam})', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Distribution de Poisson pour diff\u00e9rents \u03bb', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Propri\u00e9t\u00e9 : Additivit\u00e9\n",
    "print('\ud83d\udca1 Propri\u00e9t\u00e9 importante : Si N1 ~ Poisson(\u03bb1) et N2 ~ Poisson(\u03bb2)')\n",
    "print(f'   Alors N1 + N2 ~ Poisson(\u03bb1 + \u03bb2)')\n",
    "print(f'   Exemple : N(10s) ~ Poisson({lambda_10s}) = somme de 10 v.a. Poisson({lambda_1s})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5.3 : Distribution Normale (QI)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# QI : X ~ Normale(100, 225) o\u00f9 225 = 15\u00b2\n",
    "mu = 100\n",
    "sigma = 15\n",
    "\n",
    "print('\ud83e\udde0 DISTRIBUTION NORMALE : QI\\n' + '='*60)\n",
    "print(f'QI ~ Normale(\u03bc={mu}, \u03c3={sigma})\\n')\n",
    "\n",
    "# a) P(X > 130) - QI tr\u00e8s sup\u00e9rieur\n",
    "P_above_130 = 1 - stats.norm.cdf(130, mu, sigma)\n",
    "print(f'a) P(QI > 130) = {P_above_130:.6f}')\n",
    "print(f'   = {P_above_130*100:.3f}% (top {1/P_above_130:.1f}e)\\n')\n",
    "\n",
    "# b) P(85 \u2264 X \u2264 115)\n",
    "P_in_range = stats.norm.cdf(115, mu, sigma) - stats.norm.cdf(85, mu, sigma)\n",
    "print(f'b) P(85 \u2264 QI \u2264 115) = {P_in_range:.6f}')\n",
    "print(f'   = {P_in_range*100:.2f}% (variation \"normal\")\\n')\n",
    "\n",
    "# c) x tel que P(X > x) = 0.01\n",
    "x_top_1 = stats.norm.ppf(0.99, mu, sigma)\n",
    "print(f'c) QI pour top 1% : P(X > {x_top_1:.1f}) = 0.01\\n')\n",
    "\n",
    "# d) Visualisation\n",
    "x_vals = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "pdf_vals = stats.norm.pdf(x_vals, mu, sigma)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(x_vals, pdf_vals, 'b-', linewidth=2.5, label='PDF')\n",
    "\n",
    "# Zone P(X > 130)\n",
    "x_above_130 = x_vals[x_vals >= 130]\n",
    "pdf_above_130 = stats.norm.pdf(x_above_130, mu, sigma)\n",
    "ax.fill_between(x_above_130, pdf_above_130, alpha=0.3, color='red', \n",
    "               label=f'P(QI > 130) = {P_above_130:.4f}')\n",
    "\n",
    "# Zone P(85 \u2264 X \u2264 115)\n",
    "x_middle = x_vals[(x_vals >= 85) & (x_vals <= 115)]\n",
    "pdf_middle = stats.norm.pdf(x_middle, mu, sigma)\n",
    "ax.fill_between(x_middle, pdf_middle, alpha=0.3, color='green',\n",
    "               label=f'P(85 \u2264 QI \u2264 115) = {P_in_range:.4f}')\n",
    "\n",
    "# Annotations\n",
    "ax.axvline(mu, color='black', linestyle='--', linewidth=1.5, alpha=0.7, label=f'Moyenne = {mu}')\n",
    "ax.axvline(130, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(85, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(115, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(x_top_1, color='purple', linestyle='--', linewidth=1.5, alpha=0.7, label=f'Top 1% : {x_top_1:.0f}')\n",
    "\n",
    "ax.set_xlabel('QI', fontsize=12)\n",
    "ax.set_ylabel('Densit\u00e9', fontsize=12)\n",
    "ax.set_title(f'Distribution des QI ~ N({mu}, {sigma}\u00b2)', fontweight='bold', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# e) Simulation\n",
    "print('e) Simulation de 10 000 personnes :')\n",
    "n_samples = 10000\n",
    "samples = np.random.normal(mu, sigma, n_samples)\n",
    "\n",
    "print(f'   Empirique : \u03bc = {samples.mean():.2f}, \u03c3 = {samples.std():.2f}')\n",
    "print(f'   Th\u00e9orique : \u03bc = {mu}, \u03c3 = {sigma}')\n",
    "print(f'   P(QI > 130) empirique : {np.mean(samples > 130):.6f}')\n",
    "print(f'   P(QI > 130) th\u00e9orique : {P_above_130:.6f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5.4 : Approximation Binomiale \u2192 Normale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X ~ Binomiale(n=100, p=0.5)\n",
    "n = 100\n",
    "p = 0.5\n",
    "\n",
    "print('\ud83d\udcc8 APPROXIMATION BINOMIALE \u2192 NORMALE\\n' + '='*60)\n",
    "print(f'X ~ Binomiale(n={n}, p={p})\\n')\n",
    "\n",
    "# a) E[X] et Var(X)\n",
    "E_X = n * p\n",
    "Var_X = n * p * (1 - p)\n",
    "sigma_X = np.sqrt(Var_X)\n",
    "\n",
    "print(f'a) Param\u00e8tres :')\n",
    "print(f'   E[X] = np = {E_X}')\n",
    "print(f'   Var(X) = np(1-p) = {Var_X}')\n",
    "print(f'   \u03c3 = \u221aVar(X) = {sigma_X}\\n')\n",
    "\n",
    "# b) Approximation normale\n",
    "print(f'b) Approximation par Normale(\u03bc={E_X}, \u03c3\u00b2={Var_X}) :')\n",
    "print(f'   (Valide car n=100 est assez grand)\\n')\n",
    "\n",
    "# c) Comparer P(X \u2264 55)\n",
    "P_exact = stats.binom.cdf(55, n, p)\n",
    "P_approx = stats.norm.cdf(55, E_X, sigma_X)\n",
    "\n",
    "print(f'c) P(X \u2264 55) :')\n",
    "print(f'   Exact (Binomiale) = {P_exact:.6f}')\n",
    "print(f'   Approximation (Normale) = {P_approx:.6f}')\n",
    "print(f'   Erreur = {abs(P_exact - P_approx):.6f}\\n')\n",
    "\n",
    "# d) Tracer PMF vs PDF\n",
    "x_vals = np.arange(30, 71)\n",
    "pmf_vals = stats.binom.pmf(x_vals, n, p)\n",
    "\n",
    "x_continuous = np.linspace(30, 70, 1000)\n",
    "pdf_vals = stats.norm.pdf(x_continuous, E_X, sigma_X)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.bar(x_vals, pmf_vals, alpha=0.6, edgecolor='black', color='steelblue', \n        label=f'PMF Binomiale(n={n}, p={p})')\n",
    "ax.plot(x_continuous, pdf_vals, 'r-', linewidth=2.5, \n        label=f'PDF Normale(\u03bc={E_X}, \u03c3={sigma_X:.2f})')\n",
    "\n",
    "ax.axvline(E_X, color='black', linestyle='--', linewidth=1.5, alpha=0.7, label=f'Moyenne = {E_X}')\n",
    "ax.fill_between(x_continuous[x_continuous <= 55], pdf_vals[x_continuous <= 55], \n                  alpha=0.2, color='orange', label=f'P(X \u2264 55)')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Probabilit\u00e9')\n",
    "ax.set_title('Approximation Binomiale par Normale', fontweight='bold', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# e) Pour quel n l'approximation devient-elle bonne?\n",
    "print('e) Qualit\u00e9 de l\\'approximation en fonction de n :')\n",
    "ns = [10, 20, 50, 100, 200]\n",
    "for n_test in ns:\n",
    "    E_test = n_test * p\n",
    "    sigma_test = np.sqrt(n_test * p * (1-p))\n",
    "    P_exact_test = stats.binom.cdf(50, n_test, p)\n",
    "    P_approx_test = stats.norm.cdf(50, E_test, sigma_test)\n",
    "    erreur = abs(P_exact_test - P_approx_test)\n",
    "    print(f'   n={n_test:3d} : erreur = {erreur:.6f}')\n",
    "\n",
    "print(f'\\n\ud83d\udca1 R\u00e8gle empirique : approximation bonne si np \u2265 5 ET n(1-p) \u2265 5')\n",
    "print(f'   Pour p=0.5 : besoin n \u2265 10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5.5 : Q-Q Plot (Quantile-Quantile)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('\ud83d\udcca Q-Q PLOT : TEST DE NORMALIT\u00c9\\n' + '='*60)\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "# G\u00e9n\u00e9rer 3 ensembles d'\u00e9chantillons\n",
    "samples_normal = np.random.normal(5, 2, n_samples)\n",
    "samples_exponential = np.random.exponential(1, n_samples)\n",
    "samples_uniform = np.random.uniform(0, 10, n_samples)\n",
    "\n",
    "# Q-Q plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Normale vs Normale (doit \u00eatre lin\u00e9aire)\n",
    "stats.probplot(samples_normal, dist='norm', plot=axes[0])\n",
    "axes[0].set_title('Normale(5,4) vs Normale th\u00e9orique\\n\u2192 Lin\u00e9aire \u2713', fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Exponentielle vs Normale (courbe)\n",
    "stats.probplot(samples_exponential, dist='norm', plot=axes[1])\n",
    "axes[1].set_title('Exponentielle(1) vs Normale th\u00e9orique\\n\u2192 Courbe S \u2717', fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Uniforme vs Normale (courbe)\n",
    "stats.probplot(samples_uniform, dist='norm', plot=axes[2])\n",
    "axes[2].set_title('Uniforme(0,10) vs Normale th\u00e9orique\\n\u2192 Courbe S \u2717', fontweight='bold')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Q-Q Plots : \u00c9valuer l\\'ad\u00e9quation \u00e0 la Normale', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('d) Interpr\u00e9tation des Q-Q plots :\\n')\n",
    "print('   \u2022 Points sur la ligne diagonale \u2192 Distribution suit la Normale')\n",
    "print('   \u2022 Points courbes (S) \u2192 D\u00e9viation de la Normale')\n",
    "print('   \u2022 Queue \u00e9paisse (Exponentielle) \u2192 Skewness vers la droite')\n",
    "print('   \u2022 Uniforme \u2192 Courbe S sym\u00e9trique (plus dense aux extr\u00eames)\\n')\n",
    "\n",
    "print('e) Conclusion :')\n",
    "print('   \u2713 Normale(5,4) : ressemble \u00e0 une distribution normale')\n",
    "print('   \u2717 Exponentielle(1) : queue longue \u00e0 droite')\n",
    "print('   \u2717 Uniforme(0,10) : plate, pas concentr\u00e9e au centre')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5.6 : Application Finance - Rendements d'actions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rendements journaliers : R ~ Normale(\u03bc=0.0005, \u03c3=0.02)\n",
    "mu_daily = 0.0005  # 0.05% par jour\n",
    "sigma_daily = 0.02  # 2% d'\u00e9cart-type\n",
    "n_trading_days = 252  # jours de bourse par an\n",
    "\n",
    "print('\ud83d\udcb0 APPLICATION FINANCE : RENDEMENTS D\\'ACTIONS\\n' + '='*60)\n",
    "print(f'Rendements journaliers ~ Normale(\u03bc={mu_daily}, \u03c3={sigma_daily})\\n')\n",
    "\n",
    "# a) Probabilit\u00e9 de perdre de l'argent\n",
    "P_loss = stats.norm.cdf(0, mu_daily, sigma_daily)\n",
    "print(f'a) P(Rendement < 0) = P(R < 0)')\n",
    "print(f'   = {P_loss:.6f}')\n",
    "print(f'   = {P_loss*100:.2f}% de chances de perdre en un jour\\n')\n",
    "\n",
    "# b) Probabilit\u00e9 de perdre plus de 5%\n",
    "P_loss_5pct = stats.norm.cdf(-0.05, mu_daily, sigma_daily)\n",
    "print(f'b) P(R < -0.05) = P(rendement < -5%)')\n",
    "print(f'   = {P_loss_5pct:.6f}')\n",
    "print(f'   = {P_loss_5pct*100:.4f}% (\u00e9v\u00e9nement tr\u00e8s rare)\\n')\n",
    "\n",
    "# c) Nombre de jours de pertes en un an\n",
    "expected_loss_days = P_loss * n_trading_days\n",
    "print(f'c) Jours de pertes attendus en 1 an ({n_trading_days} jours) :')\n",
    "print(f'   {expected_loss_days:.1f} jours de pertes attendus\\n')\n",
    "\n",
    "# d) Simulation 1 an\n",
    "daily_returns = np.random.normal(mu_daily, sigma_daily, n_trading_days)\n",
    "\n",
    "# Calcul du rendement annuel compos\u00e9\n",
    "annual_return = np.prod(1 + daily_returns) - 1\n",
    "loss_days = np.sum(daily_returns < 0)\n",
    "\n",
    "print(f'd) Simulation d\\'une ann\u00e9e ({n_trading_days} jours) :')\n",
    "print(f'   Jours de pertes : {loss_days}/{n_trading_days} (attendu : ~{expected_loss_days:.0f})')\n",
    "print(f'   Rendement total : {annual_return*100:.2f}%\\n')\n",
    "\n",
    "# e) Rendement total annuel\n",
    "mu_annual = (1 + mu_daily)**n_trading_days - 1  # Approx: n_trading_days * mu_daily\n",
    "print(f'e) Rendement annuel esp\u00e9r\u00e9 :')\n",
    "print(f'   E[rendement annuel] \u2248 {mu_annual*100:.2f}%')\n",
    "print(f'   (Approximation : {n_trading_days} \u00d7 {mu_daily*100}% = {n_trading_days*mu_daily*100:.2f}%)\\n')\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribution des rendements journaliers\n",
    "x_vals = np.linspace(-0.1, 0.1, 1000)\n",
    "pdf_vals = stats.norm.pdf(x_vals, mu_daily, sigma_daily)\n",
    "\n",
    "axes[0, 0].hist(daily_returns, bins=30, density=True, alpha=0.7, edgecolor='black', label='Simulation')\n",
    "axes[0, 0].plot(x_vals, pdf_vals, 'r-', linewidth=2, label='PDF th\u00e9orique')\n",
    "axes[0, 0].axvline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[0, 0].fill_between(x_vals[x_vals < 0], pdf_vals[x_vals < 0], alpha=0.3, color='red')\n",
    "axes[0, 0].set_xlabel('Rendement journalier')\n",
    "axes[0, 0].set_ylabel('Densit\u00e9')\n",
    "axes[0, 0].set_title(f'Distribution des rendements journaliers\\nP(perte) = {P_loss:.2%}', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Chemins de prix\n",
    "n_simulations = 100\n",
    "prices = np.zeros((n_trading_days + 1, n_simulations))\n",
    "prices[0] = 100  # Prix initial\n",
    "\n",
    "for i in range(1, n_trading_days + 1):\n",
    "    returns = np.random.normal(mu_daily, sigma_daily, n_simulations)\n",
    "    prices[i] = prices[i-1] * (1 + returns)\n",
    "\n",
    "for j in range(n_simulations):\n",
    "    axes[0, 1].plot(prices[:, j], alpha=0.3, color='steelblue')\n",
    "\n",
    "axes[0, 1].plot(np.mean(prices, axis=1), color='red', linewidth=2, label='Prix moyen')\n",
    "axes[0, 1].set_xlabel('Jour')\n",
    "axes[0, 1].set_ylabel('Prix')\n",
    "axes[0, 1].set_title(f'{n_simulations} simulations d\\'1 an de trading', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Rendements cumul\u00e9s (simulation unique)\n",
    "cumulative_return = np.cumprod(1 + daily_returns) - 1\n",
    "axes[1, 0].plot(cumulative_return*100, linewidth=2, color='steelblue')\n",
    "axes[1, 0].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].fill_between(range(len(cumulative_return)), cumulative_return*100, 0, \n",
    "                         where=(cumulative_return >= 0), alpha=0.3, color='green', label='Gains')\n",
    "axes[1, 0].fill_between(range(len(cumulative_return)), cumulative_return*100, 0,\n",
    "                         where=(cumulative_return < 0), alpha=0.3, color='red', label='Pertes')\n",
    "axes[1, 0].set_xlabel('Jour')\n",
    "axes[1, 0].set_ylabel('Rendement cumul\u00e9 (%)')\n",
    "axes[1, 0].set_title('Rendement cumul\u00e9 (1 simulation)', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Distribution des rendements annuels\n",
    "annual_returns = []\n",
    "for _ in range(1000):\n",
    "    sim_returns = np.random.normal(mu_daily, sigma_daily, n_trading_days)\n",
    "    annual_r = np.prod(1 + sim_returns) - 1\n",
    "    annual_returns.append(annual_r)\n",
    "\n",
    "axes[1, 1].hist(annual_returns, bins=50, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "axes[1, 1].axvline(np.mean(annual_returns), color='red', linestyle='--', linewidth=2, \n",
    "                    label=f'Moyenne : {np.mean(annual_returns)*100:.2f}%')\n",
    "axes[1, 1].axvline(np.percentile(annual_returns, 5), color='orange', linestyle='--', linewidth=2,\n",
    "                   label=f'VaR 95% : {np.percentile(annual_returns, 5)*100:.2f}%')\n",
    "axes[1, 1].set_xlabel('Rendement annuel')\n",
    "axes[1, 1].set_ylabel('Fr\u00e9quence')\n",
    "axes[1, 1].set_title('Distribution des rendements annuels (1000 simulations)', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques\n",
    "print('\ud83d\udcca Statistiques des 1000 simulations annuelles :')\n",
    "print(f'   Rendement moyen : {np.mean(annual_returns)*100:.2f}%')\n",
    "print(f'   \u00c9cart-type : {np.std(annual_returns)*100:.2f}%')\n",
    "print(f'   Min : {np.min(annual_returns)*100:.2f}%')\n",
    "print(f'   Max : {np.max(annual_returns)*100:.2f}%')\n",
    "print(f'   VaR 95% (perte possible) : {np.percentile(annual_returns, 5)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udf93 Conclusion\n",
    "\n",
    "Ce chapitre a couvert tous les concepts fondamentaux des probabilit\u00e9s :\n",
    "\n",
    "\u2705 **Espaces de probabilit\u00e9** et \u00e9v\u00e9nements  \n",
    "\u2705 **Probabilit\u00e9s conditionnelles** et ind\u00e9pendance  \n",
    "\u2705 **Th\u00e9or\u00e8me de Bayes** et mise \u00e0 jour des croyances  \n",
    "\u2705 **Variables al\u00e9atoires** discr\u00e8tes et continues  \n",
    "\u2705 **Distributions de probabilit\u00e9** classiques  \n",
    "\u2705 **Esp\u00e9rance et variance**  \n",
    "\u2705 **Covariance et corr\u00e9lation**  \n",
    "\n",
    "Vous \u00eates maintenant pr\u00eat(e) pour :\n",
    "- La statistique inf\u00e9rentielle\n",
    "- Les processus stochastiques\n",
    "- L'apprentissage automatique\n",
    "- Les applications en finance et science\n",
    "\n",
    "\ud83d\udcaa **Bravo pour votre apprentissage !**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}